{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "## Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3df59-367c-4815-a19a-3eca20fc3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def convert_tif_to_jpg(source_folder, destination_folder, quality=85):\n",
    "    \"\"\"\n",
    "    Convert .tif files to .jpg format and move copies to destination folder.\n",
    "    Original .tif files remain in source folder.\n",
    "    \n",
    "    Args:\n",
    "        source_folder (str): Path to folder containing .tif files\n",
    "        destination_folder (str): Path to destination folder for .jpg files\n",
    "        quality (int): JPEG quality (1-100, default 85)\n",
    "    \"\"\"\n",
    "    # Create destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    converted_files = []\n",
    "    \n",
    "    # Process all .tif files in source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.lower().endswith(('.tif', '.tiff')):\n",
    "            source_path = os.path.join(source_folder, filename)\n",
    "            \n",
    "            # Create new filename with .jpg extension\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            jpg_filename = f\"{base_name}.jpg\"\n",
    "            destination_path = os.path.join(destination_folder, jpg_filename)\n",
    "            \n",
    "            try:\n",
    "                # Open and convert image\n",
    "                with Image.open(source_path) as img:\n",
    "                    # Convert to RGB if necessary (TIFF might be in different modes)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    # Save as JPEG in destination folder\n",
    "                    img.save(destination_path, 'JPEG', quality=quality, optimize=True)\n",
    "                \n",
    "                converted_files.append(jpg_filename)\n",
    "                print(f\"Converted: {filename} -> {jpg_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully converted {len(converted_files)} files\")\n",
    "    return converted_files\n",
    "\n",
    "# Example usage:\n",
    "# convert_tif_to_jpg(\"/path/to/source\", \"/path/to/destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725db7-b5dd-4321-b3ed-b1d27142efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_image_if_needed(image_path):\n",
    "    \"\"\"Convert TIFF (and other unsupported formats) to JPG.\"\"\"\n",
    "    path = Path(image_path)\n",
    "    \n",
    "    if path.suffix.lower() in ['.tif', '.tiff']:\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Build new path manually\n",
    "            jpg_path = path.parent / f\"{path.stem}_converted.jpg\"\n",
    "            \n",
    "            img.save(jpg_path, 'JPEG', quality=95)\n",
    "            print(f\"Converted {path} to {jpg_path}\")\n",
    "            return str(jpg_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return str(path)\n",
    "\n",
    "\n",
    "def call_ollama_model(image_path, prompt):\n",
    "    \"\"\"Make the API call to Ollama.\"\"\"\n",
    "    # Convert image if needed\n",
    "    processed_path = convert_image_if_needed(image_path)\n",
    "    if processed_path is None:\n",
    "        raise ValueError(f\"Could not process image: {image_path}\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"minicpm-v\",  \n",
    "        messages=[{\n",
    "            'role': 'user', \n",
    "            'content': prompt,\n",
    "            'images': [processed_path]\n",
    "        }],\n",
    "        options={\n",
    "        'temperature': 0.1,  # Lower = more deterministic (0.0 to 1.0)\n",
    "        'seed': 42           # Fixed seed for reproducibility\n",
    "    }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6242b16-8dfc-4745-a88e-47f2bd3e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'person': X,              # 1 if present, 0 if not\n",
    "        'mountain': X,            # 1 if present, 0 if not\n",
    "        'river': X,               # 1 if present, 0 if not\n",
    "        'lake': X,                # 1 if present, 0 if not\n",
    "        'building': X,            # 1 if present, 0 if not\n",
    "        'church': X,              # 1 if present, 0 if not\n",
    "        'city': X,                # 1 if present, 0 if not\n",
    "        'village': X,             # 1 if present, 0 if not\n",
    "        'glacier': X,             # 1 if present, 0 if not\n",
    "        'other_objects': [],      # List of other noteworthy/dominant objects\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f00ddd9-a107-47ae-af33-307c52f4866a",
   "metadata": {},
   "source": [
    "def parse_response_to_dict(response_text):\n",
    "    \"\"\"Parse the model response into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        dict_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if dict_match:\n",
    "            dict_str = dict_match.group()\n",
    "            dict_str = dict_str.replace('\\\\_', '_')\n",
    "            result_dict = ast.literal_eval(dict_str)\n",
    "            \n",
    "            # Add missing confidence scores if needed\n",
    "            objects = ['person', 'mountain', 'river', 'lake', 'building', \n",
    "                      'church', 'city', 'village', 'glacier']\n",
    "            \n",
    "            for obj in objects:\n",
    "                if obj in result_dict and f'{obj}_confidence' not in result_dict:\n",
    "                    # Add default confidence: 0.8 if present, 0.9 if absent\n",
    "                    result_dict[f'{obj}_confidence'] = 0.8 if result_dict[obj] == 1 else 0.9\n",
    "            \n",
    "            success = True\n",
    "        else:\n",
    "            result_dict = None\n",
    "            success = False\n",
    "    except Exception as e:\n",
    "        result_dict = None\n",
    "        success = False\n",
    "    \n",
    "    return success, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2585f-79c9-4456-a62d-e81fe711a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def parse_response_to_dict(response_text):\n",
    "    \"\"\"Parse the model response into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        # First try to find dictionary in code blocks\n",
    "        code_block_match = re.search(r'```(?:python)?\\s*(\\{.*?\\})\\s*```', response_text, re.DOTALL)\n",
    "        if code_block_match:\n",
    "            dict_str = code_block_match.group(1)\n",
    "        else:\n",
    "            # Fallback to finding any dictionary pattern\n",
    "            dict_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if dict_match:\n",
    "                dict_str = dict_match.group()\n",
    "            else:\n",
    "                return False, None\n",
    "        \n",
    "        # Clean up the dictionary string\n",
    "        dict_str = dict_str.replace('\\\\_', '_')\n",
    "        dict_str = dict_str.strip()\n",
    "        \n",
    "        # Parse the dictionary\n",
    "        result_dict = ast.literal_eval(dict_str)\n",
    "        return True, result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ee583-883d-4903-b45a-1f36b7b9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_structured(image_path):\n",
    "    \"\"\"Main function that orchestrates the image analysis.\"\"\"\n",
    "    # Define prompt for LLM model:\n",
    "    prompt = create_analysis_prompt()\n",
    "    # Ask LLM to analyse image, by calling the model and providing \n",
    "    # the defined prompt: \n",
    "    response_text = call_ollama_model(image_path, prompt)\n",
    "    # Parse response text, i.e. find dictionary of expected structure\n",
    "    # in the response text:\n",
    "    success, result_dict = parse_response_to_dict(response_text)\n",
    "    \n",
    "    if success:\n",
    "        return result_dict\n",
    "    else:\n",
    "        # Save response text in dictionary paired with key \"raw_response\"\n",
    "        # if parsing the response text fails:\n",
    "        llm_response = {\"raw_response\": response_text}\n",
    "        return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c57f3-8585-43d0-a1e6-e0d343cdef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_values(idx, labels_results, columns, values_to_add):\n",
    "    selection_bools = labels_results.image_id == inspection_idx\n",
    "    \n",
    "    labels_results.loc[selection_bools, columns] = values_to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d0ce-4b92-406a-86a3-115e9f210264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / '..').resolve()\n",
    "#root_path = (project_path / '..' / 'test_yolo_object_train').resolve()\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6e136-ac5d-4691-b43d-4c1fc8c0a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6120ce4-87af-499c-b9d4-a5138e7016ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310d7c2-a030-4058-a7dc-7648f06dc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1f1fa-c987-4fe2-b55d-a8d9e6d325b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1b307-e475-4c08-959f-bd0d38f8ef84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32204a-0c76-46d2-ae33-d1b517769bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216fa35-f34e-4259-96cd-0869f7c240e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab450-6f71-47d3-a776-2cd529f5cdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ea01b5-5273-4c33-bac4-65123ebc6102",
   "metadata": {},
   "source": [
    "## Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf52a5-56f8-4204-9e47-378e996472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "## Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30304f6-7ab4-4eb6-9c40-bed3395c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d699e4-32f5-4759-8ff3-56834cfad99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files to analyse: \n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "# Specify names of categorical variables that the create_analysis_prompt refers to \n",
    "# (for image_type one of a range of categories is expected,\n",
    "# the other ones are one-hot coded):\n",
    "keys_list_expected = ['image_type', 'person', 'mountain', 'river', \n",
    "                      'lake', 'building', 'church', 'city', 'village', \n",
    "                      'glacier', 'other_objects', 'additional_comments']\n",
    "\n",
    "# Make empty dictionary to store results:\n",
    "image_descr = {}\n",
    "\n",
    "# Loop through images to get answers: \n",
    "for image_file in image_files:\n",
    "    image_path = jpg_data_path / image_file\n",
    "    path_str = str(image_path)\n",
    "    print('\\n')\n",
    "    print(path_str)\n",
    "    parts = path_str.split('.jpg')\n",
    "    img_id = parts[-2][-3:]\n",
    "\n",
    "    # Analyse image, get values for each of the categorical variables specified above:\n",
    "    image_description = analyze_image_structured(image_path)\n",
    "    \n",
    "    dict_type_bool = type(image_description) == dict\n",
    "        \n",
    "    print(image_description)\n",
    "    image_descr[img_id] = image_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5ab71-cebd-4b0c-8b46-701be48a6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe1991-2727-4fd7-b275-109c73fd4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ec90f-f92d-4a5f-952f-b3ac127608b1",
   "metadata": {},
   "source": [
    "### Save dictionary with LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6dc6be-3ace-4199-aa39-e583f1effd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_analysis_output_path = os.path.join(data_path, 'image_analysis_minicpm_2025.07.17.pkl')\n",
    "img_analysis_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b173a0-92cf-4caa-aeb7-cad861494ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(image_descr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8bddf-907f-4864-971b-c40fa817dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99046aa2-2fc5-4074-9d2d-09fc9f9c730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reloaded_image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74980a-4bbc-4ac6-8146-15393ccace66",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reloaded_image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145f41f-9b6c-4887-98f8-f02b77d88d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295f8c3-2fbc-4967-a566-fdd57fc7df1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95530c-68b9-4ad1-9365-809f93f70ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_descr = reloaded_image_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f86bda-5a51-44df-a40c-dc5af9ea1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_descr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45410e35-c951-4735-993a-fbabf576fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_image_descr.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dd660-aa85-44e1-8b02-49e17054321c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5be30-ddc5-445c-9e92-bbc79138c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f21e6-4aae-40b2-90c2-15bda797fdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54078976-7ef8-4547-b90d-e596c9ef3f39",
   "metadata": {},
   "source": [
    "### Load person label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f459f09-9c6f-4b2c-854c-f225dce204a6",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc6072-e684-4013-81f6-2f6e947e1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1695ee-5062-4bf5-ac14-29dcb9faf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = list(label_data.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba10d8-b24e-4008-809d-9ff18e4ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' to ensure \n",
    "# string data type to deal with duck typing): \n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd5a44-796e-4b2e-9c5a-c97ce035f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50265cce-896e-484c-8aab-0475c5c0e19a",
   "metadata": {},
   "source": [
    "### Rename the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a548af-66dc-43c5-a9db-129f101a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.rename(columns={'with_person': 'person_label', 'person_recognisable': 'recognisable_label'}, inplace=True)\n",
    "label_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278339fe-7a9d-4144-8413-757a643e0069",
   "metadata": {},
   "source": [
    "### Loop through Responses from the LLM and incorporate them into a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d6b69-5f76-4678-b3c0-23215395d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare empty lists to store results\n",
    "img_ids = []\n",
    "img_type = []\n",
    "is_photo = []\n",
    "with_person = []\n",
    "with_church = []\n",
    "\n",
    "# Get list of image ids: \n",
    "img_ids = label_data.image_id\n",
    "\n",
    "# Make empty list to store responses that cannot be parsed\n",
    "# due to faulty structure for closer inspection: \n",
    "img_ids_closer_inspection = []\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "# List of keys expected in each dictionary provided as an answer by\n",
    "# the LLM:\n",
    "keys_list_expected = ['image_type', 'person', 'mountain', 'river', \n",
    "                      'lake', 'building', 'church', 'city', 'village', \n",
    "                      'glacier', 'other_objects', 'additional_comments']\n",
    "\n",
    "# Loop through image ids:\n",
    "for img_id in img_ids:\n",
    "\n",
    "    # Get response from LLM for image id in question:\n",
    "    img_pred = image_descr[img_id]\n",
    "\n",
    "    # Get keys from response dictionary:\n",
    "    keys_list = list(img_pred.keys())\n",
    "\n",
    "    # Check if structure and keys of response match expectation:\n",
    "    dict_struct_condition = (type(img_pred) == dict)\n",
    "    keys_condition = (keys_list_expected == keys_list)\n",
    "\n",
    "    # Check if response key \n",
    "    raw_key_condition = keys_list == ['raw_response']\n",
    "    \n",
    "    # If the llm response corresponds to the expected\n",
    "    # structure, get response values as planned:\n",
    "    if dict_struct_condition and keys_condition:\n",
    "        \n",
    "        image_type_values = img_pred['image_type']\n",
    "\n",
    "        is_photo_bool = 'photography' in image_type_values\n",
    "        if is_photo_bool:\n",
    "            is_photo_value = 1\n",
    "        else:\n",
    "            is_photo_value = 0\n",
    "        \n",
    "        person_value = img_pred['person']\n",
    "        \n",
    "        church_value = img_pred['church']\n",
    "\n",
    "        img_type.append(image_type_values)\n",
    "        is_photo.append(is_photo_value)\n",
    "        with_person.append(person_value)\n",
    "        with_church.append(church_value)\n",
    "        \n",
    "    # If llm response does not correspond to the expected \n",
    "    # structure but does have the 'raw_response' key\n",
    "    # try to identify a dictionary inside the response text\n",
    "    # and try to parse this dictionary as planned:\n",
    "    elif dict_struct_condition and raw_key_condition:\n",
    "        print('\\n')\n",
    "        print('raw_repsonse_dict:')\n",
    "        print(img_id)\n",
    "        print(dict_struct_condition)\n",
    "        print(raw_key_condition)\n",
    "\n",
    "        response_text = img_pred['raw_response']\n",
    "\n",
    "        start_indices = [i for i, char in enumerate(response_text) if char == '{']\n",
    "        start_idx = start_indices[0]\n",
    "        \n",
    "        end_indices = [i for i, char in enumerate(response_text) if char == '}']\n",
    "        end_idx = end_indices[0]\n",
    "\n",
    "        dict_in_text = response_text[start_idx:end_idx+1]\n",
    "\n",
    "        success_bool, img_pred = parse_response_to_dict(dict_in_text)\n",
    "        print('success_bool:')\n",
    "        print(success_bool)\n",
    "\n",
    "        # If a dictionary is found and parsed successfully\n",
    "        # get response values as planned:\n",
    "        if success_bool:\n",
    "            print(type(img_pred))\n",
    "            print(img_pred.keys())\n",
    "            \n",
    "            image_type_values = img_pred['image_type']\n",
    "    \n",
    "            is_photo_bool = 'photography' in image_type_values\n",
    "            if is_photo_bool:\n",
    "                is_photo_value = 1\n",
    "            else:\n",
    "                is_photo_value = 0\n",
    "            \n",
    "            person_value = img_pred['person']\n",
    "            \n",
    "            church_value = img_pred['church']\n",
    "\n",
    "            img_type.append(image_type_values)\n",
    "            is_photo.append(is_photo_value)\n",
    "            with_person.append(person_value)\n",
    "            with_church.append(church_value)\n",
    "            \n",
    "        else:\n",
    "            # If dictionary is not found or not successfully\n",
    "            # parsed, add the image in question to the list\n",
    "            # of images for closer (visual) inspection:\n",
    "            print('parse unsuccessful')\n",
    "            print(img_id)\n",
    "            img_ids_closer_inspection.append(img_id)\n",
    "            img_type.append(None)\n",
    "            is_photo.append(None)\n",
    "            with_person.append(None)\n",
    "            with_church.append(None)\n",
    "\n",
    "    # If the llm response does not have the expected struture\n",
    "    # and no 'raw_response' key is found, add the image in \n",
    "    # question to the list of images for closer (visual)\n",
    "    # inspection:\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print('no structure at all:')\n",
    "        print(img_id)\n",
    "        img_ids_closer_inspection.append(img_id)\n",
    "        img_type.append(None)\n",
    "        is_photo.append(None)\n",
    "        with_person.append(None)\n",
    "        with_church.append(None)\n",
    "        \n",
    "        \n",
    "    \n",
    "    iter_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad0037-b6ff-4bf4-b0ac-bded14aa9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all response variable lists have the same length:\n",
    "print(len(img_ids))\n",
    "print(len(img_type))\n",
    "print(len(is_photo))\n",
    "print(len(with_person))\n",
    "print(len(with_church))\n",
    "print(len(img_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecc2c0-78ec-45a3-b1b1-06a7bccb7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image list for closer inspection:\n",
    "img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4fbe5-a493-4d93-966b-d0c7635708d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           'is_photo_pred': is_photo,\n",
    "                           'with_person_pred': with_person,\n",
    "                           'with_church_pred': with_church})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05c4ef-a70a-4129-bc0a-325b8773a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffc372-43a2-4f15-bc30-a9a36f1fe4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920a17dc-4c15-4d1a-b808-1dd7be6703d3",
   "metadata": {},
   "source": [
    "### Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33349e62-6be4-408a-8efc-103e2655948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f13dd6-b6b0-4f56-8d39-67e111df81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f3d42-a258-412a-af23-4c7af6046d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_closer_inspection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7985c-21e1-4839-a599-91fa106edbb6",
   "metadata": {},
   "source": [
    "### Amend results manually by taking into account unstructured answers (images for closer inspection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106efde-7c2a-48d9-934e-8003e4311e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index for the image information for closer inspection:\n",
    "inspection_idx = img_ids_closer_inspection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ce384-5f3b-463c-8c79-e0b933b27db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are indeed missing:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacd709-5634-4db0-9d40-6272153b61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available information: \n",
    "image_descr[inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb95e3-452d-4f05-81ed-63fd7096faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to labels_results dataframe manually:\n",
    "columns = ['is_photo_pred', 'with_person_pred', 'with_church_pred']\n",
    "add_pred_values(inspection_idx, labels_results, columns, [int(0), int(0), int(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec6d50-b439-422d-bd1f-b53e7925b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values have been added:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743a8bb-e027-4283-8792-5ab43043e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79b549-db95-4037-85f8-1f01403dac91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f97d0-747e-4f02-b72f-5e275f66be21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b1e6c-70b8-4079-9759-d021c393c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index for the image information for closer inspection:\n",
    "inspection_idx = img_ids_closer_inspection[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e1866-2b35-4bb9-b6a3-665e887f3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are indeed missing:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4dbf7-e2f4-4db5-bf13-3c097ba25e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available information: \n",
    "image_descr[inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1cd3f-889a-4a70-aac9-ba584159994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to labels_results dataframe manually:\n",
    "columns = ['is_photo_pred', 'with_person_pred', 'with_church_pred']\n",
    "add_pred_values(inspection_idx, labels_results, columns, [0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbf1b0-29a4-4b54-b431-2141c110b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values have been added:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab84f81-d642-4771-adbe-7bd3113419ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index for the image information for closer inspection:\n",
    "inspection_idx = img_ids_closer_inspection[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1668e4-8c8c-473a-bdaf-dc1b2a4413b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are indeed missing:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05b244-608c-4e70-9bf7-599d343596b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available information: \n",
    "image_descr[inspection_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de738d5-784a-45e8-b96d-e53038dc6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to labels_results dataframe manually:\n",
    "columns = ['is_photo_pred', 'with_person_pred', 'with_church_pred']\n",
    "add_pred_values(inspection_idx, labels_results, columns, [1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d94f6f-f08b-429a-bc0d-c19a2a0f68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if values are indeed missing:\n",
    "labels_results[labels_results.image_id == inspection_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee0c21-91d0-40fe-b77f-daded83b3e20",
   "metadata": {},
   "source": [
    "### Convert data type of added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf796c9-c32a-4e53-b692-00ea4bdbcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.astype({'is_photo_pred': 'int', 'with_person_pred': 'int',\n",
    "                       'with_church_pred': 'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f0b68-52aa-4222-b304-19211ac5db75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb3f1e-6a28-4412-96d8-24b77fc0af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir_not_photo)\n",
    "print(output_dir_with_person)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e65ac1a-f2cb-4c58-9013-f79ca175f9dc",
   "metadata": {},
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14651d2-72f0-4b0a-a61d-73d4b0f282ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419e431-a0af-4e97-a9a7-7dc2daac120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be landscape photographies: \n",
    "for idx, row in labels_results.iterrows():\n",
    "    #print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.jpg'\n",
    "    if int(is_photo) == 0:\n",
    "        source_path = jpg_data_path / file_name\n",
    "        dest_path = output_dir_not_photo / file_name\n",
    "        #print(dest_path)\n",
    "        shutil.move(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1da582f6-c6a2-473c-9d55-7037bb9a64ce",
   "metadata": {},
   "source": [
    "for idx, row in labels_results.iterrows():\n",
    "    #print(idx)\n",
    "    img_id = row['image_id']\n",
    "    with_person = row['with_person_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.jpg'\n",
    "    if int(with_person) == 1:\n",
    "        source_path = jpg_data_path / file_name\n",
    "        dest_path = output_dir_with_person / file_name\n",
    "        #print(dest_path)\n",
    "        shutil.move(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66e768-1f32-418b-9062-a6e59177582a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf9df5a-88f0-4de3-ae3c-dde8d4185905",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for person predictions and get lists images with positive person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fb8f9-2032-4908-8c66-1eebdddafb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.person_label == 1\n",
    "negative_bools = labels_results.person_label == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c95cb-6605-49d0-b3af-c3ff908641a7",
   "metadata": {},
   "source": [
    "### Inspect false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446b2d-4b55-4bef-8485-f2be100e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b326a-b974-4350-9040-0c8f784f527a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4343ee97-be36-46cc-a187-222201fa544d",
   "metadata": {},
   "source": [
    "### Inspect false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f47b2-baed-4a59-8307-f8ca516b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caecd08-a314-436d-bf7b-2f4fa1b877d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462523cd-d8ea-4808-9d66-e127feda0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df66e0c-3e88-4fa7-9983-7e908fb8ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0420ed9-de48-4153-8def-15ee30a3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.person_label, labels_results.with_person_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad321902-18c9-4d50-9043-a43163ef4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Person Detection: Confusion Matrix and Performance Metrics Based on the Person Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_person.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6ee81-9aea-4edb-a3eb-d8772240022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673922cb-2284-4bce-81eb-bccb11756b57",
   "metadata": {},
   "source": [
    "### Recalculate Measures with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d3f2b-92e3-49d8-9964-2d7996606dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.recognisable_label == 1\n",
    "negative_bools = labels_results.recognisable_label == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf4f0e-a299-4803-9443-59cb4a24dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d54e54-f787-4140-982c-0b9098dc6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c1c9f-a08f-47b5-ad0e-afbc45e03b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.recognisable_label, labels_results.with_person_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb537157-cf48-4f53-8625-1013d2959129",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Person Detection: Confusion Matrix and Performance Metrics Based on the Recognisable Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_recognisable.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c00d4-45b8-46c9-bcde-6e22adc8d68f",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13d1fd-bbac-4998-954b-e7141c41d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.is_photo == 1\n",
    "negative_bools = labels_results.is_photo == 0\n",
    "positive_pred_bools = labels_results.is_photo_pred == 1\n",
    "negative_pred_bools = labels_results.is_photo_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5508e-8b60-4d77-99cd-e04e6959d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe379c24-9281-4a04-b4ad-0c9da9d47ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.is_photo, labels_results.is_photo_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d0a03-c8ad-48ad-a978-a9156958028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_is_photo.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9363e1-2c25-4d98-b6f7-45555bebd838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87f150-2f43-445f-86c0-85e2d294cfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e9918b-0295-408e-a986-ed2add02442a",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for church predictions and get lists images with positive church predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0c0b5-f2f9-492a-b44a-b9256264e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.church == 1\n",
    "negative_bools = labels_results.church == 0\n",
    "positive_pred_bools = labels_results.with_church_pred == 1\n",
    "negative_pred_bools = labels_results.with_church_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79b0f7-9834-4789-b46c-e5213b8a3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572eafb-a299-4148-b44e-c7f4c31c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.church, labels_results.with_church_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f78d5-ac9f-464d-aa71-3324e65f1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Church Detection: Confusion Matrix and Performance Metrics Based on the church Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_with_church.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956596d-148e-47b1-8cf9-47b66a0a0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0137-885b-4afd-b44b-27acdf383b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46c5c2-c63a-4d9a-b594-a4e383ff4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_curch_path = root_path / 'false_church_pred'\n",
    "church_false_positives_path = false_curch_path / 'false_positives'\n",
    "church_false_negatives_path = false_curch_path / 'false_negatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83c2d7-77da-4f2b-9e34-c49d6ce0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "church_false_positives_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933831cc-84a9-478d-880c-581a2c5015b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be landscape photographies: \n",
    "for idx, row in false_positives.iterrows():\n",
    "    print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.tif'\n",
    "    print(file_name)\n",
    "    source_path = tif_data_path / file_name\n",
    "    dest_path = church_false_positives_path / file_name\n",
    "    print(source_path)\n",
    "    print(dest_path)\n",
    "    shutil.copy(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9dd2-832f-40cb-ba90-3ed2aa1d4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be landscape photographies: \n",
    "for idx, row in false_negatives.iterrows():\n",
    "    print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.tif'\n",
    "    source_path = tif_data_path / file_name\n",
    "    dest_path = church_false_negatives_path / file_name\n",
    "    print(dest_path)\n",
    "    shutil.copy(source_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba07bd-6049-4440-a879-6a2df6e620ed",
   "metadata": {},
   "source": [
    "### Visually inspect the images in the two folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88257e62-8e10-40ea-8570-e42f8110a574",
   "metadata": {},
   "source": [
    "Visually verified all classified images, false negatives are all images with non-recognisable persons (according to my judgement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbf1fb-af81-4867-8d66-5167dfb97585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3f1d-fd66-45f3-9105-7717b6a6aef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f451591-afbb-41d9-a3b2-d1be9914fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d305021-7cdd-46ef-8338-9af38927bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image ids that will remain string type even when saved to csv and reloaded:\n",
    "labels = list(labels_results.image_id)\n",
    "new_labels = img_idc.complete_image_ids(labels)\n",
    "labels_results['image_id_str'] = new_labels\n",
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = pd.Timestamp.now()\n",
    "current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438b057-f651-4cb8-b883-aad2eacd6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "current_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ab9b-b8c3-4020-806d-c6ba76fc2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_results.to_csv(data_path /'results_img_analysis_minicpm_2025.07.17.csv')\n",
    "results_file_name = 'results_img_analysis_minicpm_' + current_date_time + '.csv'\n",
    "labels_results.to_csv(data_path /results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
