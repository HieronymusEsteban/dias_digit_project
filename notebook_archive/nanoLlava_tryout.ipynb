{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5f1e3-23ec-4155-934d-9e1912bcfa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf791b1-b302-4af4-97fc-51cdf009be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf1b7d-60ab-4759-84aa-3eca07bd8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / '..').resolve()\n",
    "\n",
    "# Define paths\n",
    "image_dir = root_path/'visual_genome_proc_data'  # Replace with your directory containing images\n",
    "image_dir_2 = root_path/'data_1'\n",
    "#image_file_path = image_dir / image_files[0]\n",
    "image_file_path = image_dir / 'visual_genome_proc_2356444.jpg'\n",
    "image_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f858ff9-b832-4fd9-9bae-724c041e04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-V', trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "# For Nvidia GPUs support BF16 (like A100, H100, RTX3090)\n",
    "#model = model.to(device='cuda', dtype=torch.bfloat16)\n",
    "# For Nvidia GPUs do NOT support BF16 (like V100, T4, RTX2080)\n",
    "#model = model.to(device='cuda', dtype=torch.float16)\n",
    "# For Mac with MPS (Apple silicon or AMD GPUs).\n",
    "# Run with `PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py`\n",
    "model = model.to(device='mps', dtype=torch.float16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V', trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(image_file_path).convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': question}]\n",
    "\n",
    "res, context, _ = model.chat(\n",
    "    image=image,\n",
    "    msgs=msgs,\n",
    "    context=None,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5c47c-3e19-4c3e-9c19-4e6c57219b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868604e7-f973-4e03-9c54-0eb16dfe1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('openbmb/MiniCPM-V', trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "# For Nvidia GPUs support BF16 (like A100, H100, RTX3090)\n",
    "#model = model.to(device='cuda', dtype=torch.bfloat16)\n",
    "# For Nvidia GPUs do NOT support BF16 (like V100, T4, RTX2080)\n",
    "#model = model.to(device='cuda', dtype=torch.float16)\n",
    "# For Mac with MPS (Apple silicon or AMD GPUs).\n",
    "# Run with `PYTORCH_ENABLE_MPS_FALLBACK=1 python test.py`\n",
    "model = model.to(device='mps', dtype=torch.float16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V', trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9f8d2-4e1c-4063-be47-16ebdd96178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / '..').resolve()\n",
    "\n",
    "# Define paths\n",
    "image_dir = root_path/'visual_genome_proc_data'  # Replace with your directory containing images\n",
    "image_dir_2 = root_path/'data_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e7417-4b7e-4865-bd12-ab7cb7958714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_file_path = image_dir / image_files[0]\n",
    "image_file_path = image_dir / 'visual_genome_proc_2356444.jpg'\n",
    "image_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d61459-b615-4922-9cb8-7e7152143624",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_file_path).convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': question}]\n",
    "\n",
    "res, context, _ = model.chat(\n",
    "    image=image,\n",
    "    msgs=msgs,\n",
    "    context=None,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a937aba-4d68-4c61-b7df-07ea8413eddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae77e5-aa82-4f9d-847f-83ae68caaca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579122d-9194-44ca-b2ae-341bd5b24945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd209550-7735-47fc-a024-f7e3edd3c2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
