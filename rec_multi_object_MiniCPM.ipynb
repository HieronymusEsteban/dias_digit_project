{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "#from source import sort_img_files as sif\n",
    "import matplotlib.pyplot as plt\n",
    "from source import llm_input as llm_i\n",
    "from source import llm_output as llm_o\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "## Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c57f3-8585-43d0-a1e6-e0d343cdef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_values(idx, labels_results, columns, values_to_add):\n",
    "    selection_bools = labels_results.image_id == idx\n",
    "    \n",
    "    labels_results.loc[selection_bools, columns] = values_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24809178-8255-4575-93d5-c6053beebdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8218b1ec-e0f3-43c9-beb9-5bf603e55328",
   "metadata": {},
   "source": [
    "def create_prompt_img_type_multi_object():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photograph': X,     # True if the image is a photograph, False otherwise (if the image is a drawing, painting, statistics figure, map, scheme, other)\n",
    "        'high_alpine_environment': X, # True if this appears to be in an high Alpine environment, False if not\n",
    "        'person': X,                  # True if present, False if not\n",
    "        'glacier': X,                 # True if present, False if not\n",
    "        'church': X,                  # True if present, False if not\n",
    "        'water_body': X.              # True if present, False if not\n",
    "        'other_objects': [],          # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''     # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (present) or False (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c1686-ebf6-4b3a-aff0-82cdfb61d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_img_type_multi_object():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photograph': X,     # True if the image is a photograph, False otherwise (if the image is a drawing, painting, statistics figure, map, scheme, other)\n",
    "        'person': X,                  # True if present, False if not\n",
    "        'water_body': X.              # True if present, False if not\n",
    "        'other_objects': [],          # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''     # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (present) or False (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ee96134-49f8-4c06-8f83-2959e771fa61",
   "metadata": {},
   "source": [
    "def create_prompt_img_type_multi_object():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'is_photo': X,     # True if the image is a photograph, False otherwise (if the image is a drawing, painting, statistics figure, map, scheme, other)\n",
    "        'with_person': X,                  # True if present, False if not\n",
    "        'water_body': X.              # True if present, False if not\n",
    "        'other_objects': [],          # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''     # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (present) or False (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057660f5-132d-4bef-af45-adeaa55cb8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf4ea0-e528-4764-b59c-683913b8cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ade46-23c8-485e-b5a6-b5af287ccb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        #print('\\n')\n",
    "        #print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        #image_description = analyze_image_structured(image_path)\n",
    "        #image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt)\n",
    "        image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        #print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9e6ca-6804-4d8f-bf6f-5fb46f40d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration,\n",
    "                  timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['time_stamp_start'].append(timestamp_start_is_photo_analysis)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "\n",
    "    return time_analysis_dict, time_analysis_for_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935c015-c54f-408b-807b-e11189c0c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1199fc-b4d1-4215-b87b-9312c2220b88",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8fa25-5947-4682-b6b7-47d529230b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['time_stamp_start'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0b749-8050-4bda-8087-37da48f392f2",
   "metadata": {},
   "source": [
    "## Switch on working version of Ollama (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a586cb5-eeb3-4841-b3f4-b8254e58705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS FOR OLLAMA VERSION SWITCHING\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def stop_ollama():\n",
    "    \"\"\"Stop any running Ollama process\"\"\"\n",
    "    subprocess.run(['killall', 'ollama'], stderr=subprocess.DEVNULL)\n",
    "    subprocess.run(['killall', 'ollama-0.11.2'], stderr=subprocess.DEVNULL)\n",
    "    subprocess.run(['killall', 'ollama-0.11.10'], stderr=subprocess.DEVNULL)\n",
    "    time.sleep(2)\n",
    "    print(\"âœ“ Stopped all Ollama processes\")\n",
    "\n",
    "def start_ollama_version(version):\n",
    "    \"\"\"Start specific Ollama version (e.g., '0.11.2' or '0.11.10')\"\"\"\n",
    "    binary_name = f'ollama-{version}'\n",
    "    log_file = open(f'/tmp/ollama_{version}.log', 'w')\n",
    "    subprocess.Popen([binary_name, 'serve'], stdout=log_file, stderr=subprocess.STDOUT)\n",
    "    print(f\"Starting Ollama v{version}...\", end='', flush=True)\n",
    "    time.sleep(4)\n",
    "    print(\" âœ“ Running\")\n",
    "\n",
    "print(\"Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af58c06-9c7f-4f13-b0ef-a1771eb58c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: TESTING WITH v0.11.2 (WORKING VERSION - Aug 5, 2025)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"ðŸŸ¢ \"*35)\n",
    "print(\"PART 1: TESTING WITH v0.11.2 (WORKING VERSION)\")\n",
    "print(\"ðŸŸ¢ \"*35 + \"\\n\")\n",
    "\n",
    "stop_ollama()\n",
    "start_ollama_version('0.11.2')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644376b4-99e8-4281-a717-5dc8dd588ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "507682e2-66fb-470c-9ef2-e1cee1f06862",
   "metadata": {},
   "source": [
    "### Define LLM model to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac02fb-e417-4398-971c-e6be5062a70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8046fed-00f6-43a4-a0fc-3e6ebe874039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_model(image_path, prompt_function):\n",
    "    prompt = prompt_function()\n",
    "    \"\"\"Make the API call to Ollama.\"\"\"\n",
    "    # Convert image if needed\n",
    "    processed_path = llm_i.convert_image_if_needed(image_path)\n",
    "    if processed_path is None:\n",
    "        raise ValueError(f\"Could not process image: {image_path}\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"minicpm-v\", \n",
    "        #model=\"llama3.2-vision:latest\",\n",
    "        #model=\"llama3.2-vision:90b\",\n",
    "        messages=[{\n",
    "            'role': 'user', \n",
    "            'content': prompt,\n",
    "            'images': [processed_path]\n",
    "        }],\n",
    "        options={\n",
    "        'temperature': 0.1,  # Lower = more deterministic (0.0 to 1.0)\n",
    "        #'seed': 42           # Fixed seed for reproducibility\n",
    "    }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15bfc5-ec51-42c4-897c-7be70a140e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e049cbf-7223-4546-8440-0c3b502d655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_function = llm_i.call_minicpm_model\n",
    "#model_function = llm_i.call_nanollava_model\n",
    "model_function = call_ollama_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9aeb5-6b12-46c2-bd0a-08d6f9d8a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "\n",
    "#root_path = (project_path / '..' /'data_folders').resolve()\n",
    "root_path = (project_path / '..' /'test_data_folders/test_rec_multi_object_MiniCPM').resolve()\n",
    "\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1b307-e475-4c08-959f-bd0d38f8ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c25bb-f178-47e6-a4db-f18d3041e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35903607-37bb-456f-a985-09cb561c3646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd8c39-a135-447c-b7f2-2be5c1877365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb62703-9432-4e3c-ba49-b5051a23bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "llm_i.convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216fa35-f34e-4259-96cd-0869f7c240e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab450-6f71-47d3-a776-2cd529f5cdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ea01b5-5273-4c33-bac4-65123ebc6102",
   "metadata": {},
   "source": [
    "## Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf52a5-56f8-4204-9e47-378e996472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690967e4-06f4-4d77-a52f-f725dfc1a8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "## Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641cb93-42a2-4cad-a2ce-2f2978100984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54078976-7ef8-4547-b90d-e596c9ef3f39",
   "metadata": {},
   "source": [
    "### Load label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f459f09-9c6f-4b2c-854c-f225dce204a6",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image.\n",
    " * Column photo: whether or not the image is a photograph (as opposed to some other kind of representation such as map, drawing, painting, scheme, figure)\n",
    " * Column church: whether or not any church is in the image.\n",
    " * Column high_alpine_environment: whether or not the scene shown in the image is situated in a high alpine environment (according to non-expert human judgement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77ef9b-d01a-45e9-a133-5a992c89d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8c9ab-29d5-4ac6-ab16-a26e26b6afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = list(label_data.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47591e1a-011a-4d0c-a5f0-8187b57f4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' to ensure \n",
    "# string data type to deal with duck typing): \n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac8e1a-1095-4523-b2fe-85f969b18279",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcc3c4-6d89-4087-908c-8a74c9685453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88dd698c-99cf-4197-a877-0bf320cb7875",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42cdef-a632-4b31-ba15-c3f15f9b766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Find all .ipynb_checkpoints directories\n",
    "for checkpoint_dir in jpg_data_path.rglob('.ipynb_checkpoints'):\n",
    "    if checkpoint_dir.is_dir():\n",
    "        print(f\"Removing: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "#image_files.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7274726-72f5-447e-a111-b2a2b33ee37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a5ce9c5-7f8b-448c-86fd-49235436230a",
   "metadata": {},
   "source": [
    "## Repeat the same procedure but with nicer code (modularized):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb7511-461e-4dba-9ca3-a3ddbbd7755f",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca776a7b-b54a-4b4d-b4ba-096807da622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "prompt_func = create_prompt_img_type_multi_object\n",
    "prompt_template = prompt_func.__name__\n",
    "prompt_id = prompt_template + '_v1'\n",
    "prompt_text = prompt_func()\n",
    "\n",
    "keys_list_expected = ['image_is_photograph', 'person', 'water_body', 'other_objects', \n",
    "                      'additional_comments']\n",
    "\n",
    "response_variables = ['image_is_photograph', 'person']\n",
    "\n",
    "label_names = ['is_photo', 'with_person']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1d804-9e8a-4163-aca2-1c7b1088be89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18117406-d25b-4829-be6b-70610ddaec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff863f-7d98-45ae-96d8-6e2cfbf0f8aa",
   "metadata": {},
   "source": [
    "### Carry out LLM analysis of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27894156-b850-487e-ac03-dbcfadf5ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out the LLM analysis:\n",
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, prompt_func, model_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16fdffa-d7d4-4b9e-b49a-2d2186868a69",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb43e6d-394a-4754-b694-3dd55a45f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timestamp_id as string from the time stamp:\n",
    "timestamp_id = timestamp_start_is_photo_analysis.strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11327511-75e1-4808-9799-fa54d51d49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "response_dictionaries = {}\n",
    "response_dictionaries[timestamp_id] = {}\n",
    "\n",
    "images_closer_inspection = {}\n",
    "\n",
    "results_tabular = {}\n",
    "\n",
    "ml_metrics = pd.DataFrame({})\n",
    "\n",
    "# ml_metrics_analysis_name = []\n",
    "# ml_metrics_prompt_id = []\n",
    "# ml_metrics_label_name = []\n",
    "# ml_metrics_time_stamp = []\n",
    "# ml_metrics_positives = []\n",
    "# ml_metrics_negatives = []\n",
    "# ml_metrics_true_positives = []\n",
    "# ml_metrics_false_positives = []\n",
    "# ml_metrics_true_negatives = []\n",
    "# ml_metrics_false_negatives = []\n",
    "# ml_metrics_sensitivity = []\n",
    "# ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f54ba-216c-4559-b1c5-2ecdc0187f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate duration of analysis: \n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118061f2-7642-4cd3-88f2-63c2256fd7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de4708f-ef5d-4915-989b-647c29f12768",
   "metadata": {},
   "source": [
    "### Extract and organize information from the dictionary containing the LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a470f2f-27f0-4198-a359-c367bf31d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate duration of analysis: \n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "\n",
    "# Store information about duration of LLM task: \n",
    "time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, prompt_id, \n",
    "                duration,timestamp_start_is_photo_analysis,\n",
    "                timestamp_end_is_photo_analysis)\n",
    "\n",
    "\n",
    "# Store dictionary with LLM responses as raw data:\n",
    "response_dictionaries[timestamp_id][prompt_id] = image_descr\n",
    "\n",
    "# convert img_ids pandas series into list:\n",
    "img_ids_l = list(img_ids)\n",
    "\n",
    "# Prepare response variable names and label names to loop through:\n",
    "#response_variables = ['image_is_photograph', 'person', 'church']\n",
    "\n",
    "# Prepare dictionary for long term storing of results: \n",
    "results_tabular[timestamp_id] = {}\n",
    "results_tabular[timestamp_id]['prompt_id'] = prompt_id\n",
    "results_tabular[timestamp_id]['prompt_template'] = prompt_template\n",
    "results_tabular[timestamp_id]['prompt_text'] = prompt_text\n",
    "results_tabular[timestamp_id]['predictions'] = {}\n",
    "\n",
    "# Get copy of label data to merge with prediction for short term presentation of results:\n",
    "labels_results_i = label_data.copy()\n",
    "print('labels_results initial:')\n",
    "print(labels_results_i.shape)\n",
    "print(labels_results_i.columns)\n",
    "\n",
    "# Extract predictions for different response variables:\n",
    "for response_variable, label_name in zip(response_variables, label_names):\n",
    "    # set prediction name: \n",
    "    prediction_name = label_name + '_pred'\n",
    "    analysis_name = label_name + '_struct_minicpm'\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('response_variable name and prediction_name:')\n",
    "    print(response_variable)\n",
    "    print(prediction_name)\n",
    "    img_ids, response_values, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids_l, image_descr, keys_list_expected, response_variable)\n",
    "\n",
    "    timestamp_ids = [timestamp_id] * len(img_ids)\n",
    "    \n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                                   prediction_name: response_values})\n",
    "    predictions[prediction_name] = predictions[prediction_name].astype('Int8')\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('predictions:')\n",
    "    # print(predictions.shape)\n",
    "    # print(predictions.columns)\n",
    "\n",
    "    results_tabular[timestamp_id]['predictions'][response_variable] = predictions\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    labels_results_i = labels_results_i.merge(predictions, how='inner', on='image_id')\n",
    "    # print('\\n')\n",
    "    # print('merged labels_results:')\n",
    "    # print(labels_results_i.shape)\n",
    "    # print(labels_results_i.columns)\n",
    "\n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_id] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_i, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name = []\n",
    "    ml_metrics_prompt_id = []\n",
    "    ml_metrics_label_name = []\n",
    "    ml_metrics_time_stamp = []\n",
    "    ml_metrics_positives = []\n",
    "    ml_metrics_negatives = []\n",
    "    ml_metrics_true_positives = []\n",
    "    ml_metrics_false_positives = []\n",
    "    ml_metrics_true_negatives = []\n",
    "    ml_metrics_false_negatives = []\n",
    "    ml_metrics_sensitivity = []\n",
    "    ml_metrics_specificity = []\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_prompt_id.append(prompt_id)\n",
    "    ml_metrics_label_name.append(label_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "\n",
    "    ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "    ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "    ml_metrics_one_analysis['prompt_id'] = ml_metrics_prompt_id\n",
    "    ml_metrics_one_analysis['label_name'] = ml_metrics_label_name\n",
    "    ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "    ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "    ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "    ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "    ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "    ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "    ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "    ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "    ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "    \n",
    "    ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('ml_metrics:')\n",
    "    # print(ml_metrics.shape)\n",
    "    # print(ml_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6b6ce-48a3-4c1a-b0c2-4108cd4ddad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4257f7-be08-4275-984e-027b44322859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033e622-3f21-4234-bc1c-4fd1d708d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da6ad0-b812-430e-9105-1455060833d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4711dfdf-040b-45aa-82b1-7a1cb572aae8",
   "metadata": {},
   "source": [
    "### Save ml_metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a814d6b-a039-432f-9f9a-79860b658aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = 'ml_metrics_multi_object_struct_minicpm_' + timestamp_id + '.csv'\n",
    "ml_metrics_output_path = os.path.join(data_path, filename)\n",
    "\n",
    "# Save csv-file: \n",
    "ml_metrics.to_csv(ml_metrics_output_path, index=False)\n",
    "\n",
    "# Reload saved csv table to check if saving worked:\n",
    "ml_metrics_reloaded = pd.read_csv(ml_metrics_output_path)\n",
    "ml_metrics_reloaded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a92768-21f7-4a1b-8024-accc0eb30576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "264ea5fc-cd02-480a-bcf0-8be9dc36ea58",
   "metadata": {},
   "source": [
    "### Save images for closer inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b860100-ca08-46d7-b2fa-5355b50c0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "\n",
    "filename = 'img_closer_insp_multi_object_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(images_closer_inspection, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_images_closer_inspection = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(images_closer_inspection))\n",
    "print(len(reloaded_images_closer_inspection))\n",
    "print(type(images_closer_inspection))\n",
    "print(type(reloaded_images_closer_inspection))\n",
    "\n",
    "print(images_closer_inspection.keys() == reloaded_images_closer_inspection.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d91309-17c6-4e7e-9e35-7dd8e12a5ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d50e762-d8f3-45c0-8121-97b17b8256cd",
   "metadata": {},
   "source": [
    "## Save response dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f650657-660d-4a3d-8d94-2d697d97c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "filename = 'responses_multi_object_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(response_dictionaries, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(image_descr))\n",
    "print(type(image_descr))\n",
    "print(type(reloaded_image_descr))\n",
    "print(len(reloaded_image_descr))\n",
    "\n",
    "print(image_descr.keys() == reloaded_image_descr.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92945cf-ec55-4f55-b355-762327dbebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloaded_image_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36a185-c2dc-43ac-b1fc-ddf8c230d843",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0e170-007a-4350-bf33-239d9000f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "results_file_name = 'results_multi_object_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7d2d0-ccd5-438f-9068-f7f6ff01e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results_tabular.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82088761-fbca-48e9-9869-7db99d1f5ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21111641-f963-42b0-acfe-77b3ba816c1d",
   "metadata": {},
   "source": [
    "## Calculate duration of analysis overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8432dad-27c3-4c7f-ab78-69e6dd5f36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_workflow = pd.Timestamp.now()\n",
    "timestamp_end_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf0454-0379-48f1-9aec-1c052492abb3",
   "metadata": {},
   "source": [
    "## Save time analyses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7339b-31cc-4a4e-9513-ccc335aa19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_df_file_name = 'times_multi_object_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32c9b8-864a-4052-b9a7-b5ad497f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses_for_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8727f23-55da-4627-86ef-01c2d4eb09de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b82ce-0fd9-4ea3-8846-c75c96dec3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3003f8-5d0b-470d-bcc2-4a560f93a7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
