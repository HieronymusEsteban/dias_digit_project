{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "import matplotlib.pyplot as plt\n",
    "from source import llm_input as llm_i\n",
    "from source import llm_output as llm_o\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "## Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6242b16-8dfc-4745-a88e-47f2bd3e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'person': X,              # 1 if present, 0 if not\n",
    "        'mountain': X,            # 1 if present, 0 if not\n",
    "        'river': X,               # 1 if present, 0 if not\n",
    "        'lake': X,                # 1 if present, 0 if not\n",
    "        'building': X,            # 1 if present, 0 if not\n",
    "        'church': X,              # 1 if present, 0 if not\n",
    "        'city': X,                # 1 if present, 0 if not\n",
    "        'village': X,             # 1 if present, 0 if not\n",
    "        'glacier': X,             # 1 if present, 0 if not\n",
    "        'other_objects': [],      # List of other noteworthy/dominant objects\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36de157-2e02-43a5-b689-4121d8f732e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'Does this appear to be in an high Alpine environment?' # 1 if yes, 0 if no\n",
    "        'person': X,              # 1 if present, 0 if not\n",
    "        'glacier': X,             # 1 if present, 0 if not\n",
    "        'church': X,              # 1 if present, 0 if not\n",
    "        'water body': X.          # 1 if present, 0 if not\n",
    "        'other_objects': [],      # List of other noteworthy/dominant objects\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a424d1-abc0-4e1c-9678-c2c2d32e6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'high alpine environment' # 1 if this appears to be in an high Alpine environment, 0 if not\n",
    "        'person': X,               # 1 if present, 0 if not\n",
    "        'glacier': X,              # 1 if present, 0 if not\n",
    "        'church': X,               # 1 if present, 0 if not\n",
    "        'water body': X.           # 1 if present, 0 if not\n",
    "        'other_objects': [],       # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''  # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c57f3-8585-43d0-a1e6-e0d343cdef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_values(idx, labels_results, columns, values_to_add):\n",
    "    selection_bools = labels_results.image_id == idx\n",
    "    \n",
    "    labels_results.loc[selection_bools, columns] = values_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ee606-5782-4b76-a216-db6f23a91e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935c015-c54f-408b-807b-e11189c0c8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1199fc-b4d1-4215-b87b-9312c2220b88",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487513a0-47e8-4b79-91b8-38141705ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['time_stamp_start'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32208388-0166-41a3-85e0-eb1be3e06689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "507682e2-66fb-470c-9ef2-e1cee1f06862",
   "metadata": {},
   "source": [
    "### Define LLM model to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf7676-2116-4d6b-8a7a-71ab4f582961",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = llm_i.call_minicpm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d0ce-4b92-406a-86a3-115e9f210264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "#root_path = (project_path / '..').resolve()\n",
    "#root_path = (project_path / '..' / 'test_yolo_object_train').resolve()\n",
    "root_path = project_path / 'test_llm_img_analysis'\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1b307-e475-4c08-959f-bd0d38f8ef84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32204a-0c76-46d2-ae33-d1b517769bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "llm_i.convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216fa35-f34e-4259-96cd-0869f7c240e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab450-6f71-47d3-a776-2cd529f5cdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ea01b5-5273-4c33-bac4-65123ebc6102",
   "metadata": {},
   "source": [
    "## Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf52a5-56f8-4204-9e47-378e996472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690967e4-06f4-4d77-a52f-f725dfc1a8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbe55cd-c3c0-45a2-bd5d-36a1bc723148",
   "metadata": {},
   "source": [
    "### Set analysis name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27b6b2-7818-4aa1-942a-0bb5604587b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'image_analysis_minicpm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "## Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30304f6-7ab4-4eb6-9c40-bed3395c71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641cb93-42a2-4cad-a2ce-2f2978100984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a191506-a410-47c7-91a6-bec8725e0360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d699e4-32f5-4759-8ff3-56834cfad99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files to analyse: \n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "# Specify names of categorical variables that the create_analysis_prompt refers to \n",
    "# (for image_type one of a range of categories is expected,\n",
    "# the other ones are one-hot coded):\n",
    "# keys_list_expected = ['image_type', 'person', 'mountain', 'river', \n",
    "#                       'lake', 'building', 'church', 'city', 'village', \n",
    "#                       'glacier', 'other_objects', 'additional_comments']\n",
    "\n",
    "# Make empty dictionary to store results:\n",
    "image_descr = {}\n",
    "\n",
    "# Loop through images to get answers: \n",
    "for image_file in image_files:\n",
    "    image_path = jpg_data_path / image_file\n",
    "    path_str = str(image_path)\n",
    "    print('\\n')\n",
    "    print(path_str)\n",
    "    parts = path_str.split('.jpg')\n",
    "    img_id = parts[-2][-3:]\n",
    "\n",
    "    # Analyse image, get values for each of the categorical variables specified above:\n",
    "    #image_description = analyze_image_structured(image_path)\n",
    "    image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "    \n",
    "    dict_type_bool = type(image_description) == dict\n",
    "        \n",
    "    print(image_description)\n",
    "    image_descr[img_id] = image_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5ab71-cebd-4b0c-8b46-701be48a6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe1991-2727-4fd7-b275-109c73fd4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d352255-e535-4d33-be66-1ba7b878980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2432fd-03fb-4db9-a053-1d4709c0c02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5be30-ddc5-445c-9e92-bbc79138c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f21e6-4aae-40b2-90c2-15bda797fdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54078976-7ef8-4547-b90d-e596c9ef3f39",
   "metadata": {},
   "source": [
    "### Load label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f459f09-9c6f-4b2c-854c-f225dce204a6",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image.\n",
    " * Column photo: whether or not the image is a photograph (as opposed to some other kind of representation such as map, drawing, painting, scheme, figure)\n",
    " * Column church: whether or not any church is in the image.\n",
    " * Column high_alpine_environment: whether or not the scene shown in the image is situated in a high alpine environment (according to non-expert human judgement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc6072-e684-4013-81f6-2f6e947e1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1695ee-5062-4bf5-ac14-29dcb9faf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = list(label_data.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba10d8-b24e-4008-809d-9ff18e4ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' to ensure \n",
    "# string data type to deal with duck typing): \n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd5a44-796e-4b2e-9c5a-c97ce035f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50265cce-896e-484c-8aab-0475c5c0e19a",
   "metadata": {},
   "source": [
    "### Rename the labels:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80f60840-9204-4754-b197-a662f98d3cf5",
   "metadata": {},
   "source": [
    "label_data.rename(columns={'with_person': 'person_label', 'person_recognisable': 'recognisable_label'}, inplace=True)\n",
    "label_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcc3c4-6d89-4087-908c-8a74c9685453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88dd698c-99cf-4197-a877-0bf320cb7875",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42cdef-a632-4b31-ba15-c3f15f9b766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Find all .ipynb_checkpoints directories\n",
    "for checkpoint_dir in jpg_data_path.rglob('.ipynb_checkpoints'):\n",
    "    if checkpoint_dir.is_dir():\n",
    "        print(f\"Removing: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "#image_files.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7274726-72f5-447e-a111-b2a2b33ee37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3ae27-5270-41dd-bc71-9c3df39e617e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0217ad7-53bb-412c-8c85-df6f9a011c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "278339fe-7a9d-4144-8413-757a643e0069",
   "metadata": {},
   "source": [
    "### Loop through Responses from the LLM and incorporate them into a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d6b69-5f76-4678-b3c0-23215395d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare empty lists to store results\n",
    "img_ids = []\n",
    "img_type = []\n",
    "is_photo = []\n",
    "with_person = []\n",
    "with_church = []\n",
    "\n",
    "# Get list of image ids: \n",
    "img_ids = label_data.image_id\n",
    "\n",
    "# Make empty list to store responses that cannot be parsed\n",
    "# due to faulty structure for closer inspection: \n",
    "img_ids_closer_inspection = []\n",
    "\n",
    "iter_count = 0\n",
    "\n",
    "# List of keys expected in each dictionary provided as an answer by\n",
    "# the LLM:\n",
    "keys_list_expected = ['image_type', 'high alpine environment', 'person', \n",
    "                      'glacier', 'church', 'water body', 'other_objects', \n",
    "                      'additional_comments']\n",
    "\n",
    "# Loop through image ids:\n",
    "for img_id in img_ids:\n",
    "\n",
    "    #Â Get response from LLM for image id in question:\n",
    "    img_pred = image_descr[img_id]\n",
    "\n",
    "    # Get keys from response dictionary:\n",
    "    keys_list = list(img_pred.keys())\n",
    "\n",
    "    # Check if structure and keys of response match expectation:\n",
    "    dict_struct_condition = (type(img_pred) == dict)\n",
    "    keys_condition = (keys_list_expected == keys_list)\n",
    "\n",
    "    # Check if response key \n",
    "    raw_key_condition = keys_list == ['raw_response']\n",
    "    \n",
    "    # If the llm response corresponds to the expected\n",
    "    # structure, get response values as planned:\n",
    "    if dict_struct_condition and keys_condition:\n",
    "        \n",
    "        image_type_values = img_pred['image_type']\n",
    "\n",
    "        is_photo_bool = 'photography' in image_type_values\n",
    "        if is_photo_bool:\n",
    "            is_photo_value = 1\n",
    "        else:\n",
    "            is_photo_value = 0\n",
    "        \n",
    "        person_value = img_pred['person']\n",
    "        \n",
    "        church_value = img_pred['church']\n",
    "\n",
    "        img_type.append(image_type_values)\n",
    "        is_photo.append(is_photo_value)\n",
    "        with_person.append(person_value)\n",
    "        with_church.append(church_value)\n",
    "        \n",
    "    # If llm response does not correspond to the expected \n",
    "    # structure but does have the 'raw_response' key\n",
    "    # try to identify a dictionary inside the response text\n",
    "    # and try to parse this dictionary as planned:\n",
    "    elif dict_struct_condition and raw_key_condition:\n",
    "        print('\\n')\n",
    "        print('raw_repsonse_dict:')\n",
    "        print(img_id)\n",
    "        print(dict_struct_condition)\n",
    "        print(raw_key_condition)\n",
    "\n",
    "        response_text = img_pred['raw_response']\n",
    "\n",
    "        start_indices = [i for i, char in enumerate(response_text) if char == '{']\n",
    "        start_idx = start_indices[0]\n",
    "        \n",
    "        end_indices = [i for i, char in enumerate(response_text) if char == '}']\n",
    "        end_idx = end_indices[0]\n",
    "\n",
    "        dict_in_text = response_text[start_idx:end_idx+1]\n",
    "\n",
    "        success_bool, img_pred = parse_response_to_dict(dict_in_text)\n",
    "        print('success_bool:')\n",
    "        print(success_bool)\n",
    "\n",
    "        # If a dictionary is found and parsed successfully\n",
    "        # get response values as planned:\n",
    "        if success_bool:\n",
    "            print(type(img_pred))\n",
    "            print(img_pred.keys())\n",
    "            \n",
    "            image_type_values = img_pred['image_type']\n",
    "    \n",
    "            is_photo_bool = 'photography' in image_type_values\n",
    "            if is_photo_bool:\n",
    "                is_photo_value = 1\n",
    "            else:\n",
    "                is_photo_value = 0\n",
    "            \n",
    "            person_value = img_pred['person']\n",
    "            \n",
    "            church_value = img_pred['church']\n",
    "\n",
    "            img_type.append(image_type_values)\n",
    "            is_photo.append(is_photo_value)\n",
    "            with_person.append(person_value)\n",
    "            with_church.append(church_value)\n",
    "            \n",
    "        else:\n",
    "            # If dictionary is not found or not successfully\n",
    "            # parsed, add the image in question to the list\n",
    "            # of images for closer (visual) inspection:\n",
    "            print('parse unsuccessful')\n",
    "            print(img_id)\n",
    "            img_ids_closer_inspection.append(img_id)\n",
    "            img_type.append(None)\n",
    "            is_photo.append(None)\n",
    "            with_person.append(None)\n",
    "            with_church.append(None)\n",
    "\n",
    "    # If the llm response does not have the expected struture\n",
    "    # and no 'raw_response' key is found, add the image in \n",
    "    # question to the list of images for closer (visual)\n",
    "    # inspection:\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print('no structure at all:')\n",
    "        print(img_id)\n",
    "        img_ids_closer_inspection.append(img_id)\n",
    "        img_type.append(None)\n",
    "        is_photo.append(None)\n",
    "        with_person.append(None)\n",
    "        with_church.append(None)\n",
    "        \n",
    "        \n",
    "    \n",
    "    iter_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad0037-b6ff-4bf4-b0ac-bded14aa9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all response variable lists have the same length:\n",
    "print(len(img_ids))\n",
    "print(len(img_type))\n",
    "print(len(is_photo))\n",
    "print(len(with_person))\n",
    "print(len(with_church))\n",
    "print(len(img_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceecc2c0-78ec-45a3-b1b1-06a7bccb7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image list for closer inspection:\n",
    "img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4fbe5-a493-4d93-966b-d0c7635708d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           'is_photo_pred': is_photo,\n",
    "                           'with_person_pred': with_person,\n",
    "                           'with_church_pred': with_church})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05c4ef-a70a-4129-bc0a-325b8773a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffc372-43a2-4f15-bc30-a9a36f1fe4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['is_photo_pred'] = predictions['is_photo_pred'].astype('Int8')\n",
    "predictions['with_person_pred'] = predictions['with_person_pred'].astype('Int8')\n",
    "predictions['with_church_pred'] = predictions['with_church_pred'].astype('Int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a17dc-4c15-4d1a-b808-1dd7be6703d3",
   "metadata": {},
   "source": [
    "### Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33349e62-6be4-408a-8efc-103e2655948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f13dd6-b6b0-4f56-8d39-67e111df81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9757eb-dc00-426a-9e55-fc84d4b60495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b780c-ad23-401b-b196-cd4d724375c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d6907-4a42-4579-a485-287a8d1e2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a506aa-6ab6-4032-80a0-3d2281c55096",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_descr.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11722091-d337-4f05-b8d1-de0d57ea94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = list(image_descr.keys())\n",
    "keys_list[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4bee3-1474-4dab-8ae3-05bdd156d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_count = 0\n",
    "for key, item in image_descr.items():\n",
    "    print('\\n')\n",
    "    print(key)\n",
    "    print(item)\n",
    "    print(type(item))\n",
    "    print(item.keys())\n",
    "    iter_count += 1\n",
    "    if iter_count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb220234-43ec-43dd-b365-a755c307afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab89bda-4e9d-4b8e-aff4-2fbccc6a8112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528c6f8-ed22-49b6-8433-a1e89c8e4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee0c21-91d0-40fe-b77f-daded83b3e20",
   "metadata": {},
   "source": [
    "### Convert data type of added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf796c9-c32a-4e53-b692-00ea4bdbcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.astype({'is_photo_pred': 'Int8', 'with_person_pred': 'Int8',\n",
    "                       'with_church_pred': 'Int8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f0b68-52aa-4222-b304-19211ac5db75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb3f1e-6a28-4412-96d8-24b77fc0af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir_not_photo)\n",
    "print(output_dir_with_person)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e65ac1a-f2cb-4c58-9013-f79ca175f9dc",
   "metadata": {},
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14651d2-72f0-4b0a-a61d-73d4b0f282ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66e768-1f32-418b-9062-a6e59177582a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf9df5a-88f0-4de3-ae3c-dde8d4185905",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for person predictions and get lists images with positive person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fb8f9-2032-4908-8c66-1eebdddafb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.with_person == 1\n",
    "negative_bools = labels_results.with_person == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c95cb-6605-49d0-b3af-c3ff908641a7",
   "metadata": {},
   "source": [
    "### Inspect false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446b2d-4b55-4bef-8485-f2be100e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97701b27-b3b4-42b5-82a8-3745a0801373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4343ee97-be36-46cc-a187-222201fa544d",
   "metadata": {},
   "source": [
    "### Inspect false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f47b2-baed-4a59-8307-f8ca516b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caecd08-a314-436d-bf7b-2f4fa1b877d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a5ce9c5-7f8b-448c-86fd-49235436230a",
   "metadata": {},
   "source": [
    "## Repeat the same procedure but with nicer code (modularized):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee4f63-1bff-45b8-bade-a439d8be65da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d3f12-a7cb-4813-8478-7667417b4431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f360a-1233-4497-ab93-63964933c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'high alpine environment' # 1 if this appears to be in an high Alpine environment, 0 if not\n",
    "        'person': X,               # 1 if present, 0 if not\n",
    "        'glacier': X,              # 1 if present, 0 if not\n",
    "        'church': X,               # 1 if present, 0 if not\n",
    "        'water body': X.           # 1 if present, 0 if not\n",
    "        'other_objects': [],       # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''  # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3c66d-33c2-432e-b311-2ca3efcacccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9e19b-727f-4e98-becb-72e5f88fa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_img_type_multi_object():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photograph': X,     # True if the image is a photograph, False otherwise (if the image is a drawing, painting, statistics figure, map, scheme, other)\n",
    "        'high_alpine_environment': X, # True if this appears to be in an high Alpine environment, False if not\n",
    "        'person': X,                  # True if present, False if not\n",
    "        'glacier': X,                 # True if present, False if not\n",
    "        'church': X,                  # True if present, False if not\n",
    "        'water_body': X.              # True if present, False if not\n",
    "        'other_objects': [],          # List of other noteworthy/dominant objects\n",
    "        'additional_comments': ''     # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (present) or False (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9d99f-f5ec-4b10-bbe8-44c7a8204a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a759a92-8dae-4427-8ac1-83fb9fedbb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        #print('\\n')\n",
    "        #print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        #image_description = analyze_image_structured(image_path)\n",
    "        #image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt)\n",
    "        image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        #print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef110e9-87b0-48bc-a9d1-774aaa313721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration,\n",
    "                  timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['time_stamp_start'].append(timestamp_start_is_photo_analysis)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "\n",
    "    return time_analysis_dict, time_analysis_for_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a861a-b768-4223-8450-c7a9e27d23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb7511-461e-4dba-9ca3-a3ddbbd7755f",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca776a7b-b54a-4b4d-b4ba-096807da622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "prompt_func = create_prompt_img_type_multi_object\n",
    "prompt_template = prompt_func.__name__\n",
    "prompt_id = prompt_template + '_v1'\n",
    "prompt_text = prompt_func()\n",
    "# analysis_name = 'is_photo_struct_minicpm'\n",
    "\n",
    "\n",
    "keys_list_expected = ['image_is_photograph', 'high_alpine_environment', 'person', 'glacier',\n",
    "                      'church', 'water_body', 'other_objects', 'additional_comments']\n",
    "\n",
    "response_variable = 'image_is_photograph'\n",
    "\n",
    "# label_name = 'is_photo'\n",
    "# prediction_name = 'is_photo_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2af57f-5668-4472-8da0-4e8a45418c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f16fdffa-d7d4-4b9e-b49a-2d2186868a69",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11327511-75e1-4808-9799-fa54d51d49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "response_dictionaries = {}\n",
    "response_dictionaries[prompt_id] = {}\n",
    "\n",
    "images_closer_inspection = {}\n",
    "\n",
    "results_tabular = {}\n",
    "\n",
    "ml_metrics = pd.DataFrame({})\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_prompt_id = []\n",
    "ml_metrics_label_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff863f-7d98-45ae-96d8-6e2cfbf0f8aa",
   "metadata": {},
   "source": [
    "### Carry out LLM analysis of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27894156-b850-487e-ac03-dbcfadf5ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out the LLM analysis:\n",
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, prompt_func, model_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f54ba-216c-4559-b1c5-2ecdc0187f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate duration of analysis: \n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4708f-ef5d-4915-989b-647c29f12768",
   "metadata": {},
   "source": [
    "### Extract and organize information from the dictionary containing the LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a470f2f-27f0-4198-a359-c367bf31d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate duration of analysis: \n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "\n",
    "# Store information about duration of LLM task: \n",
    "time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                duration,timestamp_start_is_photo_analysis,\n",
    "                timestamp_end_is_photo_analysis)\n",
    "\n",
    "# Get timestamp_id as string from the time stamp:\n",
    "timestamp_id = timestamp_start_is_photo_analysis.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Store dictionary with LLM responses as raw data:\n",
    "response_dictionaries[prompt_id][timestamp_id] = image_descr\n",
    "\n",
    "# convert img_ids pandas series into list:\n",
    "img_ids_l = list(img_ids)\n",
    "\n",
    "# Prepare response variable names and label names to loop through:\n",
    "response_variables = ['image_is_photograph', 'person', 'church']\n",
    "label_names = ['is_photo', 'with_person', 'with_church']\n",
    "#analysis_names = ['is_photo_struct_minicpm', 'with_person_struct_minicpm', 'with_church_struct_minicpm']\n",
    "\n",
    "# Prepare dictionary for long term storing of results: \n",
    "results_tabular[timestamp_id] = {}\n",
    "results_tabular[timestamp_id]['prompt_id'] = prompt_id\n",
    "results_tabular[timestamp_id]['prompt_template'] = prompt_template\n",
    "results_tabular[timestamp_id]['prompt_text'] = prompt_text\n",
    "results_tabular[timestamp_id]['predictions'] = {}\n",
    "\n",
    "# Get copy of label data to merge with prediction for short term presentation of results:\n",
    "labels_results_i = label_data.copy()\n",
    "print('labels_results initial:')\n",
    "print(labels_results_i.shape)\n",
    "print(labels_results_i.columns)\n",
    "\n",
    "# Extract predictions for different response variables:\n",
    "for response_variable, label_name in zip(response_variables, label_names):\n",
    "    # set prediction name: \n",
    "    prediction_name = label_name + '_pred'\n",
    "    analysis_name = label_name + '_struct_minicpm'\n",
    "    print('\\n')\n",
    "    print('response_variable name and prediction_name:')\n",
    "    print(response_variable)\n",
    "    print(prediction_name)\n",
    "    img_ids, response_values, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids_l, image_descr, keys_list_expected, response_variable)\n",
    "\n",
    "    timestamp_ids = [timestamp_id] * len(img_ids_l)\n",
    "    \n",
    "    predictions = pd.DataFrame({'image_id': img_ids_l, \n",
    "                                   prediction_name: response_values})\n",
    "    predictions[prediction_name] = predictions[prediction_name].astype('Int8')\n",
    "    \n",
    "    print('predictions:')\n",
    "    print(predictions.shape)\n",
    "    print(predictions.columns)\n",
    "\n",
    "    results_tabular[timestamp_id]['predictions'][response_variable] = predictions\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    labels_results_i = labels_results_i.merge(predictions, how='inner', on='image_id')\n",
    "    print('\\n')\n",
    "    print('merged labels_results:')\n",
    "    print(labels_results_i.shape)\n",
    "    print(labels_results_i.columns)\n",
    "\n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_id] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_i, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_prompt_id.append(prompt_id)\n",
    "    ml_metrics_label_name.append(label_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "\n",
    "    ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "    ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "    ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "    ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "    ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "    ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "    ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "    ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "    ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "    ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "    ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "    \n",
    "    ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df44409-3380-4b50-b5bf-764ec64fcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca9152-b6e1-4e40-a8ab-1794b30a9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a7d1d-6395-416b-b97d-8e7eef87f90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe1289-3e20-4f5e-8a1b-15f2f1f4bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_m = label_data.copy()\n",
    "for key, item in results_tabular['20251023_115108']['predictions'].items():\n",
    "    print(key)\n",
    "    print(type(item))\n",
    "    \n",
    "    label_data_m = label_data_m.merge(item, how= 'inner', on='image_id')\n",
    "    print(label_data_m.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ac2b9-2f44-456f-a742-16308747602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1130760-a82a-4bbe-9b95-a831f7864f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e4725-7229-4dba-85c2-8aa610a4eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732c95d-a9c2-4534-8a7d-dc8a9531a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = labels_results_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993400b-a5ab-485c-aa5e-72e8b8cbf0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels_results.with_person_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8730e-e4a0-4a40-adc3-6349cf5cd12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aad1a9-12ae-487f-a392-61b807f290eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7eee77-ed3f-4b45-9a80-d00683db297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_is_photo_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811a02e-4032-4aa3-b544-060f8f39050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634b655-00a8-4f99-b043-ab7e466ff769",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c235d28-9598-40dd-b24f-b44d988a5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb47ed-34a3-4aa0-a577-b9e2de1015f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a814d6b-a039-432f-9f9a-79860b658aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = 'ml_metrics_struct_minicpm_' + timestamp_id + '.csv'\n",
    "ml_metrics_output_path = os.path.join(data_path, filename)\n",
    "\n",
    "# Save csv-file: \n",
    "ml_metrics.to_csv(ml_metrics_output_path, index=False)\n",
    "\n",
    "# Reload saved csv table to check if saving worked:\n",
    "ml_metrics_reloaded = pd.read_csv(ml_metrics_output_path)\n",
    "ml_metrics_reloaded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a92768-21f7-4a1b-8024-accc0eb30576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c01726-ee29-4a04-b845-952ba4d98e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f9a8d-cbc6-4981-9566-66fe1bae3060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d50e762-d8f3-45c0-8121-97b17b8256cd",
   "metadata": {},
   "source": [
    "## Save response dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f650657-660d-4a3d-8d94-2d697d97c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "filename = 'responses_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(response_dictionaries, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(image_descr))\n",
    "print(type(image_descr))\n",
    "print(type(reloaded_image_descr))\n",
    "print(len(reloaded_image_descr))\n",
    "\n",
    "print(image_descr.keys() == reloaded_image_descr.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92945cf-ec55-4f55-b355-762327dbebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloaded_image_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36a185-c2dc-43ac-b1fc-ddf8c230d843",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0e170-007a-4350-bf33-239d9000f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "results_file_name = 'results_tabular_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7d2d0-ccd5-438f-9068-f7f6ff01e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results_tabular.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ce576-0538-4023-92a5-a187340d0d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results_tabular['20251023_115108']['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0468d-a006-4537-b69d-491a5861b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results_tabular['20251023_115108']['predictions']['image_is_photograph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82088761-fbca-48e9-9869-7db99d1f5ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21111641-f963-42b0-acfe-77b3ba816c1d",
   "metadata": {},
   "source": [
    "## Calculate duration of analysis overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8432dad-27c3-4c7f-ab78-69e6dd5f36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_workflow = pd.Timestamp.now()\n",
    "timestamp_end_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf0454-0379-48f1-9aec-1c052492abb3",
   "metadata": {},
   "source": [
    "## Save time analyses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7339b-31cc-4a4e-9513-ccc335aa19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_df_file_name = 'times_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32c9b8-864a-4052-b9a7-b5ad497f5451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8727f23-55da-4627-86ef-01c2d4eb09de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b82ce-0fd9-4ea3-8846-c75c96dec3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c863e28-48b0-405d-9470-850211a145c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "label = 'with_person'\n",
    "prediction = 'with_person_pred'\n",
    "\n",
    "file_name = 'confusion_matrix' + '_with_person'\n",
    "\n",
    "save_path = data_path / file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc499b74-0942-451a-b78a-761766ff438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_o.save_conf_matrix(labels_results_i, label, prediction, cases, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014a7a7-ddaf-4294-a0f2-9f6bd464a28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9770308-cf30-46c9-9b0a-20166058c32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948f09a-aed8-49c9-a4f3-7e02f2a7190c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673922cb-2284-4bce-81eb-bccb11756b57",
   "metadata": {},
   "source": [
    "### Recalculate Measures with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d3f2b-92e3-49d8-9964-2d7996606dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.recognisable_label == 1\n",
    "negative_bools = labels_results.recognisable_label == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf4f0e-a299-4803-9443-59cb4a24dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d54e54-f787-4140-982c-0b9098dc6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c1c9f-a08f-47b5-ad0e-afbc45e03b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.recognisable_label, labels_results.with_person_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "#precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "#miss_rate = number_false_negatives / positives.shape[0]\n",
    "#f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "#print(f'Precision: {precision:.4f}')\n",
    "#print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "#print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb537157-cf48-4f53-8625-1013d2959129",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "#metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "#               f'True Positives: {number_true_positives}\\n'\n",
    "#               f'False Positives: {number_false_positives}\\n'\n",
    "#               f'True Negatives: {number_true_negatives}\\n'\n",
    "#               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "#               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "#               f'Specificity: {specificity:.4f}\\n'\n",
    "#               f'Precision: {precision:.4f}\\n'\n",
    "#               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "#               f'F1 Score: {f1_score:.4f}')\n",
    "\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Person Detection: Confusion Matrix and Performance Metrics Based on the Recognisable Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_recognisable.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10c00d4-45b8-46c9-bcde-6e22adc8d68f",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13d1fd-bbac-4998-954b-e7141c41d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.is_photo == 1\n",
    "negative_bools = labels_results.is_photo == 0\n",
    "positive_pred_bools = labels_results.is_photo_pred == 1\n",
    "negative_pred_bools = labels_results.is_photo_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5508e-8b60-4d77-99cd-e04e6959d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe379c24-9281-4a04-b4ad-0c9da9d47ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.is_photo, labels_results.is_photo_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d0a03-c8ad-48ad-a978-a9156958028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_is_photo.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9363e1-2c25-4d98-b6f7-45555bebd838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87f150-2f43-445f-86c0-85e2d294cfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e9918b-0295-408e-a986-ed2add02442a",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for church predictions and get lists images with positive church predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0c0b5-f2f9-492a-b44a-b9256264e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.church == 1\n",
    "negative_bools = labels_results.church == 0\n",
    "positive_pred_bools = labels_results.with_church_pred == 1\n",
    "negative_pred_bools = labels_results.with_church_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79b0f7-9834-4789-b46c-e5213b8a3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572eafb-a299-4148-b44e-c7f4c31c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.church, labels_results.with_church_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "#precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "#miss_rate = number_false_negatives / positives.shape[0]\n",
    "#f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "#print(f'Precision: {precision:.4f}')\n",
    "#print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "#print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f78d5-ac9f-464d-aa71-3324e65f1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "#metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "#               f'True Positives: {number_true_positives}\\n'\n",
    "#               f'False Positives: {number_false_positives}\\n'\n",
    "#               f'True Negatives: {number_true_negatives}\\n'\n",
    "#               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "#               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "#               f'Specificity: {specificity:.4f}\\n'\n",
    "#               f'Precision: {precision:.4f}\\n'\n",
    "#               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "#               f'F1 Score: {f1_score:.4f}')\n",
    "\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n')\n",
    "\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Church Detection: Confusion Matrix and Performance Metrics Based on the church Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "output_path = data_path / 'confusion_matrix_metrics_with_church.pdf'\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956596d-148e-47b1-8cf9-47b66a0a0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a0137-885b-4afd-b44b-27acdf383b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46c5c2-c63a-4d9a-b594-a4e383ff4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_curch_path = root_path / 'false_church_pred'\n",
    "church_false_positives_path = false_curch_path / 'false_positives'\n",
    "church_false_negatives_path = false_curch_path / 'false_negatives'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83c2d7-77da-4f2b-9e34-c49d6ce0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "church_false_positives_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933831cc-84a9-478d-880c-581a2c5015b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be landscape photographies: \n",
    "for idx, row in false_positives.iterrows():\n",
    "    print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.tif'\n",
    "    print(file_name)\n",
    "    source_path = tif_data_path / file_name\n",
    "    dest_path = church_false_positives_path / file_name\n",
    "    print(source_path)\n",
    "    print(dest_path)\n",
    "    shutil.copy(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9dd2-832f-40cb-ba90-3ed2aa1d4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be landscape photographies: \n",
    "for idx, row in false_negatives.iterrows():\n",
    "    print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.tif'\n",
    "    source_path = tif_data_path / file_name\n",
    "    dest_path = church_false_negatives_path / file_name\n",
    "    print(dest_path)\n",
    "    shutil.copy(source_path, dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba07bd-6049-4440-a879-6a2df6e620ed",
   "metadata": {},
   "source": [
    "### Visually inspect the images in the two folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88257e62-8e10-40ea-8570-e42f8110a574",
   "metadata": {},
   "source": [
    "Visually verified all classified images, false negatives are all images with non-recognisable persons (according to my judgement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbf1fb-af81-4867-8d66-5167dfb97585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3f1d-fd66-45f3-9105-7717b6a6aef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f451591-afbb-41d9-a3b2-d1be9914fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d305021-7cdd-46ef-8338-9af38927bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image ids that will remain string type even when saved to csv and reloaded:\n",
    "labels = list(labels_results.image_id)\n",
    "new_labels = img_idc.complete_image_ids(labels)\n",
    "labels_results['image_id_str'] = new_labels\n",
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = pd.Timestamp.now()\n",
    "current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438b057-f651-4cb8-b883-aad2eacd6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "current_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ab9b-b8c3-4020-806d-c6ba76fc2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_results.to_csv(data_path /'results_img_analysis_minicpm_2025.07.17.csv')\n",
    "results_file_name = 'results_img_analysis_minicpm_' + current_date_time + '.csv'\n",
    "labels_results.to_csv(data_path /results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
