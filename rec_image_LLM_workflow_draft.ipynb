{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "### Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3df59-367c-4815-a19a-3eca20fc3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def convert_tif_to_jpg(source_folder, destination_folder, quality=85):\n",
    "    \"\"\"\n",
    "    Convert .tif files to .jpg format and move copies to destination folder.\n",
    "    Original .tif files remain in source folder.\n",
    "    \n",
    "    Args:\n",
    "        source_folder (str): Path to folder containing .tif files\n",
    "        destination_folder (str): Path to destination folder for .jpg files\n",
    "        quality (int): JPEG quality (1-100, default 85)\n",
    "    \"\"\"\n",
    "    # Create destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    converted_files = []\n",
    "    \n",
    "    # Process all .tif files in source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.lower().endswith(('.tif', '.tiff')):\n",
    "            source_path = os.path.join(source_folder, filename)\n",
    "            \n",
    "            # Create new filename with .jpg extension\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            jpg_filename = f\"{base_name}.jpg\"\n",
    "            destination_path = os.path.join(destination_folder, jpg_filename)\n",
    "            \n",
    "            try:\n",
    "                # Open and convert image\n",
    "                with Image.open(source_path) as img:\n",
    "                    # Convert to RGB if necessary (TIFF might be in different modes)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    # Save as JPEG in destination folder\n",
    "                    img.save(destination_path, 'JPEG', quality=quality, optimize=True)\n",
    "                \n",
    "                converted_files.append(jpg_filename)\n",
    "                print(f\"Converted: {filename} -> {jpg_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully converted {len(converted_files)} files\")\n",
    "    return converted_files\n",
    "\n",
    "# Example usage:\n",
    "# convert_tif_to_jpg(\"/path/to/source\", \"/path/to/destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725db7-b5dd-4321-b3ed-b1d27142efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_image_if_needed(image_path):\n",
    "    \"\"\"Convert TIFF (and other unsupported formats) to JPG.\"\"\"\n",
    "    path = Path(image_path)\n",
    "    \n",
    "    if path.suffix.lower() in ['.tif', '.tiff']:\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Build new path manually\n",
    "            jpg_path = path.parent / f\"{path.stem}_converted.jpg\"\n",
    "            \n",
    "            img.save(jpg_path, 'JPEG', quality=95)\n",
    "            print(f\"Converted {path} to {jpg_path}\")\n",
    "            return str(jpg_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return str(path)\n",
    "\n",
    "\n",
    "def call_ollama_model(image_path, prompt):\n",
    "    \"\"\"Make the API call to Ollama.\"\"\"\n",
    "    # Convert image if needed\n",
    "    processed_path = convert_image_if_needed(image_path)\n",
    "    if processed_path is None:\n",
    "        raise ValueError(f\"Could not process image: {image_path}\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"minicpm-v\",  \n",
    "        messages=[{\n",
    "            'role': 'user', \n",
    "            'content': prompt,\n",
    "            'images': [processed_path]\n",
    "        }],\n",
    "        options={\n",
    "        'temperature': 0.1,  # Lower = more deterministic (0.0 to 1.0)\n",
    "        'seed': 42           # Fixed seed for reproducibility\n",
    "    }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89071635-bea1-4e18-a295-51974e8f8f09",
   "metadata": {},
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_type': [],  # List all that apply: photography, drawing, painting, statistics figure, map, scheme, other\n",
    "        'person': X,              # 1 if present, 0 if not\n",
    "        'mountain': X,            # 1 if present, 0 if not\n",
    "        'river': X,               # 1 if present, 0 if not\n",
    "        'lake': X,                # 1 if present, 0 if not\n",
    "        'building': X,            # 1 if present, 0 if not\n",
    "        'church': X,              # 1 if present, 0 if not\n",
    "        'city': X,                # 1 if present, 0 if not\n",
    "        'village': X,             # 1 if present, 0 if not\n",
    "        'glacier': X,             # 1 if present, 0 if not\n",
    "        'other_objects': [],      # List of other noteworthy/dominant objects\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with 1 (present) or 0 (not present).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7b508-a68d-4629-bfc3-871238892a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and determine if the image is an actual photography of a landscape or something else.\n",
    "    In this context anything that an individual may see when standing outside qualifies as landscape.\n",
    "    Please, return your answer in form of a Python dictionary in exactly this format:\n",
    "    {\n",
    "        'image_is_photography': X,  \n",
    "        'additional_comments': ''\n",
    "    }\n",
    "    Replace X, with True if the image is a photography of a landscape, replace X with False\n",
    "    if the image is not a photography of a landscape.\n",
    "    Between the single quotes next to 'additional_comments' you may enter any further comments\n",
    "    or explanations if you feel they are necessary. You may also not write anything between the\n",
    "    single quotes next to 'additional_comments' if you don't feel it is necessary. \n",
    "    \n",
    "    Return ONLY the dictionary as an answer, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d271ab-8183-41e0-b6ff-c175830a1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is a photography, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (image is not a photography).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578097bb-67ae-4f4b-b4b4-6e50b9c3ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f00ddd9-a107-47ae-af33-307c52f4866a",
   "metadata": {},
   "source": [
    "def parse_response_to_dict(response_text):\n",
    "    \"\"\"Parse the model response into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        dict_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if dict_match:\n",
    "            dict_str = dict_match.group()\n",
    "            dict_str = dict_str.replace('\\\\_', '_')\n",
    "            result_dict = ast.literal_eval(dict_str)\n",
    "            \n",
    "            # Add missing confidence scores if needed\n",
    "            objects = ['person', 'mountain', 'river', 'lake', 'building', \n",
    "                      'church', 'city', 'village', 'glacier']\n",
    "            \n",
    "            for obj in objects:\n",
    "                if obj in result_dict and f'{obj}_confidence' not in result_dict:\n",
    "                    # Add default confidence: 0.8 if present, 0.9 if absent\n",
    "                    result_dict[f'{obj}_confidence'] = 0.8 if result_dict[obj] == 1 else 0.9\n",
    "            \n",
    "            success = True\n",
    "        else:\n",
    "            result_dict = None\n",
    "            success = False\n",
    "    except Exception as e:\n",
    "        result_dict = None\n",
    "        success = False\n",
    "    \n",
    "    return success, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2585f-79c9-4456-a62d-e81fe711a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def parse_response_to_dict(response_text):\n",
    "    \"\"\"Parse the model response into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        # First try to find dictionary in code blocks\n",
    "        code_block_match = re.search(r'```(?:python)?\\s*(\\{.*?\\})\\s*```', response_text, re.DOTALL)\n",
    "        if code_block_match:\n",
    "            dict_str = code_block_match.group(1)\n",
    "        else:\n",
    "            # Fallback to finding any dictionary pattern\n",
    "            dict_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if dict_match:\n",
    "                dict_str = dict_match.group()\n",
    "            else:\n",
    "                return False, None\n",
    "        \n",
    "        # Clean up the dictionary string\n",
    "        dict_str = dict_str.replace('\\\\_', '_')\n",
    "        dict_str = dict_str.strip()\n",
    "        \n",
    "        # Parse the dictionary\n",
    "        result_dict = ast.literal_eval(dict_str)\n",
    "        return True, result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ee583-883d-4903-b45a-1f36b7b9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_structured(image_path):\n",
    "    \"\"\"Main function that orchestrates the image analysis.\"\"\"\n",
    "    # Define prompt for LLM model:\n",
    "    prompt = create_analysis_prompt()\n",
    "    # Ask LLM to analyse image, by calling the model and providing \n",
    "    # the defined prompt: \n",
    "    response_text = call_ollama_model(image_path, prompt)\n",
    "    # Parse response text, i.e. find dictionary of expected structure\n",
    "    # in the response text:\n",
    "    success, result_dict = parse_response_to_dict(response_text)\n",
    "    \n",
    "    if success:\n",
    "        return result_dict\n",
    "    else:\n",
    "        # Save response text in dictionary paired with key \"raw_response\"\n",
    "        # if parsing the response text fails:\n",
    "        llm_response = {\"raw_response\": response_text}\n",
    "        return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c57f3-8585-43d0-a1e6-e0d343cdef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_values(idx, labels_results, columns, values_to_add):\n",
    "    selection_bools = labels_results.image_id == inspection_idx\n",
    "    \n",
    "    labels_results.loc[selection_bools, columns] = values_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4ff24-c880-4984-ab11-ee89b7f83c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable): \n",
    "   #img_type = []\n",
    "   response_values = []\n",
    "   #with_person = []\n",
    "   #with_church = []\n",
    "   \n",
    "   # Make empty list to store responses that cannot be parsed\n",
    "   # due to faulty structure for closer inspection: \n",
    "   img_ids_closer_inspection = []\n",
    "   \n",
    "   iter_count = 0\n",
    "   \n",
    "   # Loop through image ids:\n",
    "   for img_id in img_ids:\n",
    "   \n",
    "       # Get response from LLM for image id in question:\n",
    "       img_pred = image_descr[img_id]\n",
    "   \n",
    "       # Get keys from response dictionary:\n",
    "       keys_list = list(img_pred.keys())\n",
    "   \n",
    "       # Check if structure and keys of response match expectation:\n",
    "       dict_struct_condition = (type(img_pred) == dict)\n",
    "       keys_condition = (keys_list_expected == keys_list)\n",
    "   \n",
    "       # Check if response key \n",
    "       raw_key_condition = keys_list == ['raw_response']\n",
    "       \n",
    "       # If the llm response corresponds to the expected\n",
    "       # structure, get response values as planned:\n",
    "       if dict_struct_condition and keys_condition:\n",
    "           \n",
    "           bool_value = img_pred[response_variable]\n",
    "   \n",
    "           if bool_value:\n",
    "               int_value = int(1)\n",
    "           else:\n",
    "               int_value = int(0)\n",
    "   \n",
    "           response_values.append(int_value)\n",
    "           \n",
    "       # If llm response does not correspond to the expected \n",
    "       # structure but does have the 'raw_response' key\n",
    "       # try to identify a dictionary inside the response text\n",
    "       # and try to parse this dictionary as planned:\n",
    "       elif dict_struct_condition and raw_key_condition:\n",
    "           print('\\n')\n",
    "           print('raw_repsonse_dict:')\n",
    "           print(img_id)\n",
    "           print(dict_struct_condition)\n",
    "           print(raw_key_condition)\n",
    "   \n",
    "           response_text = img_pred['raw_response']\n",
    "   \n",
    "           start_indices = [i for i, char in enumerate(response_text) if char == '{']\n",
    "           start_idx = start_indices[0]\n",
    "           \n",
    "           end_indices = [i for i, char in enumerate(response_text) if char == '}']\n",
    "           end_idx = end_indices[0]\n",
    "   \n",
    "           dict_in_text = response_text[start_idx:end_idx+1]\n",
    "   \n",
    "           success_bool, img_pred = parse_response_to_dict(dict_in_text)\n",
    "           print('success_bool:')\n",
    "           print(success_bool)\n",
    "   \n",
    "           # If a dictionary is found and parsed successfully\n",
    "           # get response values as planned:\n",
    "           if success_bool:\n",
    "               print(type(img_pred))\n",
    "               print(img_pred.keys())\n",
    "               \n",
    "               bool_value = img_pred[response_variable]\n",
    "       \n",
    "               if bool_value:\n",
    "                   int_value = int(1)\n",
    "               else:\n",
    "                   int_value = int(0)\n",
    "               \n",
    "               response_values.append(int_value)\n",
    "               \n",
    "           else:\n",
    "               # If dictionary is not found or not successfully\n",
    "               # parsed, add the image in question to the list\n",
    "               # of images for closer (visual) inspection:\n",
    "               print('parse unsuccessful')\n",
    "               print(img_id)\n",
    "               img_ids_closer_inspection.append(img_id)\n",
    "               response_values.append(None)\n",
    "   \n",
    "       # If the llm response does not have the expected struture\n",
    "       # and no 'raw_response' key is found, add the image in \n",
    "       # question to the list of images for closer (visual)\n",
    "       # inspection:\n",
    "       else:\n",
    "           print('\\n')\n",
    "           print('no structure at all:')\n",
    "           print(img_id)\n",
    "           img_ids_closer_inspection.append(img_id)\n",
    "           response_values.append(None)\n",
    "           \n",
    "       \n",
    "       iter_count += 1\n",
    "   return img_ids, response_values, img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100cdcc-aadc-4ee7-b1f2-b05f8a72e882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf63d5-4e16-42be-9921-6dadc4dc49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More comprehensive check including empty strings and whitespace\n",
    "def has_missing_comprehensive(df):\n",
    "   # Standard missing values\n",
    "   has_standard_missing = df.isnull().any().any()\n",
    "   \n",
    "   # Empty strings and whitespace-only strings\n",
    "   has_empty_strings = False\n",
    "   for col in df.select_dtypes(include=['object']):\n",
    "       if (df[col].astype(str).str.strip() == '').any():\n",
    "           has_empty_strings = True\n",
    "           break\n",
    "   \n",
    "   return has_standard_missing or has_empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb7c4d-86da-42d7-aac2-f2b9d870ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_subsets_metrics(labels_results, var_name, pred_var_name):\n",
    "    positive_bools = labels_results[var_name] == 1\n",
    "    negative_bools = labels_results[var_name] == 0\n",
    "    positive_pred_bools = labels_results[pred_var_name] == 1\n",
    "    negative_pred_bools = labels_results[pred_var_name] == 0\n",
    "    \n",
    "    positives = labels_results[positive_bools]\n",
    "    negatives = labels_results[negative_bools]\n",
    "    true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "    true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "    \n",
    "    false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "    false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "    sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "    print('sensitivity:')\n",
    "    print(sensitivity)\n",
    "    \n",
    "    specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "    print('specificity:')\n",
    "    print(specificity)\n",
    "\n",
    "    subsets_and_metrics = (positives, negatives, true_positives, true_negatives, \n",
    "                           false_negatives, false_positives, sensitivity, specificity)\n",
    "    \n",
    "    return subsets_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9006398-1f75-4e18-95ba-67d0f39f3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(labels_results, label, prediction, cases):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "    miss_rate = number_false_negatives / positives.shape[0]\n",
    "    f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                              [number_false_negatives, number_true_positives]]\n",
    "    sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'True Positives: {number_true_positives}')\n",
    "    print(f'False Positives: {number_false_positives}')\n",
    "    print(f'True Negatives: {number_true_negatives}')\n",
    "    print(f'False Negatives: {number_false_negatives}')\n",
    "    print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "    print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20297625-08fa-4b95-be19-5b4bb505e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_matrix(labels_results, label, prediction, cases):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "    miss_rate = number_false_negatives / positives.shape[0]\n",
    "    f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    \n",
    "    plt.subplot(gs[0])\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                             [number_false_negatives, number_true_positives]]\n",
    "    heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "               xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "               yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "               cbar_kws={'label': 'Number of Instances'})\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                   f'True Positives: {number_true_positives}\\n'\n",
    "                   f'False Positives: {number_false_positives}\\n'\n",
    "                   f'True Negatives: {number_true_negatives}\\n'\n",
    "                   f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                   f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                   f'Specificity: {specificity:.4f}\\n'\n",
    "                   f'Precision: {precision:.4f}\\n'\n",
    "                   f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "                   f'F1 Score: {f1_score:.4f}')\n",
    "    plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "            verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    output_path = data_path / 'confusion_matrix_metrics_is_photo.pdf'\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa5948-cd95-4df4-b522-6c2c2755d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee920e4-11db-411b-a702-4ac8c8b06616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6baecdaa-3eb8-4b84-a687-6d79a2b8dc6b",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fab53-b91f-4fc4-8034-d348a95a109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944fe6c-cbf4-44a5-9a60-2161ea174666",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for cases with unstructured answers for visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c71661-cc6a-4a0f-aec2-372111668756",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_closer_inspection = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dce6f-6efc-4190-8302-212c4840a5bf",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for result dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502d312-4363-420e-8ba2-4e897d9bd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "### Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d0ce-4b92-406a-86a3-115e9f210264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / '..' / 'test_LLM_workflow').resolve()\n",
    "#root_path = (project_path / '..' / 'test_yolo_object_train').resolve()\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6e136-ac5d-4691-b43d-4c1fc8c0a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6120ce4-87af-499c-b9d4-a5138e7016ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310d7c2-a030-4058-a7dc-7648f06dc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1f1fa-c987-4fe2-b55d-a8d9e6d325b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570215b-ddd7-45bb-99f5-adbbd6e80afe",
   "metadata": {},
   "source": [
    "### Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd239889-c0d0-4290-96bd-c0f6dcdad172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(tif_data_path, exist_ok=True)\n",
    "os.makedirs(jpg_data_path, exist_ok=True)\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f056-ba70-42e2-b65b-8a4f03de7e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32204a-0c76-46d2-ae33-d1b517769bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bd1c1-a1d1-4be9-9cd9-052b058d3576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0fea0f-6a59-46eb-b057-12cb5672d4b2",
   "metadata": {},
   "source": [
    "### Load person label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c7411-e309-4f9f-8051-63c7f4867514",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image.\n",
    " * Column church: whether the image contains a church.\n",
    " * Column is_photo: whether the image is a photography or something else. (this formulation is, of course, unprecise, as every dia can be called a photography of sorts, so, to be precise: whether or not the image is showing only a representation of a part of our world (painting, drawing, scheme etc, i.e. not a \"photography\") or is showing a part of our world that includes objects that are not representations (landscapes, buildings etc), where the latter qualifies as a \"photography\" and the former does not.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bba5d-201d-470c-95c1-578906246062",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6aa73-8348-4a71-9f83-b606e5107f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' \n",
    "# to ensure string data type to deal with duck typing): \n",
    "img_ids = list(label_data.image_id)\n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "930aa08f-6fff-4d06-9a9e-0351119a48f5",
   "metadata": {},
   "source": [
    "# Rename labels: \n",
    "label_data.rename(columns={'with_person': 'person_label', 'person_recognisable': 'recognisable_label'}, inplace=True)\n",
    "label_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cc27e-f350-4fd0-8d56-c2a28310e6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72cc5225-b73b-4cc3-a1d7-c9ab2cbea829",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e760fae-8f9c-45b6-8eeb-9b50fd715313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853a5ba-1fff-412b-8861-171e54e6fa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ed81b-81c2-4328-9252-7cd33e0befd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b7f0497-34ea-4903-8adf-43ac0f35cd0a",
   "metadata": {},
   "source": [
    "## Identify non-photo images and move them to a different directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bfce4-a523-4307-acc9-59960f2bc00e",
   "metadata": {},
   "source": [
    "### Adapt LLM prompt function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e95f7-c9e7-43d2-8a3a-49ec9c36422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is a photography, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (image is not a photography).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "### Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2855bbb-73c8-4249-9f1d-02751bc7b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'image_is_photography'\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'\n",
    "keys_list_expected = ['image_is_photography', 'additional_comments']\n",
    "response_variable = 'image_is_photography'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d699e4-32f5-4759-8ff3-56834cfad99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time stamp:\n",
    "timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "# Get list of image files to analyse: \n",
    "image_files = os.listdir(jpg_data_path)\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "\n",
    "# Make empty dictionary to store results:\n",
    "image_descr = {}\n",
    "\n",
    "# Loop through images to get answers: \n",
    "for image_file in image_files:\n",
    "    image_path = jpg_data_path / image_file\n",
    "    path_str = str(image_path)\n",
    "    print('\\n')\n",
    "    print(path_str)\n",
    "    parts = path_str.split('.jpg')\n",
    "    img_id = parts[-2][-3:]\n",
    "\n",
    "    # Analyse image, get values for each of the categorical variables specified above:\n",
    "    image_description = analyze_image_structured(image_path)\n",
    "    \n",
    "    dict_type_bool = type(image_description) == dict\n",
    "        \n",
    "    print(image_description)\n",
    "    image_descr[img_id] = image_description\n",
    "\n",
    "timestamp_end_is_photo_analysis = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449084d-9abe-427b-80a4-bef85d48fe92",
   "metadata": {},
   "source": [
    "### Get duration of the LLM analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e109289-a0ba-4fba-a09b-d9a6bfeac770",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ec90f-f92d-4a5f-952f-b3ac127608b1",
   "metadata": {},
   "source": [
    "### Check and save dictionary with LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6dc6be-3ace-4199-aa39-e583f1effd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = analysis_name + '_analysis_minicpm_' + date + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(image_descr, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(image_descr))\n",
    "print(type(image_descr))\n",
    "print(type(reloaded_image_descr))\n",
    "print(len(reloaded_image_descr))\n",
    "\n",
    "print(image_descr.keys() == reloaded_image_descr.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278339fe-7a9d-4144-8413-757a643e0069",
   "metadata": {},
   "source": [
    "### Loop through Responses from the LLM and incorporate them into a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460c64a-2acf-4620-9d8d-34866760b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "# Check if the response variable lists has the same length as id list:\n",
    "print(len(img_ids))\n",
    "print(len(is_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4fbe5-a493-4d93-966b-d0c7635708d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: is_photo})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44933e-3644-41c2-bea4-2000c060ab12",
   "metadata": {},
   "source": [
    "### Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccaa23-10a6-4208-9a0d-95f97a4e4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8f25a-13bf-42fd-a93d-2bcc733e45ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920a17dc-4c15-4d1a-b808-1dd7be6703d3",
   "metadata": {},
   "source": [
    "### Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33349e62-6be4-408a-8efc-103e2655948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b4b10-bfdc-4243-b02f-e390f4c40e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805842e1-c670-4adb-bfe5-f23f0efcf1a0",
   "metadata": {},
   "source": [
    "### Save labels and predictions in dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42157896-7f87-4c89-bbd2-b6764b52710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular[analysis_name] = labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202b7a5-c687-4769-9089-e6ec26528ae8",
   "metadata": {},
   "source": [
    "### Save image ids with unstructured answers for closer inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0202833-fc8b-4a17-9aae-fc0116d109d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22e366-f113-443b-86ce-31c5066bd019",
   "metadata": {},
   "source": [
    "### Move not-photography image files to output_dir_not_photo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419e431-a0af-4e97-a9a7-7dc2daac120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be photographies: \n",
    "for idx, row in labels_results.iterrows():\n",
    "    #print(idx)\n",
    "    img_id = row['image_id']\n",
    "    is_photo = row['is_photo_pred']\n",
    "    #print(is_photo)\n",
    "    file_name = 'BernerOberland' + img_id + '.jpg'\n",
    "    if int(is_photo) == 0:\n",
    "        source_path = jpg_data_path / file_name\n",
    "        dest_path = output_dir_not_photo / file_name\n",
    "        #print(dest_path)\n",
    "        shutil.move(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6de12-2111-4555-9064-7a3b685d910f",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf361c-6834-4dec-95b7-6715920a2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90099289-a13f-429d-baba-01b6086a9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2e7f5-fbc6-458b-9ed2-d3df59413482",
   "metadata": {},
   "source": [
    "### Plot and save convolution matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c2ace-4921-470d-b84f-1e06c2c1d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix(labels_results, label_name, prediction_name, cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecb046-3594-4651-9692-e8bda6c861e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a836ccda-aa80-484d-b4f5-826c48c8695d",
   "metadata": {},
   "source": [
    "## Identify images with persons and move them to a different directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f8e88-1a9c-44c6-aade-0333b6e5cab0",
   "metadata": {},
   "source": [
    "### Adapt LLM prompt function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895ab32-e54a-4c8a-bd04-879b29454c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_with_person': X,  # True if the image contains a person or persons, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image contains one or multiple persons) or False (image does not contain any person).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5e649-9c5e-4b8a-b0c5-44b9125cc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'with_person_analysis'\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_pred'\n",
    "keys_list_expected = ['image_with_person', 'additional_comments']\n",
    "response_variable = 'image_with_person'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f7be1-3702-49e7-b7c5-6bb35fa66857",
   "metadata": {},
   "source": [
    "### Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9babae-c3fc-4fa9-88ae-454f4b033dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files to analyse: \n",
    "timestamp_start_with_person_analysis = pd.Timestamp.now()\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "\n",
    "\n",
    "# Make empty dictionary to store results:\n",
    "image_descr = {}\n",
    "\n",
    "# Loop through images to get answers: \n",
    "for image_file in image_files:\n",
    "    image_path = jpg_data_path / image_file\n",
    "    path_str = str(image_path)\n",
    "    print('\\n')\n",
    "    print(path_str)\n",
    "    parts = path_str.split('.jpg')\n",
    "    img_id = parts[-2][-3:]\n",
    "\n",
    "    # Analyse image, get values for each of the categorical variables specified above:\n",
    "    image_description = analyze_image_structured(image_path)\n",
    "    \n",
    "    dict_type_bool = type(image_description) == dict\n",
    "        \n",
    "    print(image_description)\n",
    "    image_descr[img_id] = image_description\n",
    "\n",
    "timestamp_end_with_person_analysis = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd275a-aa7e-4a8f-b083-e3a697cd431c",
   "metadata": {},
   "source": [
    "### Get duration of the LLM analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ec708-8105-4140-8103-5659d4252f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = timestamp_end_with_person_analysis - timestamp_start_with_person_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "total_seconds = duration.total_seconds()\n",
    "print(f\"Analysis took: {duration}\")\n",
    "print(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "print(f\"Analysis took: {total_seconds/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b68ffa-421d-474c-84f0-e6599327e518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31602880-1993-457b-9400-8bf74e68e702",
   "metadata": {},
   "source": [
    "### Check and save dictionary with LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a5717-9dd0-4762-a0d6-3e3ee85be3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "date = str(timestamp_end_with_person_analysis).split('.')[0][0:10]\n",
    "filename = analysis_name + '_analysis_minicpm_' + date + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(image_descr, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6df9e-fc99-4d46-bd24-e650c0bb2ade",
   "metadata": {},
   "source": [
    "### Loop through Responses from the LLM and incorporate them into a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e9ef0-0bea-44f6-ad7f-afaa74af9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_ids, with_person, img_ids_closer_inspection = extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "print(len(img_ids))\n",
    "print(len(with_person))\n",
    "print(len(img_ids_closer_inspection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949646b-bf84-4fa8-ac59-42d2a5c33819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: with_person})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12f49c-98ef-4747-933e-0225f6aae150",
   "metadata": {},
   "source": [
    "### Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb3901-8083-4114-9063-947e047c0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04737f5b-156d-4387-af4f-09d771d0c001",
   "metadata": {},
   "source": [
    "### Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6d804-4ec4-4da1-8177-72ca9dd1971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ce3fa-887b-48c3-b987-480bbe1d7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d96a4-b3a7-4692-adc4-fc8afd243a20",
   "metadata": {},
   "source": [
    "### Save labels and predictions in dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b26d7-58f0-4b84-a9eb-553ca11eaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular[analysis_name] = labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86ac92-b36d-41ad-b7ed-4950bbc4dd34",
   "metadata": {},
   "source": [
    "### Save image ids with unstructured answers for closer inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96390bd1-d900-4467-8110-44721be6f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfc618-f84b-4e6b-91aa-c019b79ef98d",
   "metadata": {},
   "source": [
    "### Move files with persons to output_dir_with_person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78219cf-1331-44da-8f8c-c5f2eb1c685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move image files that predicted to not be photographies: \n",
    "for idx, row in labels_results.iterrows():\n",
    "    #print(idx)\n",
    "    img_id = row['image_id']\n",
    "    with_person = row[prediction_name]\n",
    "\n",
    "    file_name = 'BernerOberland' + img_id + '.jpg'\n",
    "    if np.isnan(with_person):\n",
    "        continue\n",
    "    elif int(with_person) == 1:\n",
    "        source_path = jpg_data_path / file_name\n",
    "        dest_path = output_dir_with_person / file_name\n",
    "        #print(dest_path)\n",
    "        shutil.move(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c192807-a52f-43ab-881d-5fa8cd9a0148",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc469b7-6b2a-4ee0-be71-2a1254605423",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba8138-0bc5-4768-928e-b4ac23ca6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374bf21-3385-467d-b43e-2aa0856e15f8",
   "metadata": {},
   "source": [
    "### Plot and save convolution matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6087a3-7552-4242-94a3-82668d49cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix(labels_results, label_name, prediction_name, cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34127dc0-6bb1-49a3-83b3-89cd6951a4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c49d5e1-5561-49c2-858f-1657898db42d",
   "metadata": {},
   "source": [
    "## Identify images with churches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6c7ee-7135-43e2-9163-0f894622b257",
   "metadata": {},
   "source": [
    "### Adapt promp function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae5ee5-2279-4c4c-8e5c-eb4628f2ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_with_church': X,  # True if the image contains a church or churches, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image contains one or multiple churches) or False (image does not contain any church).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf38f0-0ec2-4f23-9f9a-d558eb246117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07320ecf-5bf0-4bd8-8029-f4fc6ebfb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'with_church_analysis'\n",
    "label_name = 'church'\n",
    "prediction_name = 'with_church_pred'\n",
    "keys_list_expected = ['image_with_church', 'additional_comments']\n",
    "response_variable = 'image_with_church'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e72b2d-5ada-4280-b10f-b63a0d3a03ce",
   "metadata": {},
   "source": [
    "### Loop through images and analyze with miniCPM (LLM model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77542bc5-96e7-48fa-b2f5-115cdf8d7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files to analyse: \n",
    "timestamp_start_with_church_analysis = pd.Timestamp.now()\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "\n",
    "\n",
    "# Make empty dictionary to store results:\n",
    "image_descr = {}\n",
    "\n",
    "# Loop through images to get answers: \n",
    "for image_file in image_files:\n",
    "    image_path = jpg_data_path / image_file\n",
    "    path_str = str(image_path)\n",
    "    print('\\n')\n",
    "    print(path_str)\n",
    "    parts = path_str.split('.jpg')\n",
    "    img_id = parts[-2][-3:]\n",
    "\n",
    "    # Analyse image, get values for each of the categorical variables specified above:\n",
    "    image_description = analyze_image_structured(image_path)\n",
    "    \n",
    "    dict_type_bool = type(image_description) == dict\n",
    "        \n",
    "    print(image_description)\n",
    "    image_descr[img_id] = image_description\n",
    "\n",
    "timestamp_end_with_church_analysis = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125e8e16-8dfa-420a-be99-2f065fbdef60",
   "metadata": {},
   "source": [
    "### Get duration of the LLM analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d156a75-95dd-468e-b2dd-ecd8ba29286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = timestamp_end_with_church_analysis - timestamp_start_with_church_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "print(f\"Analysis took: {duration}\")\n",
    "print(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "print(f\"Analysis took: {total_seconds/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e4184-2fde-49c9-9ffa-a378ae8bb818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e1aee6-a01e-47af-ac8c-8bee3644851f",
   "metadata": {},
   "source": [
    "### Check and save dictionary with LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca1ab2-75b8-45ee-a0bb-8fdd6023745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = str(timestamp_end_with_church_analysis).split('.')[0][0:10]\n",
    "\n",
    "filename = analysis_name + '_analysis_minicpm_' + date + '.pkl'\n",
    "\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(image_descr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0aeab-42f5-4951-87ee-c5f3aae63a89",
   "metadata": {},
   "source": [
    "### Loop through Responses from the LLM and incorporate them into a Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd1d12-114d-4958-b568-22b7b9637b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_ids, with_person, img_ids_closer_inspection = extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "print(len(img_ids))\n",
    "print(len(with_person))\n",
    "print(len(img_ids_closer_inspection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43939905-85df-4a19-bf77-1c68d16de95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: with_person})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8a942-b2f0-4f86-9e18-8c5f72f317c1",
   "metadata": {},
   "source": [
    "### Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce35bb-f09c-480f-a44f-f1b973be45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f607017-2752-4f02-a55a-43df0884b7b3",
   "metadata": {},
   "source": [
    "### Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b034597-a925-49a2-8bb3-a6ccd6772ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e2141-80f9-4882-be83-bae8b25aa56e",
   "metadata": {},
   "source": [
    "### Save labels and predictions in dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb317d98-ce78-4404-a83d-1dcf9391a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular[analysis_name] = labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb6808-ccb7-49f9-b89c-2b41519e20f3",
   "metadata": {},
   "source": [
    "### Save image ids with unstructured answers for closer inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d26a1d-de45-4a7e-9f9e-44e87c36a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19065f-bda6-4589-bd44-bbba3e884fbd",
   "metadata": {},
   "source": [
    "### Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b8eb7-00ef-42b4-8575-899dc0a4c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383e95a-ed19-4aae-ad89-8224ec17a44c",
   "metadata": {},
   "source": [
    "### Plot and save convolution matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665945c3-b14d-4862-a8e0-c1da741e135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix(labels_results, label_name, prediction_name, cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909a36b-d04e-4a2f-9f25-71a7f270b1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6ee81-9aea-4edb-a3eb-d8772240022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ba07bd-6049-4440-a879-6a2df6e620ed",
   "metadata": {},
   "source": [
    "### Visually inspect the images in the two folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88257e62-8e10-40ea-8570-e42f8110a574",
   "metadata": {},
   "source": [
    "Visually verified all classified images, false negatives are all images with non-recognisable persons (according to my judgement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbf1fb-af81-4867-8d66-5167dfb97585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3f1d-fd66-45f3-9105-7717b6a6aef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_timestamp = pd.Timestamp.now()\n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "results_file_name = 'results_tabular_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8437c1e-cc8f-4cb7-99ae-de3f4bfb2ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9d2ac2-2eba-4d5a-a128-27c055043b46",
   "metadata": {},
   "source": [
    "## Calculate duration of analysis overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_workflow = pd.Timestamp.now()\n",
    "timestamp_end_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb31b9f-5004-413a-86f9-e492fd20c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = timestamp_end_workflow - timestamp_start_workflow\n",
    "total_seconds = duration.total_seconds()\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "print(f\"Analysis took: {duration}\")\n",
    "print(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "print(f\"Analysis took: {total_seconds/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e892f-cdf1-4e60-b9e7-8b73f992cb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d8c4bc-ec18-4a6d-b59a-2656f485274c",
   "metadata": {},
   "source": [
    "## Save time analyses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "time_analyses_file_name = 'time_analyses_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "time_analyses_output_path = os.path.join(data_path, time_analyses_file_name)\n",
    "with open(time_analyses_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses))\n",
    "print(type(time_analyses))\n",
    "print(type(reloaded_time_analyses))\n",
    "print(len(reloaded_time_analyses))\n",
    "\n",
    "print(time_analyses.keys() == reloaded_time_analyses.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "time_analyses_df_file_name = 'time_analyses_df_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
