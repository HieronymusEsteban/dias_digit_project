{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "from source import detect_persons_yolo as dpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76f7d8-548a-41d9-8893-9b199772d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad9cd2-eee5-44cf-a6dd-cee0115b112e",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e14a3-c84e-44ab-90a3-287d078b8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece681-2ea0-4de7-b84b-ec3e1f8ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9ff36-8849-4814-9d1b-99e39f0e6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "image_dir = root_path/\"../data\"  # Replace with your directory containing images\n",
    "output_dir_with_person = root_path/\"../with_person\"  # Replace with output directory for images with persons\n",
    "output_dir_without_person = root_path/\"../without_person\"  # Replace with output directory for images without persons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4d2f0-1a37-4ac0-89ff-75c9086e7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_dir)\n",
    "print(output_dir_with_person)\n",
    "print(output_dir_without_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea01b5-5273-4c33-bac4-65123ebc6102",
   "metadata": {},
   "source": [
    "## Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf52a5-56f8-4204-9e47-378e996472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "## Define the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80166cf-42cd-48d6-a5ea-074716419a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv5 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use yolov8n (nano) for faster inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3e0ce-6f84-4e7a-9001-14f6f4b49dfc",
   "metadata": {},
   "source": [
    "## Loop through images, sort them into the respective output folders according to person detection result and store results in list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a696001-b66f-4a55-be94-190f0b36acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ids, with_person = sif.sort_img_files(image_dir, model, output_dir_with_person, \n",
    "#                                           output_dir_without_person, threshold=0.25)\n",
    "#img_ids, with_person = sif.detect_persons_yolo(image_dir, model, output_dir_with_person, \n",
    "#                                         output_dir_without_person, threshold=0.25)\n",
    "\n",
    "img_ids, with_person = dpy.detect_persons_yolo(image_dir, model, threshold=0.25, file_format=\"tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c752b-e8b7-4661-b8dd-6392c57b98e8",
   "metadata": {},
   "source": [
    "## Load person predictions into a dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9109a-8ee8-49fc-86b4-2b67f56d1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_person = pd.DataFrame({'image_id': img_ids, 'with_person': with_person})\n",
    "results_person.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700135be-b2cc-43e0-be66-03eb03a48178",
   "metadata": {},
   "source": [
    "## Add one-hot-coded person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4984e3-c840-48d6-8067-cb2111ee34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_person['with_person_pred']= [1 if x else 0 for x in results_person.with_person]\n",
    "results_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b06fa-e711-4ebd-ab9f-3308c9a9a80e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc80c93-033f-4293-948a-525c30a15310",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b34c9-d185-4966-befd-a39a23e7ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = image_dir / 'BernerOberland043.tif'\n",
    "image_file_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeceed5c-3b7c-45ca-a3c1-af8b7449dbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f8e639f-5027-469f-b955-5e19b9a56976",
   "metadata": {},
   "source": [
    "## Load person label data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196c960-9bfd-4daa-8fca-48e0dc8347d8",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection. The labels thus represent the ground truth regarding to whether or not an image contains a person. The column with_person indicates whether a person or several persons are in the image, the columns recognisable indicates whether such person would be recognisable to a human familiar with the person in question based on their appearance (according to the jugdement of the author)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0c99d-5dea-446e-9c6c-a959f2fc5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_without_person = pd.read_csv(image_dir/'with_without_person_mod.csv')\n",
    "with_without_person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1695ee-5062-4bf5-ac14-29dcb9faf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = list(with_without_person.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba10d8-b24e-4008-809d-9ff18e4ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_without_person['image_id'] = img_idc.reconvert_image_ids(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd5a44-796e-4b2e-9c5a-c97ce035f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_without_person.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50265cce-896e-484c-8aab-0475c5c0e19a",
   "metadata": {},
   "source": [
    "## Rename the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a548af-66dc-43c5-a9db-129f101a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_without_person.rename(columns={'with_person': 'person_label', 'recognisable': 'recognisable_label'}, inplace=True)\n",
    "with_without_person.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a17dc-4c15-4d1a-b808-1dd7be6703d3",
   "metadata": {},
   "source": [
    "## Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33349e62-6be4-408a-8efc-103e2655948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = with_without_person.merge(results_person, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f13dd6-b6b0-4f56-8d39-67e111df81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9df5a-88f0-4de3-ae3c-dde8d4185905",
   "metadata": {},
   "source": [
    "## Calculate sensitivity and specificity for person predictions and get lists images with positive person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fb8f9-2032-4908-8c66-1eebdddafb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.person_label == 1\n",
    "negative_bools = labels_results.person_label == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c95cb-6605-49d0-b3af-c3ff908641a7",
   "metadata": {},
   "source": [
    "## Inspect false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446b2d-4b55-4bef-8485-f2be100e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709c677-04e4-4c3b-9593-c8c3810a0885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4343ee97-be36-46cc-a187-222201fa544d",
   "metadata": {},
   "source": [
    "## Inspect false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f47b2-baed-4a59-8307-f8ca516b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4153d-ea07-4df8-b8e5-faa36475b656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462523cd-d8ea-4808-9d66-e127feda0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df66e0c-3e88-4fa7-9983-7e908fb8ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0420ed9-de48-4153-8def-15ee30a3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.recognisable_label, labels_results.with_person_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad321902-18c9-4d50-9043-a43163ef4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Confusion Matrix and Performance Metrics Based on the Person Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_metrics_person.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b05b5f-e7a0-4389-957a-7947ff987434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6ee81-9aea-4edb-a3eb-d8772240022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673922cb-2284-4bce-81eb-bccb11756b57",
   "metadata": {},
   "source": [
    "## Recalculate Measures with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d3f2b-92e3-49d8-9964-2d7996606dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bools = labels_results.recognisable_label == 1\n",
    "negative_bools = labels_results.recognisable_label == 0\n",
    "positive_pred_bools = labels_results.with_person_pred == 1\n",
    "negative_pred_bools = labels_results.with_person_pred == 0\n",
    "\n",
    "positives = labels_results[positive_bools]\n",
    "negatives = labels_results[negative_bools]\n",
    "true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "\n",
    "false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "print('sensitivity:')\n",
    "print(sensitivity)\n",
    "\n",
    "specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "print('specificity:')\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d54e54-f787-4140-982c-0b9098dc6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c1c9f-a08f-47b5-ad0e-afbc45e03b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(labels_results.recognisable_label, labels_results.with_person_pred)\n",
    "\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "sensitivity = number_true_positives / positives.shape[0]\n",
    "specificity = number_true_negatives / negatives.shape[0]\n",
    "precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "miss_rate = number_false_negatives / positives.shape[0]\n",
    "f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                          [number_false_negatives, number_true_positives]]\n",
    "sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'True Positives: {number_true_positives}')\n",
    "print(f'False Positives: {number_false_positives}')\n",
    "print(f'True Negatives: {number_true_negatives}')\n",
    "print(f'False Negatives: {number_false_negatives}')\n",
    "print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb537157-cf48-4f53-8625-1013d2959129",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                         [number_false_negatives, number_true_positives]]\n",
    "heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "           xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "           yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "           cbar_kws={'label': 'Number of Instances'})\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.subplot(gs[1])\n",
    "plt.axis('off')\n",
    "metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "               f'True Positives: {number_true_positives}\\n'\n",
    "               f'False Positives: {number_false_positives}\\n'\n",
    "               f'True Negatives: {number_true_negatives}\\n'\n",
    "               f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "               f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "               f'Specificity: {specificity:.4f}\\n'\n",
    "               f'Precision: {precision:.4f}\\n'\n",
    "               f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "               f'F1 Score: {f1_score:.4f}')\n",
    "plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "        verticalalignment='center')\n",
    "\n",
    "plt.suptitle('Confusion Matrix and Performance Metrics Based on the Recognisable Label as Ground Truth', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_metrics_recognisable.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a4298-9f83-4fea-9179-d9ad4ea7d7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f33a36-295d-4458-9165-cc6e11fdfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_positives = labels_results[positive_pred_bools]\n",
    "pred_positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bda536-9d9f-4180-800b-ecf94a70c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_pos_pred = list(pred_positives.image_id)\n",
    "img_ids_pos_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0e8a5-d255-41bf-9f40-337a3254ec0a",
   "metadata": {},
   "source": [
    "## Move files to corresponding folders based on person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da622d-6c43-4994-85e4-d55bbbf841a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image_path in Path(image_dir).glob(\"*.tif\"):\n",
    "    #print(image_path)\n",
    "    path_str = str(image_path.resolve())\n",
    "    #print(path_str)\n",
    "    parts = path_str.split('.tif')\n",
    "    img_id = parts[-2][-3:]\n",
    "    #print(img_id)\n",
    "    #print(type(img_id))\n",
    "    parts = path_str.split('/')\n",
    "    filename = parts[-1]\n",
    "    #print(filename)\n",
    "    \n",
    "    \n",
    "    if img_id in img_ids_pos_pred:\n",
    "        file_path_origin = image_path\n",
    "        file_path_dest = os.path.join(output_dir_with_person, filename)\n",
    "        shutil.move(file_path_origin, file_path_dest)\n",
    "    else:\n",
    "        file_path_origin = image_path\n",
    "        file_path_dest = os.path.join(output_dir_without_person, filename)\n",
    "        shutil.move(file_path_origin, file_path_dest)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2868bb-2928-45ec-8721-868349bb85e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a831352-ec23-4eb3-bac8-edb5ad94e49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ba07bd-6049-4440-a879-6a2df6e620ed",
   "metadata": {},
   "source": [
    "## Visually inspect the images in the two folders!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88257e62-8e10-40ea-8570-e42f8110a574",
   "metadata": {},
   "source": [
    "Visually verified all classified images, false negatives are all images with non-recognisable persons (according to my judgement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbf1fb-af81-4867-8d66-5167dfb97585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32baff67-1cb5-4414-a715-591a507a6f84",
   "metadata": {},
   "source": [
    "## Check how many images have been moved to folder output_dir_with_person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40998e8f-4a68-4c16-b505-0a6ac5ac0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pred_with_person = [f for f in os.listdir(output_dir_with_person) if f.endswith('.tif')]\n",
    "#files_pred_with_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0df5f1-6e54-4e8c-a8fc-add914134241",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_pred_with_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0bf11-3eb4-4f0f-b7f7-8b51d52220a0",
   "metadata": {},
   "source": [
    "## Check how many images have been moved to folder output_dir_without_person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fe04e-7449-4cb7-ba92-b46475c1aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_pred_without_person = tif_files = [f for f in os.listdir(output_dir_without_person) if f.endswith('.tif')]\n",
    "#files_pred_without_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12817d6f-9a13-48e1-9298-413df23913dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_pred_without_person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f451591-afbb-41d9-a3b2-d1be9914fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d305021-7cdd-46ef-8338-9af38927bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image ids that will remain string type even when saved to csv and reloaded:\n",
    "labels = list(labels_results.image_id)\n",
    "new_labels = img_idc.complete_image_ids(labels)\n",
    "labels_results['image_id_str'] = new_labels\n",
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268a577-6522-4e06-96a2-81f32875fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9ee53-47e7-4ba3-bbab-3f7dcd588bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_select = ['image_id', 'person_label', 'recognisable_label', 'with_person_pred', 'image_id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8e612-4bc6-45c4-8306-df02cde9e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_to_store = labels_results[cols_to_select].copy()\n",
    "labels_results_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f353a1-894b-4f9a-9998-3bfd7cb33192",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_to_store.rename({'with_person_pred': 'prediction_with_person'}, axis='columns',\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06557fef-2f42-42d4-b2ef-a8d48870c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ab9b-b8c3-4020-806d-c6ba76fc2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_to_store.to_csv(image_dir/'results_people_detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
