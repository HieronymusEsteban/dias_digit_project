{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "### Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3df59-367c-4815-a19a-3eca20fc3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def convert_tif_to_jpg(source_folder, destination_folder, quality=85):\n",
    "    \"\"\"\n",
    "    Convert .tif files to .jpg format and move copies to destination folder.\n",
    "    Original .tif files remain in source folder.\n",
    "    \n",
    "    Args:\n",
    "        source_folder (str): Path to folder containing .tif files\n",
    "        destination_folder (str): Path to destination folder for .jpg files\n",
    "        quality (int): JPEG quality (1-100, default 85)\n",
    "    \"\"\"\n",
    "    # Create destination folder if it doesn't exist\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    converted_files = []\n",
    "    \n",
    "    # Process all .tif files in source folder\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.lower().endswith(('.tif', '.tiff')):\n",
    "            source_path = os.path.join(source_folder, filename)\n",
    "            \n",
    "            # Create new filename with .jpg extension\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            jpg_filename = f\"{base_name}.jpg\"\n",
    "            destination_path = os.path.join(destination_folder, jpg_filename)\n",
    "            \n",
    "            try:\n",
    "                # Open and convert image\n",
    "                with Image.open(source_path) as img:\n",
    "                    # Convert to RGB if necessary (TIFF might be in different modes)\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    \n",
    "                    # Save as JPEG in destination folder\n",
    "                    img.save(destination_path, 'JPEG', quality=quality, optimize=True)\n",
    "                \n",
    "                converted_files.append(jpg_filename)\n",
    "                print(f\"Converted: {filename} -> {jpg_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {filename}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully converted {len(converted_files)} files\")\n",
    "    return converted_files\n",
    "\n",
    "# Example usage:\n",
    "# convert_tif_to_jpg(\"/path/to/source\", \"/path/to/destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725db7-b5dd-4321-b3ed-b1d27142efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_image_if_needed(image_path):\n",
    "    \"\"\"Convert TIFF (and other unsupported formats) to JPG.\"\"\"\n",
    "    path = Path(image_path)\n",
    "    \n",
    "    if path.suffix.lower() in ['.tif', '.tiff']:\n",
    "        try:\n",
    "            img = Image.open(path)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Build new path manually\n",
    "            jpg_path = path.parent / f\"{path.stem}_converted.jpg\"\n",
    "            \n",
    "            img.save(jpg_path, 'JPEG', quality=95)\n",
    "            print(f\"Converted {path} to {jpg_path}\")\n",
    "            return str(jpg_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {path}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return str(path)\n",
    "\n",
    "\n",
    "def call_ollama_model(image_path, prompt):\n",
    "    \"\"\"Make the API call to Ollama.\"\"\"\n",
    "    # Convert image if needed\n",
    "    processed_path = convert_image_if_needed(image_path)\n",
    "    if processed_path is None:\n",
    "        raise ValueError(f\"Could not process image: {image_path}\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"minicpm-v\",  \n",
    "        messages=[{\n",
    "            'role': 'user', \n",
    "            'content': prompt,\n",
    "            'images': [processed_path]\n",
    "        }],\n",
    "        options={\n",
    "        'temperature': 0.1,  # Lower = more deterministic (0.0 to 1.0)\n",
    "        'seed': 42           # Fixed seed for reproducibility\n",
    "    }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578097bb-67ae-4f4b-b4b4-6e50b9c3ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2585f-79c9-4456-a62d-e81fe711a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def parse_response_to_dict(response_text):\n",
    "    \"\"\"Parse the model response into a Python dictionary.\"\"\"\n",
    "    try:\n",
    "        # First try to find dictionary in code blocks\n",
    "        code_block_match = re.search(r'```(?:python)?\\s*(\\{.*?\\})\\s*```', response_text, re.DOTALL)\n",
    "        if code_block_match:\n",
    "            dict_str = code_block_match.group(1)\n",
    "        else:\n",
    "            # Fallback to finding any dictionary pattern\n",
    "            dict_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "            if dict_match:\n",
    "                dict_str = dict_match.group()\n",
    "            else:\n",
    "                return False, None\n",
    "        \n",
    "        # Clean up the dictionary string\n",
    "        dict_str = dict_str.replace('\\\\_', '_')\n",
    "        dict_str = dict_str.strip()\n",
    "        \n",
    "        # Parse the dictionary\n",
    "        result_dict = ast.literal_eval(dict_str)\n",
    "        return True, result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ee583-883d-4903-b45a-1f36b7b9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_structured(image_path):\n",
    "    \"\"\"Main function that orchestrates the image analysis.\"\"\"\n",
    "    # Define prompt for LLM model:\n",
    "    prompt = create_analysis_prompt()\n",
    "    # Ask LLM to analyse image, by calling the model and providing \n",
    "    # the defined prompt: \n",
    "    response_text = call_ollama_model(image_path, prompt)\n",
    "    # Parse response text, i.e. find dictionary of expected structure\n",
    "    # in the response text:\n",
    "    success, result_dict = parse_response_to_dict(response_text)\n",
    "    \n",
    "    if success:\n",
    "        return result_dict\n",
    "    else:\n",
    "        # Save response text in dictionary paired with key \"raw_response\"\n",
    "        # if parsing the response text fails:\n",
    "        llm_response = {\"raw_response\": response_text}\n",
    "        return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc55be-dbc4-4461-9507-16853b656bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def first_word_is_yes_or_no(text):\n",
    "    \"\"\"\n",
    "    Check if the first word of a text is 'yes' or 'no' (case-insensitive).\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to check\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (bool, str or None) - (True if first word is 'yes' or 'no', the cleaned first word or None)\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return False, None\n",
    "    \n",
    "    first_token = text.strip().split()[0].lower()\n",
    "    \n",
    "    # Check if it starts with 'yes' or 'no' followed by punctuation\n",
    "    if re.match(r'^(yes|no)[.,!?;:\"()[\\]{}]', first_token):\n",
    "        answer = re.match(r'^(yes|no)', first_token).group(1)\n",
    "        return True, answer\n",
    "    \n",
    "    # Fallback to the original method for clean words\n",
    "    cleaned_word = re.sub(r'[^a-zA-Z]', '', first_token)\n",
    "    is_yes_or_no = cleaned_word in ['yes', 'no']\n",
    "    return is_yes_or_no, cleaned_word if is_yes_or_no else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd2246-432d-463f-8f01-48ed98b1aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yes_no_text(text):\n",
    "    \"\"\"\n",
    "    Parse text that may start with 'yes' or 'no' and return structured data.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to parse\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (bool, dict or None) - Success status and result dictionary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or not text.strip():\n",
    "            return False, None\n",
    "        \n",
    "        text = text.strip()\n",
    "        is_yes_or_no, first_word = first_word_is_yes_or_no(text)\n",
    "        \n",
    "        if is_yes_or_no:\n",
    "            return True, {'answer': first_word, 'additional_comments': text}\n",
    "        else:\n",
    "            return False, None\n",
    "    except Exception as e:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc4d62-f8e0-4ce9-9bf1-1446c7aecb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parse_yes_no_text(\"yes,e, no, ay\"))      # Should be None (correctly)\n",
    "print(parse_yes_no_text(\"yes, I agree\"))       # Should be 'yes' \n",
    "print(parse_yes_no_text(\"yes!\"))              # Should be 'yes'\n",
    "print(parse_yes_no_text(\"YES,\"))              # Should be 'yes'\n",
    "# Example usage:\n",
    "print(parse_yes_no_text(\"Yes, I completely agree with this\"))\n",
    "# {'answer': 'yes', 'additional_comments': 'Yes, I completely agree with this'}\n",
    "\n",
    "print(parse_yes_no_text(\"No problem at all\"))\n",
    "# {'answer': 'no', 'additional_comments': 'No problem at all'}\n",
    "\n",
    "print(parse_yes_no_text(\"Maybe we should consider this\"))\n",
    "# {'answer': None, 'additional_comments': 'Maybe we should consider this'}\n",
    "\n",
    "print(parse_yes_no_text(\"YES!\"))\n",
    "# {'answer': 'yes', 'additional_comments': 'YES!'}\n",
    "\n",
    "print(parse_yes_no_text(\"\"))\n",
    "# {'answer': None, 'additional_comments': ''}\n",
    "\n",
    "print(parse_yes_no_text(\",yesjaja\"))\n",
    "# {'answer': True, 'additional_comments': ',yesjaja'}\n",
    "\n",
    "print(parse_yes_no_text(\" no. jaja\"))\n",
    "\n",
    "print(parse_yes_no_text(\" kaki no, ay\"))\n",
    "\n",
    "print(parse_yes_no_text(\"yes,e, no, ay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb471d-bda2-42b5-aec1-b834f0a50314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9180e-a816-4918-9478-20405b4965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_yes_no(image_path):\n",
    "    \"\"\"Main function that orchestrates the image analysis.\"\"\"\n",
    "    # Define prompt for LLM model:\n",
    "    prompt = create_analysis_prompt()\n",
    "    # Ask LLM to analyse image, by calling the model and providing \n",
    "    # the defined prompt: \n",
    "    response_text = call_ollama_model(image_path, prompt)\n",
    "    # Parse response text:\n",
    "    success, result_dict = parse_yes_no_text(response_text)\n",
    "    \n",
    "    if success:\n",
    "        return result_dict\n",
    "    else:\n",
    "        # Save response text in dictionary paired with key \"raw_response\"\n",
    "        # if parsing the response text fails:\n",
    "        llm_response = {\"raw_response\": response_text}\n",
    "        return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fb3f1-c6af-4fda-8ad7-a271bc19c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '  yes kekeeaé lei'\n",
    "first_word = text.strip().split()[0].lower()\n",
    "first_word\n",
    "first_word in ['yes', 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514206e-71e8-450a-a637-238b6cd6dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c57f3-8585-43d0-a1e6-e0d343cdef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_values(idx, labels_results, columns, values_to_add):\n",
    "    selection_bools = labels_results.image_id == inspection_idx\n",
    "    \n",
    "    labels_results.loc[selection_bools, columns] = values_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4ff24-c880-4984-ab11-ee89b7f83c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, \n",
    "                                    response_variable): \n",
    "   #img_type = []\n",
    "   response_values = []\n",
    "   #with_person = []\n",
    "   #with_church = []\n",
    "   \n",
    "   # Make empty list to store responses that cannot be parsed\n",
    "   # due to faulty structure for closer inspection: \n",
    "   img_ids_closer_inspection = []\n",
    "   \n",
    "   iter_count = 0\n",
    "   \n",
    "   # Loop through image ids:\n",
    "   for img_id in img_ids:\n",
    "   \n",
    "       # Get response from LLM for image id in question:\n",
    "       img_pred = image_descr[img_id]\n",
    "   \n",
    "       # Get keys from response dictionary:\n",
    "       keys_list = list(img_pred.keys())\n",
    "   \n",
    "       # Check if structure and keys of response match expectation:\n",
    "       dict_struct_condition = (type(img_pred) == dict)\n",
    "       keys_condition = (keys_list_expected == keys_list)\n",
    "   \n",
    "       # Check if response key \n",
    "       raw_key_condition = keys_list == ['raw_response']\n",
    "       \n",
    "       # If the llm response corresponds to the expected\n",
    "       # structure, get response values as planned:\n",
    "       if dict_struct_condition and keys_condition:\n",
    "           \n",
    "           bool_value = img_pred[response_variable]\n",
    "   \n",
    "           if bool_value:\n",
    "               int_value = int(1)\n",
    "           else:\n",
    "               int_value = int(0)\n",
    "   \n",
    "           response_values.append(int_value)\n",
    "           \n",
    "       # If llm response does not correspond to the expected \n",
    "       # structure but does have the 'raw_response' key\n",
    "       # try to identify a dictionary inside the response text\n",
    "       # and try to parse this dictionary as planned:\n",
    "       elif dict_struct_condition and raw_key_condition:\n",
    "           print('\\n')\n",
    "           print('raw_repsonse_dict:')\n",
    "           print(img_id)\n",
    "           print(dict_struct_condition)\n",
    "           print(raw_key_condition)\n",
    "   \n",
    "           response_text = img_pred['raw_response']\n",
    "   \n",
    "           start_indices = [i for i, char in enumerate(response_text) if char == '{']\n",
    "           start_idx = start_indices[0]\n",
    "           \n",
    "           end_indices = [i for i, char in enumerate(response_text) if char == '}']\n",
    "           end_idx = end_indices[0]\n",
    "   \n",
    "           dict_in_text = response_text[start_idx:end_idx+1]\n",
    "   \n",
    "           success_bool, img_pred = parse_response_to_dict(dict_in_text)\n",
    "           print('success_bool:')\n",
    "           print(success_bool)\n",
    "   \n",
    "           # If a dictionary is found and parsed successfully\n",
    "           # get response values as planned:\n",
    "           if success_bool:\n",
    "               print(type(img_pred))\n",
    "               print(img_pred.keys())\n",
    "               \n",
    "               bool_value = img_pred[response_variable]\n",
    "       \n",
    "               if bool_value:\n",
    "                   int_value = int(1)\n",
    "               else:\n",
    "                   int_value = int(0)\n",
    "               \n",
    "               response_values.append(int_value)\n",
    "               \n",
    "           else:\n",
    "               # If dictionary is not found or not successfully\n",
    "               # parsed, add the image in question to the list\n",
    "               # of images for closer (visual) inspection:\n",
    "               print('parse unsuccessful')\n",
    "               print(img_id)\n",
    "               img_ids_closer_inspection.append(img_id)\n",
    "               response_values.append(None)\n",
    "   \n",
    "       # If the llm response does not have the expected struture\n",
    "       # and no 'raw_response' key is found, add the image in \n",
    "       # question to the list of images for closer (visual)\n",
    "       # inspection:\n",
    "       else:\n",
    "           print('\\n')\n",
    "           print('no structure at all:')\n",
    "           print(img_id)\n",
    "           img_ids_closer_inspection.append(img_id)\n",
    "           response_values.append(None)\n",
    "           \n",
    "       \n",
    "       iter_count += 1\n",
    "   return img_ids, response_values, img_ids_closer_inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100cdcc-aadc-4ee7-b1f2-b05f8a72e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vals_from_yes_no_response(img_ids, image_descr, keys_list_expected, \n",
    "                                    response_variable): \n",
    "   #img_type = []\n",
    "   response_values = []\n",
    "   #with_person = []\n",
    "   #with_church = []\n",
    "   \n",
    "   # Make empty list to store responses that cannot be parsed\n",
    "   # due to faulty structure for closer inspection: \n",
    "   img_ids_closer_inspection = []\n",
    "   \n",
    "   iter_count = 0\n",
    "   \n",
    "   # Loop through image ids:\n",
    "   for img_id in img_ids:\n",
    "   \n",
    "       # Get response from LLM for image id in question:\n",
    "       img_pred = image_descr[img_id]\n",
    "   \n",
    "       # Get keys from response dictionary:\n",
    "       keys_list = list(img_pred.keys())\n",
    "   \n",
    "       # Check if structure and keys of response match expectation:\n",
    "       dict_struct_condition = (type(img_pred) == dict)\n",
    "       keys_condition = (keys_list_expected == keys_list)\n",
    "   \n",
    "       # Check if response key \n",
    "       raw_key_condition = keys_list == ['raw_response']\n",
    "       \n",
    "       # If the llm response corresponds to the expected\n",
    "       # structure, get response values as planned:\n",
    "       if dict_struct_condition and keys_condition:\n",
    "           \n",
    "           response_val = img_pred[response_variable]\n",
    "   \n",
    "           if response_val == 'yes':\n",
    "               int_value = int(1)\n",
    "           else:\n",
    "               int_value = int(0)\n",
    "   \n",
    "           response_values.append(int_value)\n",
    "           \n",
    "       else:\n",
    "           print('\\n')\n",
    "           print('not expected structure:')\n",
    "           print(img_id)\n",
    "           img_ids_closer_inspection.append(img_id)\n",
    "           response_values.append(None)\n",
    "           \n",
    "       \n",
    "       iter_count += 1\n",
    "   return img_ids, response_values, img_ids_closer_inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e062740-b8c2-487e-8c38-3e873b9c787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf63d5-4e16-42be-9921-6dadc4dc49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More comprehensive check including empty strings and whitespace\n",
    "def has_missing_comprehensive(df):\n",
    "   # Standard missing values\n",
    "   has_standard_missing = df.isnull().any().any()\n",
    "   \n",
    "   # Empty strings and whitespace-only strings\n",
    "   has_empty_strings = False\n",
    "   for col in df.select_dtypes(include=['object']):\n",
    "       if (df[col].astype(str).str.strip() == '').any():\n",
    "           has_empty_strings = True\n",
    "           break\n",
    "   \n",
    "   return has_standard_missing or has_empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb7c4d-86da-42d7-aac2-f2b9d870ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_subsets_metrics(labels_results, var_name, pred_var_name):\n",
    "    positive_bools = labels_results[var_name] == 1\n",
    "    negative_bools = labels_results[var_name] == 0\n",
    "    positive_pred_bools = labels_results[pred_var_name] == 1\n",
    "    negative_pred_bools = labels_results[pred_var_name] == 0\n",
    "    \n",
    "    positives = labels_results[positive_bools]\n",
    "    negatives = labels_results[negative_bools]\n",
    "    true_positives = labels_results[positive_bools & positive_pred_bools]\n",
    "    true_negatives = labels_results[negative_bools & negative_pred_bools]\n",
    "    \n",
    "    false_negatives = labels_results[positive_bools & negative_pred_bools]\n",
    "    false_positives = labels_results[negative_bools & positive_pred_bools]\n",
    "\n",
    "    sensitivity = true_positives.shape[0] / positives.shape[0]\n",
    "    print('sensitivity:')\n",
    "    print(sensitivity)\n",
    "    \n",
    "    specificity = true_negatives.shape[0] / negatives.shape[0]\n",
    "    print('specificity:')\n",
    "    print(specificity)\n",
    "\n",
    "    subsets_and_metrics = (positives, negatives, true_positives, true_negatives, \n",
    "                           false_negatives, false_positives, sensitivity, specificity)\n",
    "    \n",
    "    return subsets_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9006398-1f75-4e18-95ba-67d0f39f3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(labels_results, label, prediction, cases):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    if (number_true_positives + number_false_positives) > 0:\n",
    "        precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    else:\n",
    "        precision = None\n",
    "        f1_score = None\n",
    "    if positives.shape[0] > 0:\n",
    "        miss_rate = number_false_negatives / positives.shape[0]\n",
    "    else:\n",
    "        miss_rate = None\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                              [number_false_negatives, number_true_positives]]\n",
    "    sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "                xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "                yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'True Positives: {number_true_positives}')\n",
    "    print(f'False Positives: {number_false_positives}')\n",
    "    print(f'True Negatives: {number_true_negatives}')\n",
    "    print(f'False Negatives: {number_false_negatives}')\n",
    "    print(f'\\nSensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    if precision is not None:\n",
    "        print(f'Precision: {precision:.4f}')\n",
    "        print(f'Miss Rate (False Negative Rate): {miss_rate:.4f}')\n",
    "        print(f'F1 Score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20297625-08fa-4b95-be19-5b4bb505e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_matrix(labels_results, label, prediction, cases):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "    miss_rate = number_false_negatives / positives.shape[0]\n",
    "    f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    \n",
    "    plt.subplot(gs[0])\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                             [number_false_negatives, number_true_positives]]\n",
    "    heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "               xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "               yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "               cbar_kws={'label': 'Number of Instances'})\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                   f'True Positives: {number_true_positives}\\n'\n",
    "                   f'False Positives: {number_false_positives}\\n'\n",
    "                   f'True Negatives: {number_true_negatives}\\n'\n",
    "                   f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                   f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                   f'Specificity: {specificity:.4f}\\n'\n",
    "                   f'Precision: {precision:.4f}\\n'\n",
    "                   f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "                   f'F1 Score: {f1_score:.4f}')\n",
    "    plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "            verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    output_path = data_path / 'conf_matrix_metrics.pdf'\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc1130-c8c9-41c9-a4a4-a24d09a13753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_matrix_tag(labels_results, label, prediction, cases, filename_tag):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    \n",
    "    if (number_true_positives + number_false_positives) > 0:\n",
    "        precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    else:\n",
    "        precision = None\n",
    "        f1_score = None\n",
    "        \n",
    "    if positives.shape[0] > 0:\n",
    "        miss_rate = number_false_negatives / positives.shape[0]\n",
    "    else:\n",
    "        miss_rate = None\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    \n",
    "    plt.subplot(gs[0])\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                             [number_false_negatives, number_true_positives]]\n",
    "    heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "               xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "               yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "               cbar_kws={'label': 'Number of Instances'})\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    if precision is not None:\n",
    "        metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                       f'True Positives: {number_true_positives}\\n'\n",
    "                       f'False Positives: {number_false_positives}\\n'\n",
    "                       f'True Negatives: {number_true_negatives}\\n'\n",
    "                       f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                       f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                       f'Specificity: {specificity:.4f}\\n'\n",
    "                       f'Precision: {precision:.4f}\\n'\n",
    "                       f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "                       f'F1 Score: {f1_score:.4f}')\n",
    "    else:\n",
    "        metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                       f'True Positives: {number_true_positives}\\n'\n",
    "                       f'False Positives: {number_false_positives}\\n'\n",
    "                       f'True Negatives: {number_true_negatives}\\n'\n",
    "                       f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                       f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                       f'Specificity: {specificity:.4f}\\n')\n",
    "        \n",
    "    plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "            verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    filename = 'conf_matrix_metrics_' + filename_tag + '.pdf'\n",
    "    output_path = data_path / filename\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa5948-cd95-4df4-b522-6c2c2755d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee920e4-11db-411b-a702-4ac8c8b06616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, analysis_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        print('\\n')\n",
    "        print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        image_description = analysis_function(image_path)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdf7cd-470d-4209-ae65-fa0e9a94b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6baecdaa-3eb8-4b84-a687-6d79a2b8dc6b",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fab53-b91f-4fc4-8034-d348a95a109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a948d-ff0a-47f6-b0d9-26a1b858b621",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary to store the different response dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d6356-c39e-4543-ab7a-904f9faf9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dictionaries = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944fe6c-cbf4-44a5-9a60-2161ea174666",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for cases with unstructured answers for visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c71661-cc6a-4a0f-aec2-372111668756",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_closer_inspection = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dce6f-6efc-4190-8302-212c4840a5bf",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for result dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502d312-4363-420e-8ba2-4e897d9bd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "### Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d0ce-4b92-406a-86a3-115e9f210264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / '..' / 'test_LLM_prompt_experiments').resolve()\n",
    "#root_path = (project_path / '..' / 'test_yolo_object_train').resolve()\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6e136-ac5d-4691-b43d-4c1fc8c0a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6120ce4-87af-499c-b9d4-a5138e7016ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310d7c2-a030-4058-a7dc-7648f06dc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1f1fa-c987-4fe2-b55d-a8d9e6d325b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570215b-ddd7-45bb-99f5-adbbd6e80afe",
   "metadata": {},
   "source": [
    "### Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd239889-c0d0-4290-96bd-c0f6dcdad172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "#os.chdir(root_path/'..')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(tif_data_path, exist_ok=True)\n",
    "os.makedirs(jpg_data_path, exist_ok=True)\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f056-ba70-42e2-b65b-8a4f03de7e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32204a-0c76-46d2-ae33-d1b517769bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bd1c1-a1d1-4be9-9cd9-052b058d3576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0fea0f-6a59-46eb-b057-12cb5672d4b2",
   "metadata": {},
   "source": [
    "### Load person label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c7411-e309-4f9f-8051-63c7f4867514",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image.\n",
    " * Column church: whether the image contains a church.\n",
    " * Column is_photo: whether the image is a photography or something else. (this formulation is, I guess, unprecise, as most dias can probably be called a photography of sorts (if a dia shows a painting, I assume a photograph of the painting has been taken), so, to be precise: whether or not the image is showing anything that exists in the real world or is showing a representation of anything that exists in the real world or aspects thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bba5d-201d-470c-95c1-578906246062",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6aa73-8348-4a71-9f83-b606e5107f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' \n",
    "# to ensure string data type to deal with duck typing): \n",
    "img_ids = list(label_data.image_id)\n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cc27e-f350-4fd0-8d56-c2a28310e6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72cc5225-b73b-4cc3-a1d7-c9ab2cbea829",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e760fae-8f9c-45b6-8eeb-9b50fd715313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853a5ba-1fff-412b-8861-171e54e6fa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747bfce4-a523-4307-acc9-59960f2bc00e",
   "metadata": {},
   "source": [
    "### Prepare variations of LLM prompt functions to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce2beb-05bf-4767-990b-f182518ab33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_yes_no_basic():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Is this image a photography or is it something else?\n",
    "\n",
    "    Please, answwer yes if it is a photography, answer no if it is something else.\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d8d08-2ea4-4815-ac7b-634fddc96eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_yes_no_precise():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Is this image a photography or is it something else?\n",
    "\n",
    "    Please, answwer yes if the image is a direct representation of something, no if it is an indirect representation (i.e. a representation of a representation of something).\n",
    "    \n",
    "    A representation can represent anything that exists or aspects thereof; the represantation can be concrete or abstract. \n",
    "    The image at hand can either be such a direct representation \n",
    "    or else a representation of a representation of anything that exists or of aspects thereof (concrete or abstract). \n",
    "    In other words, you have to determine if the image is a direct (answer yes) or an indirect representation (answer no).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7ddaf-fb89-4ce7-804b-799f1b5405c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_yes_no_intuitive():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Is this image a photography or is it something else (e.g. if the image is a map or a painting)?\n",
    "\n",
    "    Please, answwer yes if it is a photography, answer no if it is something else.\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cfce9-386f-438e-8fef-355fa110215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_yes_no_alternatives():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Is this image a photography or is it something else (map, a painting, a drawing, a scheme, a statistics figure, or other)?\n",
    "\n",
    "    Please, answwer yes if it is a photography, answer no if it is something else.\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd19d9-0463-44f9-8339-d7d65fb8b6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "805092b5-17dc-49b7-9987-3fc5355497cd",
   "metadata": {},
   "source": [
    "## Identify non-photo images with basic prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2855bbb-73c8-4249-9f1d-02751bc7b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'is_photo_basic_nat_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_yes_no_basic\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'\n",
    "keys_list_expected = ['answer', 'additional_comments']\n",
    "#response_variable = 'image_is_photography'\n",
    "response_variable = 'answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d23a0-8365-4ad3-a114-44ef6ca70316",
   "metadata": {},
   "source": [
    "### Run LLM image analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1acc7b-b828-41a8-b2fb-a5141b199acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, \\\n",
    "image_descr = analyse_giub_img_dir_llm(jpg_data_path, analyze_image_yes_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1e4f3-cfdc-4420-b994-7318bbe2a5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604e1ab0-04da-4656-bfa8-53ff56589e30",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460c64a-2acf-4620-9d8d-34866760b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration of the LLM analysis:\n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "\n",
    "# Store dictionary with LLM responses:\n",
    "response_dictionaries[analysis_name] = image_descr\n",
    "\n",
    "# Extract LLM responses from dictionary:\n",
    "img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "extract_vals_from_yes_no_response(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "# Check if the response variable lists has the same length as id list:\n",
    "print(len(img_ids))\n",
    "print(len(is_photo))\n",
    "\n",
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: is_photo})\n",
    "\n",
    "# Check for missing values:\n",
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))\n",
    "\n",
    "# Merge label data with the predictions:\n",
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "print(labels_results.shape)\n",
    "\n",
    "# Save labels and predictions in dictionary: \n",
    "results_tabular[analysis_name] = labels_results\n",
    "\n",
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection\n",
    "\n",
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "\n",
    "# Plot and save convolution matrix: \n",
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix_tag(labels_results, label_name, prediction_name, cases, analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4fbe5-a493-4d93-966b-d0c7635708d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dad657-2cbe-4da7-a384-3c6716d8a2aa",
   "metadata": {},
   "source": [
    "## Identify non-photo images with precise prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55c60e-57f4-434f-b46c-a006251e36f5",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e52242-17d4-4d05-8533-62b8c53d0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'is_photo_precise_nat_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_yes_no_precise\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'\n",
    "keys_list_expected = ['answer', 'additional_comments']\n",
    "#response_variable = 'image_is_photography'\n",
    "response_variable = 'answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16ace6-65f0-40db-9728-018b8c148775",
   "metadata": {},
   "source": [
    "### Run LLM image analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d6eb5-a83b-4c12-893b-8730aff7fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, \\\n",
    "image_descr = analyse_giub_img_dir_llm(jpg_data_path, analyze_image_yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fc964-218d-48a5-8a8a-d4034d0b87bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2212d2-febd-45ec-b3ce-7d82020e19de",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6ef7f-bf24-4b03-86de-2182a4c26c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration of the LLM analysis:\n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "\n",
    "# Store dictionary with LLM responses:\n",
    "response_dictionaries[analysis_name] = image_descr\n",
    "\n",
    "# Extract LLM responses from dictionary:\n",
    "img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "extract_vals_from_yes_no_response(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "# Check if the response variable lists has the same length as id list:\n",
    "print(len(img_ids))\n",
    "print(len(is_photo))\n",
    "\n",
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: is_photo})\n",
    "\n",
    "# Check for missing values:\n",
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))\n",
    "\n",
    "# Merge label data with the predictions:\n",
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "print(labels_results.shape)\n",
    "\n",
    "# Save labels and predictions in dictionary: \n",
    "results_tabular[analysis_name] = labels_results\n",
    "\n",
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection\n",
    "\n",
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "\n",
    "# Plot and save convolution matrix: \n",
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix_tag(labels_results, label_name, prediction_name, cases, analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05525549-b125-4c2c-ac77-6a767ace01d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3483a37-7ef4-4f30-9d23-ce3a632b8a22",
   "metadata": {},
   "source": [
    "## Identify non-photo images with intuitive prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2322d-096c-4334-af36-cb457c929aee",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1c3b5-5c1a-4d9c-a7e4-7f90d8a2b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_name = 'is_photo_intuitive_nat_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_yes_no_intuitive\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'\n",
    "keys_list_expected = ['answer', 'additional_comments']\n",
    "#response_variable = 'image_is_photography'\n",
    "response_variable = 'answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e542c92-06e5-421d-8375-9d205fa3ebd3",
   "metadata": {},
   "source": [
    "### Run LLM image analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0110c5a-e89e-42af-9bf3-5346947015fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, \\\n",
    "image_descr = analyse_giub_img_dir_llm(jpg_data_path, analyze_image_yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9172d7-c01f-4a56-b880-67036fbfbedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfbfe4cd-2f9a-4c5e-9aba-8985093516b3",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beede36-be3f-41d2-8632-546723bb5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration of the LLM analysis:\n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "\n",
    "# Store dictionary with LLM responses:\n",
    "response_dictionaries[analysis_name] = image_descr\n",
    "\n",
    "# Extract LLM responses from dictionary:\n",
    "img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "extract_vals_from_yes_no_response(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "# Check if the response variable lists has the same length as id list:\n",
    "print(len(img_ids))\n",
    "print(len(is_photo))\n",
    "\n",
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: is_photo})\n",
    "\n",
    "# Check for missing values:\n",
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))\n",
    "\n",
    "# Merge label data with the predictions:\n",
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "print(labels_results.shape)\n",
    "\n",
    "# Save labels and predictions in dictionary: \n",
    "results_tabular[analysis_name] = labels_results\n",
    "\n",
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection\n",
    "\n",
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "\n",
    "# Plot and save convolution matrix: \n",
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix_tag(labels_results, label_name, prediction_name, cases, analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0c75d-d603-48f4-8eef-28a4cf0781af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b589af-62f1-4f49-a24c-593bad8e31a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f274d0dc-d7a9-4685-9993-2585e6e7bbb5",
   "metadata": {},
   "source": [
    "## Identify non-photo images with alternatives prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c66709-dd66-40d1-81b8-9401d3475ed7",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013351ec-1dbd-42d4-a775-c75e973c9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis_name = 'is_photo_alternatives_nat_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_yes_no_alternatives\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'\n",
    "keys_list_expected = ['answer', 'additional_comments']\n",
    "#response_variable = 'image_is_photography'\n",
    "response_variable = 'answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d657f-35af-4150-93ce-30996aa3c7ca",
   "metadata": {},
   "source": [
    "### Run LLM image analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294bf3d-1214-4a6c-857e-8b1532679048",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, \\\n",
    "image_descr = analyse_giub_img_dir_llm(jpg_data_path, analyze_image_yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785bae1-fc97-4f7a-ac7a-2d062c558aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6de4ff6-1493-4d98-86e9-fd51c3c8b2ac",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0aa5c8-6539-42c8-8956-5aeec0cbf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get duration of the LLM analysis:\n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "\n",
    "\n",
    "# Store dictionary with LLM responses:\n",
    "response_dictionaries[analysis_name] = image_descr\n",
    "\n",
    "# Extract LLM responses from dictionary:\n",
    "img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "extract_vals_from_yes_no_response(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "# Check if the response variable lists has the same length as id list:\n",
    "print(len(img_ids))\n",
    "print(len(is_photo))\n",
    "\n",
    "# Put response variables into data frame: \n",
    "predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                           prediction_name: is_photo})\n",
    "\n",
    "# Check for missing values:\n",
    "print(predictions.isnull().any().any())\n",
    "print(predictions.isna().any().any())\n",
    "print(has_missing_comprehensive(predictions))\n",
    "\n",
    "# Merge label data with the predictions:\n",
    "labels_results = label_data.merge(predictions, how='inner', on='image_id')\n",
    "print(labels_results.shape)\n",
    "\n",
    "# Save labels and predictions in dictionary: \n",
    "results_tabular[analysis_name] = labels_results\n",
    "\n",
    "# Save image list for closer inspection:\n",
    "images_closer_inspection[analysis_name] = img_ids_closer_inspection\n",
    "\n",
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "print(f'True Positives: {true_positives.shape[0]}')\n",
    "print(f'False Positives: {false_positives.shape[0]}')\n",
    "print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "\n",
    "# Plot and save convolution matrix: \n",
    "cases = (true_positives, false_positives, true_negatives, false_negatives, positives, negatives)\n",
    "plot_conf_matrix(labels_results, label_name, prediction_name, cases)\n",
    "save_conf_matrix_tag(labels_results, label_name, prediction_name, cases, analysis_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb651a84-1396-4b16-ada6-7e07ef0cd1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9afc8-5a62-48d9-9eeb-709daa069398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d3ac3-f2df-4d8d-9aed-e5c149f42c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4485f-09c0-4edd-bbc8-673b5eb17a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa7fb15e-d347-4871-b060-6007962e4548",
   "metadata": {},
   "source": [
    "## Save response dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3f1d-fd66-45f3-9105-7717b6a6aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = 'results_prompt_exp_nat_minicpm_' + date + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(response_dictionaries, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(image_descr))\n",
    "print(type(image_descr))\n",
    "print(type(reloaded_image_descr))\n",
    "print(len(reloaded_image_descr))\n",
    "\n",
    "print(image_descr.keys() == reloaded_image_descr.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_timestamp = pd.Timestamp.now()\n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "results_file_name = 'results_table_prompt_exp_nat_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8437c1e-cc8f-4cb7-99ae-de3f4bfb2ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9d2ac2-2eba-4d5a-a128-27c055043b46",
   "metadata": {},
   "source": [
    "## Calculate duration of analysis overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_workflow = pd.Timestamp.now()\n",
    "timestamp_end_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb31b9f-5004-413a-86f9-e492fd20c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = timestamp_end_workflow - timestamp_start_workflow\n",
    "total_seconds = duration.total_seconds()\n",
    "store_duration(time_analyses, time_analyses_for_df, analysis_name, duration)\n",
    "print(f\"Analysis took: {duration}\")\n",
    "print(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "print(f\"Analysis took: {total_seconds/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e892f-cdf1-4e60-b9e7-8b73f992cb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93d8c4bc-ec18-4a6d-b59a-2656f485274c",
   "metadata": {},
   "source": [
    "## Save time analyses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "time_analyses_file_name = 'times_prompt_exp_nat_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "time_analyses_output_path = os.path.join(data_path, time_analyses_file_name)\n",
    "with open(time_analyses_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses))\n",
    "print(type(time_analyses))\n",
    "print(type(reloaded_time_analyses))\n",
    "print(len(reloaded_time_analyses))\n",
    "\n",
    "print(time_analyses.keys() == reloaded_time_analyses.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "time_analyses_df_file_name = 'times_df_prompt_exp_nat_minicpm_' + current_date_time + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
