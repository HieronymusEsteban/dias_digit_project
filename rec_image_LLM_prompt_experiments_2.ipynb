{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "from source import llm_input as llm_i\n",
    "from source import llm_output as llm_o\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38edd-bef0-48c4-84c5-8c89603d07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bea40-b27c-431f-84d2-40c986b376eb",
   "metadata": {},
   "source": [
    "# Using LLM (mini-CPM) for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8419f-b468-417d-963b-e80799c4f034",
   "metadata": {},
   "source": [
    "### Define Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d271ab-8183-41e0-b6ff-c175830a1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is a photography, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (image is not a photography).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578097bb-67ae-4f4b-b4b4-6e50b9c3ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fb3f1-c6af-4fda-8ad7-a271bc19c6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ff193-0a60-4050-a286-d8e004156fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More comprehensive check including empty strings and whitespace\n",
    "def has_missing_comprehensive(df):\n",
    "   # Standard missing values\n",
    "   has_standard_missing = df.isnull().any().any()\n",
    "   \n",
    "   # Empty strings and whitespace-only strings\n",
    "   has_empty_strings = False\n",
    "   for col in df.select_dtypes(include=['object']):\n",
    "       if (df[col].astype(str).str.strip() == '').any():\n",
    "           has_empty_strings = True\n",
    "           break\n",
    "   \n",
    "   return has_standard_missing or has_empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc1130-c8c9-41c9-a4a4-a24d09a13753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_matrix_tag(labels_results, label, prediction, cases, filename_tag):\n",
    "    true_positives, false_positives, true_negatives, false_negatives, positives, negatives = cases\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(labels_results[label], labels_results[prediction])\n",
    "    \n",
    "    number_true_positives = true_positives.shape[0]\n",
    "    number_false_positives = false_positives.shape[0]\n",
    "    number_true_negatives = true_negatives.shape[0]\n",
    "    number_false_negatives = false_negatives.shape[0]\n",
    "    \n",
    "    sensitivity = number_true_positives / positives.shape[0]\n",
    "    specificity = number_true_negatives / negatives.shape[0]\n",
    "    \n",
    "    if (number_true_positives > 0) and (number_false_positives > 0):\n",
    "        precision = number_true_positives / (number_true_positives + number_false_positives)\n",
    "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity)\n",
    "    else:\n",
    "        precision = None\n",
    "        f1_score = None\n",
    "        \n",
    "    if positives.shape[0] > 0:\n",
    "        miss_rate = number_false_negatives / positives.shape[0]\n",
    "    else:\n",
    "        miss_rate = None\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    \n",
    "    plt.subplot(gs[0])\n",
    "    confusion_matrix_data = [[number_true_negatives, number_false_positives], \n",
    "                             [number_false_negatives, number_true_positives]]\n",
    "    heatmap = sns.heatmap(confusion_matrix_data, annot=True, fmt='d', \n",
    "               xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "               yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "               cbar_kws={'label': 'Number of Instances'})\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    plt.subplot(gs[1])\n",
    "    plt.axis('off')\n",
    "    if precision is not None:\n",
    "        metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                       f'True Positives: {number_true_positives}\\n'\n",
    "                       f'False Positives: {number_false_positives}\\n'\n",
    "                       f'True Negatives: {number_true_negatives}\\n'\n",
    "                       f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                       f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                       f'Specificity: {specificity:.4f}\\n'\n",
    "                       f'Precision: {precision:.4f}\\n'\n",
    "                       f'Miss Rate: {miss_rate:.4f}\\n'\n",
    "                       f'F1 Score: {f1_score:.4f}')\n",
    "    else:\n",
    "        metrics_text = (f'Performance Metrics:\\n\\n'\n",
    "                       f'True Positives: {number_true_positives}\\n'\n",
    "                       f'False Positives: {number_false_positives}\\n'\n",
    "                       f'True Negatives: {number_true_negatives}\\n'\n",
    "                       f'False Negatives: {number_false_negatives}\\n\\n'\n",
    "                       f'Sensitivity: {sensitivity:.4f}\\n'\n",
    "                       f'Specificity: {specificity:.4f}\\n')\n",
    "        \n",
    "    plt.text(0, 0.5, metrics_text, fontsize=10, \n",
    "            verticalalignment='center')\n",
    "    \n",
    "    plt.suptitle('Photography Detection: Confusion Matrix and Performance Metrics Based on is_photo Label as Ground Truth', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    filename = 'conf_matrix_metrics_' + filename_tag + '.pdf'\n",
    "    output_path = data_path / filename\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa5948-cd95-4df4-b522-6c2c2755d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration,\n",
    "                  timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['time_stamp_start'].append(timestamp_start_is_photo_analysis)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "\n",
    "    return time_analysis_dict, time_analysis_for_df_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdf7cd-470d-4209-ae65-fa0e9a94b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d0fb9-1f20-481c-aa15-a1c7880085c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        #print('\\n')\n",
    "        #print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        #image_description = analyze_image_structured(image_path)\n",
    "        #image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt)\n",
    "        image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        #print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f143f-1580-43b2-ba12-475406077535",
   "metadata": {},
   "source": [
    "### Choose LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ef353-6f6e-4c70-94e0-11a7dcb80fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = llm_i.call_minicpm_model\n",
    "#model_function = llm_i.call_ollama_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baecdaa-3eb8-4b84-a687-6d79a2b8dc6b",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fab53-b91f-4fc4-8034-d348a95a109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['time_stamp_start'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1561ab0-c707-484c-95aa-07167bbc7071",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary to store the different response dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c887dc3-3539-401d-97dc-cac715393e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dictionaries = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944fe6c-cbf4-44a5-9a60-2161ea174666",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for cases with unstructured answers for visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c71661-cc6a-4a0f-aec2-372111668756",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_closer_inspection = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dce6f-6efc-4190-8302-212c4840a5bf",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for result dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502d312-4363-420e-8ba2-4e897d9bd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03821616-748e-4682-ab50-be308265de7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae6972-e011-4dc6-beb7-136a3a7511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics = pd.DataFrame({'positives': [],\n",
    "              'negatives': [], \n",
    "              'true_positives': [], \n",
    "              'true_negatives': [],\n",
    "              'false_negatives': [], \n",
    "              'false_positives': [], \n",
    "              'sensitivity': [], \n",
    "              'specificity': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585626b0-743e-49a1-b0a5-ce2dc292831c",
   "metadata": {},
   "source": [
    "### Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d135728-ea08-4ebb-87e7-582b5384a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project')\n",
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/test_yolo_object_train')\n",
    "\n",
    "project_path = Path.cwd()\n",
    "root_path = (project_path / 'test_LLM_prompt_experiments').resolve()\n",
    "#root_path = project_path\n",
    "data_path = root_path / 'data'\n",
    "tif_data_path = root_path / 'data_1'\n",
    "#data_path = root_path / 'visual_genome_data_all'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "#yolo_path = root_path / 'visual_genome_yolo_all'\n",
    "output_dir_not_photo = root_path / 'not_photo'\n",
    "output_dir_with_person = root_path / 'with_person'\n",
    "output_dir_without_person = root_path / 'without_person'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570215b-ddd7-45bb-99f5-adbbd6e80afe",
   "metadata": {},
   "source": [
    "### Create directories for sorting the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdd789-34e4-46f1-ac88-427c49866d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(tif_data_path, exist_ok=True)\n",
    "os.makedirs(jpg_data_path, exist_ok=True)\n",
    "os.makedirs(output_dir_not_photo, exist_ok=True)\n",
    "os.makedirs(output_dir_with_person, exist_ok=True)\n",
    "os.makedirs(output_dir_without_person, exist_ok=True)\n",
    "#os.chdir('root_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5f056-ba70-42e2-b65b-8a4f03de7e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c2fe3ae-d0e8-4101-b740-fde42409b7aa",
   "metadata": {},
   "source": [
    "### Copy and convert image files from tif_data_path to jpg_data_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32204a-0c76-46d2-ae33-d1b517769bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "llm_i.convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bd1c1-a1d1-4be9-9cd9-052b058d3576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0fea0f-6a59-46eb-b057-12cb5672d4b2",
   "metadata": {},
   "source": [
    "### Load person label data (ground truth) to compare to LLM responses:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c7411-e309-4f9f-8051-63c7f4867514",
   "metadata": {},
   "source": [
    "The file with_without_person.csv contains labels added by (human) visual inspection that represent the ground truth. \n",
    " * Column with_person: whether or not any person is in the image.\n",
    " * Column recognisable: whether any person that would be recognisable to a human familiar with said person is in the image.\n",
    " * Column church: whether the image contains a church.\n",
    " * Column is_photo: whether the image is a photography or something else. (this formulation is, I guess, unprecise, as most dias can probably be called a photography of sorts (if a dia shows a painting, I assume a photograph of the painting has been taken), so, to be precise: whether or not the image is showing anything that exists in the real world or is showing a representation of anything that exists in the real world or aspects thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bba5d-201d-470c-95c1-578906246062",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6aa73-8348-4a71-9f83-b606e5107f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' \n",
    "# to ensure string data type to deal with duck typing): \n",
    "img_ids = list(label_data.image_id)\n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc5225-b73b-4cc3-a1d7-c9ab2cbea829",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e760fae-8f9c-45b6-8eeb-9b50fd715313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Find all .ipynb_checkpoints directories\n",
    "for checkpoint_dir in jpg_data_path.rglob('.ipynb_checkpoints'):\n",
    "    if checkpoint_dir.is_dir():\n",
    "        print(f\"Removing: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "#image_files.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81653ad4-a42c-4677-95bb-f7e15325fa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747bfce4-a523-4307-acc9-59960f2bc00e",
   "metadata": {},
   "source": [
    "### Prepare variations of LLM prompt functions to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e95f7-c9e7-43d2-8a3a-49ec9c36422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_basic():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is a photography, False otherwise\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (image is not a photography).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d062470-b460-442a-a400-136a5f86ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_precise():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_of_image': X,  # True if the image is a direct representation of something, False if it is an indirect representation (i.e. a representation of a representation of something).\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (direct representation) or False (indirect representation).\n",
    "    A representation can represent anything that exists or aspects thereof; the represantation can be concrete or abstract. \n",
    "    The image at hand can either be such a direct representation \n",
    "    or else a representation of a representation of anything that exists or of aspects thereof (concrete or abstract). \n",
    "    In other words, you have to determine if the image is a direct (Replace X with True) or an indirect representation (Replace X with False).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecbb64-5046-4049-a284-555549e0fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_intuitive():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is photography, False otherwise (e.g. if the image is a map or a painting)\n",
    "        'additional_comments': '' # Any additional observations or empty string if none\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (otherwise).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad15425-0a43-4c94-9714-6f684288e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_alternatives():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'image_is_photography': X,  # True if the image is photography, False if image is a map, a painting, a drawing, a scheme, a statistics figure, or other.\n",
    "        'additional_comments': '' # Any additional observations or empty string if none.\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image is a photography) or False (image is a map, a painting, a drawing, a scheme, a statistics figure, or other).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e11d20-e37f-4888-9903-04025bd0f384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93dad657-2cbe-4da7-a384-3c6716d8a2aa",
   "metadata": {},
   "source": [
    "## Identify non-photo images with basic prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55c60e-57f4-434f-b46c-a006251e36f5",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6489666-7024-477e-97b6-f54cc5c2b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'is_photo_basic_struct_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_basic\n",
    "keys_list_expected = ['image_is_photography', 'additional_comments']\n",
    "response_variable = 'image_is_photography'\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcfc45-b347-4bd4-8eb4-139fd18da430",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2715b-7d27-4215-9d3b-c237eb9a15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "labels_results_repetitions = []\n",
    "response_dictionaries[analysis_name] = {}\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2212d2-febd-45ec-b3ce-7d82020e19de",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6ef7f-bf24-4b03-86de-2182a4c26c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "itercount = 0\n",
    "\n",
    "while itercount < 5:\n",
    "\n",
    "    # Analysis with LLM: \n",
    "    timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function)\n",
    "\n",
    "    # Calculate duration of analysis: \n",
    "    duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "    total_seconds = duration.total_seconds()\n",
    "    print(total_seconds)\n",
    "\n",
    "    # Store information about duration: \n",
    "    time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                   duration,timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis)\n",
    "    \n",
    "    # Store dictionary with LLM responses:\n",
    "    response_dictionaries[analysis_name][timestamp_start_is_photo_analysis] = image_descr\n",
    "    \n",
    "    # Extract LLM responses from dictionary:\n",
    "    img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "    \n",
    "    # Check if the response variable lists has the same length as id list:\n",
    "    # print('Length of img_ids:')\n",
    "    # print(len(img_ids))\n",
    "    # print('Length of is_photo:')\n",
    "    # print(len(is_photo))\n",
    "    \n",
    "    # Put response variables into data frame: \n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                               prediction_name: is_photo,\n",
    "                               'time_stamp': timestamp_ids})\n",
    "    \n",
    "    # Check for missing values:\n",
    "    # print(predictions.isnull().any().any())\n",
    "    # print(predictions.isna().any().any())\n",
    "    # print(has_missing_comprehensive(predictions))\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    label_data_c = label_data.copy()\n",
    "    labels_results = label_data_c.merge(predictions, how='inner', on='image_id')\n",
    "    print(labels_results.shape)\n",
    "    labels_results_repetitions.append(labels_results)\n",
    "    \n",
    "    # Save labels and predictions in dictionary: \n",
    "    #results_tabular[analysis_name] = {}\n",
    "    #results_tabular[analysis_name][timestamp_start_is_photo_analysis] = labels_results\n",
    "    \n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "    # ml_metrics['analysis_name'] = analysis_name\n",
    "    # ml_metrics['time_stamp'] = timestamp_start_is_photo_analysis\n",
    "    # ml_metrics['positives'] = positives.shape[0]\n",
    "    # ml_metrics['negatives'] = negatives.shape[0]\n",
    "    # ml_metrics['true_positives'] = true_positives.shape[0]\n",
    "    # ml_metrics['false_positives'] = false_positives.shape[0]\n",
    "    # ml_metrics['true_negatives'] = true_negatives.shape[0]\n",
    "    # ml_metrics['false_negatives'] = false_negatives.shape[0]\n",
    "    # ml_metrics['sensitivity'] = sensitivity\n",
    "    # ml_metrics['specificity'] = specificity\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'True Positives: {true_positives.shape[0]}')\n",
    "    print(f'False Positives: {false_positives.shape[0]}')\n",
    "    print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "    print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "    \n",
    "    itercount += 1\n",
    "\n",
    "results_tabular[analysis_name] = pd.concat(labels_results_repetitions, ignore_index=True)\n",
    "\n",
    "\n",
    "ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbacdf-dbf2-4d27-b2cf-88cf40d1e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files[0].split('Oberland')[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b3967-a7f8-4fd8-a175-79a667f2e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bc871-7057-41a3-8593-c6d77565c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196e331-0c52-4eee-954e-b15890f4f9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122e454-ac7d-4c22-806b-cb69a9481f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da5064-4ff9-466c-858e-c64f7cde11f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84575590-bcdb-4356-a5b4-bcc497f4135c",
   "metadata": {},
   "source": [
    "## Identify non-photo images with intuitive prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf890d-0b48-4d7d-8f09-dc9b504a0716",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c63d8-1965-4493-9af9-d3fc519ba778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'is_photo_intuitive_struct_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_intuitive\n",
    "keys_list_expected = ['image_is_photography', 'additional_comments']\n",
    "response_variable = 'image_is_photography'\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd511d-7d60-4c66-ae26-c8afddd96df9",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72ca94-cc5b-46c3-8ed8-02f19d8a8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "labels_results_repetitions = []\n",
    "response_dictionaries[analysis_name] = {}\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83fddc-d6ab-4ab5-ae3f-c57b4324eebc",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539dd53-cbe6-424c-8264-c52cadb99b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "itercount = 0\n",
    "\n",
    "while itercount < 5:\n",
    "\n",
    "    # Analysis with LLM: \n",
    "    timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function)\n",
    "\n",
    "    # Calculate duration of analysis: \n",
    "    duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "    total_seconds = duration.total_seconds()\n",
    "    print(total_seconds)\n",
    "\n",
    "    # Store information about duration: \n",
    "    time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                   duration,timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis)\n",
    "    \n",
    "    # Store dictionary with LLM responses:\n",
    "    response_dictionaries[analysis_name][timestamp_start_is_photo_analysis] = image_descr\n",
    "    \n",
    "    # Extract LLM responses from dictionary:\n",
    "    img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "    \n",
    "    # Check if the response variable lists has the same length as id list:\n",
    "    # print('Length of img_ids:')\n",
    "    # print(len(img_ids))\n",
    "    # print('Length of is_photo:')\n",
    "    # print(len(is_photo))\n",
    "    \n",
    "    # Put response variables into data frame: \n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                               prediction_name: is_photo,\n",
    "                               'time_stamp': timestamp_ids})\n",
    "    \n",
    "    # Check for missing values:\n",
    "    # print(predictions.isnull().any().any())\n",
    "    # print(predictions.isna().any().any())\n",
    "    # print(has_missing_comprehensive(predictions))\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    label_data_c = label_data.copy()\n",
    "    labels_results = label_data_c.merge(predictions, how='inner', on='image_id')\n",
    "    print(labels_results.shape)\n",
    "    labels_results_repetitions.append(labels_results)\n",
    "    \n",
    "    # Save labels and predictions in dictionary: \n",
    "    #results_tabular[analysis_name] = {}\n",
    "    #results_tabular[analysis_name][timestamp_start_is_photo_analysis] = labels_results\n",
    "    \n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "    # ml_metrics['analysis_name'] = analysis_name\n",
    "    # ml_metrics['time_stamp'] = timestamp_start_is_photo_analysis\n",
    "    # ml_metrics['positives'] = positives.shape[0]\n",
    "    # ml_metrics['negatives'] = negatives.shape[0]\n",
    "    # ml_metrics['true_positives'] = true_positives.shape[0]\n",
    "    # ml_metrics['false_positives'] = false_positives.shape[0]\n",
    "    # ml_metrics['true_negatives'] = true_negatives.shape[0]\n",
    "    # ml_metrics['false_negatives'] = false_negatives.shape[0]\n",
    "    # ml_metrics['sensitivity'] = sensitivity\n",
    "    # ml_metrics['specificity'] = specificity\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'True Positives: {true_positives.shape[0]}')\n",
    "    print(f'False Positives: {false_positives.shape[0]}')\n",
    "    print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "    print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "    \n",
    "    itercount += 1\n",
    "\n",
    "results_tabular[analysis_name] = pd.concat(labels_results_repetitions, ignore_index=True)\n",
    "\n",
    "\n",
    "ml_metrics_one_analysis = pd.DataFrame({'positives': [],\n",
    "              'negatives': [], \n",
    "              'true_positives': [], \n",
    "              'true_negatives': [],\n",
    "              'false_negatives': [], \n",
    "              'false_positives': [], \n",
    "              'sensitivity': [], \n",
    "              'specificity': []})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93e2cb-2929-4eb3-8bd6-06a76ce90446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dfdf89-ebb2-4357-a1df-57c59d24aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular[analysis_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514e5ac-bfb1-4c52-87eb-01d44974d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e02512-2951-45ef-bad6-1888e41524d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da3e62-8e1a-4e1f-8893-13c396b523a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36315001-2822-461b-ba3f-07f7e5c2d40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6118f3a-4194-472a-b0fa-e46d82313cb4",
   "metadata": {},
   "source": [
    "## Identify non-photo images with alternatives prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8245faa-d047-4141-afc2-f418fc6bff16",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd5852-ac15-4c8d-848d-513055779eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'is_photo_alternatives_struct_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_alternatives\n",
    "keys_list_expected = ['image_is_photography', 'additional_comments']\n",
    "response_variable = 'image_is_photography'\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d87089-29aa-4584-953f-7d91baa16aff",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b05bf2-ed8c-4f4b-9fbc-b8e87ff3c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "labels_results_repetitions = []\n",
    "response_dictionaries[analysis_name] = {}\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ae3ce-cf94-419c-97ef-a24f38b65260",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5cd7d-0a84-4d85-b063-4c264a08e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "itercount = 0\n",
    "\n",
    "while itercount < 5:\n",
    "\n",
    "    # Analysis with LLM: \n",
    "    timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function)\n",
    "\n",
    "    # Calculate duration of analysis: \n",
    "    duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "    total_seconds = duration.total_seconds()\n",
    "    print(total_seconds)\n",
    "\n",
    "    # Store information about duration: \n",
    "    time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                   duration,timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis)\n",
    "    \n",
    "    # Store dictionary with LLM responses:\n",
    "    response_dictionaries[analysis_name][timestamp_start_is_photo_analysis] = image_descr\n",
    "    \n",
    "    # Extract LLM responses from dictionary:\n",
    "    img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "    \n",
    "    # Check if the response variable lists has the same length as id list:\n",
    "    # print('Length of img_ids:')\n",
    "    # print(len(img_ids))\n",
    "    # print('Length of is_photo:')\n",
    "    # print(len(is_photo))\n",
    "    \n",
    "    # Put response variables into data frame: \n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                               prediction_name: is_photo,\n",
    "                               'time_stamp': timestamp_ids})\n",
    "    \n",
    "    # Check for missing values:\n",
    "    # print(predictions.isnull().any().any())\n",
    "    # print(predictions.isna().any().any())\n",
    "    # print(has_missing_comprehensive(predictions))\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    label_data_c = label_data.copy()\n",
    "    labels_results = label_data_c.merge(predictions, how='inner', on='image_id')\n",
    "    print(labels_results.shape)\n",
    "    labels_results_repetitions.append(labels_results)\n",
    "    \n",
    "    # Save labels and predictions in dictionary: \n",
    "    #results_tabular[analysis_name] = {}\n",
    "    #results_tabular[analysis_name][timestamp_start_is_photo_analysis] = labels_results\n",
    "    \n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "    # ml_metrics['analysis_name'] = analysis_name\n",
    "    # ml_metrics['time_stamp'] = timestamp_start_is_photo_analysis\n",
    "    # ml_metrics['positives'] = positives.shape[0]\n",
    "    # ml_metrics['negatives'] = negatives.shape[0]\n",
    "    # ml_metrics['true_positives'] = true_positives.shape[0]\n",
    "    # ml_metrics['false_positives'] = false_positives.shape[0]\n",
    "    # ml_metrics['true_negatives'] = true_negatives.shape[0]\n",
    "    # ml_metrics['false_negatives'] = false_negatives.shape[0]\n",
    "    # ml_metrics['sensitivity'] = sensitivity\n",
    "    # ml_metrics['specificity'] = specificity\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'True Positives: {true_positives.shape[0]}')\n",
    "    print(f'False Positives: {false_positives.shape[0]}')\n",
    "    print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "    print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "    \n",
    "    itercount += 1\n",
    "\n",
    "results_tabular[analysis_name] = pd.concat(labels_results_repetitions, ignore_index=True)\n",
    "\n",
    "\n",
    "ml_metrics_one_analysis = pd.DataFrame({'positives': [],\n",
    "              'negatives': [], \n",
    "              'true_positives': [], \n",
    "              'true_negatives': [],\n",
    "              'false_negatives': [], \n",
    "              'false_positives': [], \n",
    "              'sensitivity': [], \n",
    "              'specificity': []})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9e5a5-aaac-448b-93bf-0d206c3cb70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3303f44d-a354-45eb-9f8d-d5d4bf792b0d",
   "metadata": {},
   "source": [
    "## Identify non-photo images with precise prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80e6b6-238c-4b20-abeb-8b493d77aa07",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163ecb1-1e6b-4666-8449-a7c305dc7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'is_photo_precise_struct_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_precise\n",
    "keys_list_expected = ['image_of_image', 'additional_comments']\n",
    "response_variable = 'image_of_image'\n",
    "\n",
    "label_name = 'is_photo'\n",
    "prediction_name = 'is_photo_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8d326-ab14-41b7-a2b6-7923a656080d",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefe89a-6204-423e-ae55-39bd1e6f0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "labels_results_repetitions = []\n",
    "response_dictionaries[analysis_name] = {}\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef94359-cad5-44fe-91ca-892c7d6a1cdc",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded7d60-fdf8-4e12-8f23-1f27aad7c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "itercount = 0\n",
    "\n",
    "while itercount < 5:\n",
    "\n",
    "    # Analysis with LLM: \n",
    "    timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function)\n",
    "\n",
    "    # Calculate duration of analysis: \n",
    "    duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "    total_seconds = duration.total_seconds()\n",
    "    print(total_seconds)\n",
    "\n",
    "    # Store information about duration: \n",
    "    time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                   duration,timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis)\n",
    "    \n",
    "    # Store dictionary with LLM responses:\n",
    "    response_dictionaries[analysis_name][timestamp_start_is_photo_analysis] = image_descr\n",
    "    \n",
    "    # Extract LLM responses from dictionary:\n",
    "    img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "    \n",
    "    # Check if the response variable lists has the same length as id list:\n",
    "    # print('Length of img_ids:')\n",
    "    # print(len(img_ids))\n",
    "    # print('Length of is_photo:')\n",
    "    # print(len(is_photo))\n",
    "    \n",
    "    # Put response variables into data frame: \n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                               prediction_name: is_photo,\n",
    "                               'time_stamp': timestamp_ids})\n",
    "    \n",
    "    # Check for missing values:\n",
    "    # print(predictions.isnull().any().any())\n",
    "    # print(predictions.isna().any().any())\n",
    "    # print(has_missing_comprehensive(predictions))\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    label_data_c = label_data.copy()\n",
    "    labels_results = label_data_c.merge(predictions, how='inner', on='image_id')\n",
    "    print(labels_results.shape)\n",
    "    labels_results_repetitions.append(labels_results)\n",
    "    \n",
    "    # Save labels and predictions in dictionary: \n",
    "    #results_tabular[analysis_name] = {}\n",
    "    #results_tabular[analysis_name][timestamp_start_is_photo_analysis] = labels_results\n",
    "    \n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "    # ml_metrics['analysis_name'] = analysis_name\n",
    "    # ml_metrics['time_stamp'] = timestamp_start_is_photo_analysis\n",
    "    # ml_metrics['positives'] = positives.shape[0]\n",
    "    # ml_metrics['negatives'] = negatives.shape[0]\n",
    "    # ml_metrics['true_positives'] = true_positives.shape[0]\n",
    "    # ml_metrics['false_positives'] = false_positives.shape[0]\n",
    "    # ml_metrics['true_negatives'] = true_negatives.shape[0]\n",
    "    # ml_metrics['false_negatives'] = false_negatives.shape[0]\n",
    "    # ml_metrics['sensitivity'] = sensitivity\n",
    "    # ml_metrics['specificity'] = specificity\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'True Positives: {true_positives.shape[0]}')\n",
    "    print(f'False Positives: {false_positives.shape[0]}')\n",
    "    print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "    print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "    \n",
    "    itercount += 1\n",
    "\n",
    "results_tabular[analysis_name] = pd.concat(labels_results_repetitions, ignore_index=True)\n",
    "\n",
    "\n",
    "ml_metrics_one_analysis = pd.DataFrame({'positives': [],\n",
    "              'negatives': [], \n",
    "              'true_positives': [], \n",
    "              'true_negatives': [],\n",
    "              'false_negatives': [], \n",
    "              'false_positives': [], \n",
    "              'sensitivity': [], \n",
    "              'specificity': []})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e15ee-c214-4674-a2a2-30a7560dbcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50def63-bb3a-4edd-b17e-17014e40a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_id = timestamp_start_is_photo_analysis.strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b84e40-4271-4c8c-9fb0-dcb48846032c",
   "metadata": {},
   "source": [
    "## Save ml-metrics data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d21010-357d-4ff5-9277-116c9c3da7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "#date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = 'ml_metrics_prompt_exp_struct_minicpm_' + timestamp_id + '.csv'\n",
    "ml_metrics_output_path = os.path.join(data_path, filename)\n",
    "\n",
    "# Save csv-file: \n",
    "ml_metrics.to_csv(ml_metrics_output_path, index=False)\n",
    "\n",
    "# Reload saved csv table to check if saving worked:\n",
    "ml_metrics_reloaded = pd.read_csv(ml_metrics_output_path)\n",
    "ml_metrics_reloaded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d3dae-dfeb-4ab3-b327-b73ad9695577",
   "metadata": {},
   "source": [
    "## Save response dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b3f1d-fd66-45f3-9105-7717b6a6aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "#date = str(timestamp_end_is_photo_analysis).split('.')[0][0:10]\n",
    "filename = 'responses_prompt_exp_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(response_dictionaries, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_image_descr = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(image_descr))\n",
    "print(type(image_descr))\n",
    "print(type(reloaded_image_descr))\n",
    "print(len(reloaded_image_descr))\n",
    "\n",
    "print(image_descr.keys() == reloaded_image_descr.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be394aa6-5b9e-4050-b684-d5cff2ca6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "#current_timestamp = pd.Timestamp.now()\n",
    "#current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "results_file_name = 'results_prompt_exp_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d2ac2-2eba-4d5a-a128-27c055043b46",
   "metadata": {},
   "source": [
    "## Calculate duration of analysis overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_end_workflow = pd.Timestamp.now()\n",
    "timestamp_end_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8c4bc-ec18-4a6d-b59a-2656f485274c",
   "metadata": {},
   "source": [
    "## Save time analyses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "# current_date_time = current_timestamp.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "time_analyses_df_file_name = 'times_df_prompt_exp_struct_minicpm_' + timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9704fd8-042c-437f-b552-5bd05b686f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1879e3b-d293-4dc2-9178-0367e8051f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaaf60-5011-48aa-9ed9-5570f7c772c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0032e47-c2fc-4fb0-957e-949421dd8e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41035e54-1c64-4d18-b0f0-f9bd6f73086a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
