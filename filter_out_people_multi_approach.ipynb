{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "from source import sort_img_files as sif\n",
    "from source import detect_persons_yolo as dpy\n",
    "from source import llm_input as llm_i\n",
    "from source import llm_output as llm_o\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f992c0-9920-4c20-963a-d4f3bafbef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43342371-5d6a-4df4-b521-911399c2f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea648d46-1292-496c-9833-f5e103a67ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8afa7-89c3-45d1-b5d3-6c2b5e40b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration,\n",
    "                  timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['time_stamp_start'].append(timestamp_start_is_photo_analysis)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "\n",
    "    return time_analysis_dict, time_analysis_for_df_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3eac1-77c7-4d69-9224-cca38ee310df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf71fe-dffa-419f-a765-e72003a07043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1dcaf31-4555-4290-9842-86d1981bcde6",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for time analyses and get time stamp for overall workflow duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487513a0-47e8-4b79-91b8-38141705ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_for_df = {}\n",
    "time_analyses_for_df['analysis_name'] = []\n",
    "time_analyses_for_df['time_stamp_start'] = []\n",
    "time_analyses_for_df['duration_str'] = []\n",
    "time_analyses_for_df['duration_seconds'] = []\n",
    "time_analyses_for_df['duration_seconds_str'] = []\n",
    "time_analyses_for_df['duration_minutes'] = []\n",
    "time_analyses_for_df['duration_minutes_str'] = []\n",
    "\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7fa6a-5d37-4f37-a10e-de6155c103f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0775f7f-99d1-4c5f-84c4-432c68d7c07c",
   "metadata": {},
   "source": [
    "### Prepare empty data frame to store performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad6a54-0860-43a4-a939-cf7b9c10dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea703fc-910a-43ee-b187-bf961eaa582e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ad9cd2-eee5-44cf-a6dd-cee0115b112e",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e14a3-c84e-44ab-90a3-287d078b8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece681-2ea0-4de7-b84b-ec3e1f8ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(os.getcwd())\n",
    "root_path = project_path / 'test_filter_out_people_multi_approach'\n",
    "# root_path = project_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9ff36-8849-4814-9d1b-99e39f0e6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "# image_dir = root_path/\"../data\"  # Replace with your directory containing images\n",
    "# Adaptation to the different file structure on ubelix: \n",
    "data_path = root_path/\"data\"  # Replace with your directory containing images\n",
    "tif_data_path = root_path / 'data_1'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "image_dir = jpg_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc36722-dc8f-4363-bd69-e0e1403ccdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8627427b-9eac-429a-884b-e10eee880a99",
   "metadata": {},
   "source": [
    "### Load label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bba5d-201d-470c-95c1-578906246062",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6aa73-8348-4a71-9f83-b606e5107f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' \n",
    "# to ensure string data type to deal with duck typing): \n",
    "img_ids = list(label_data.image_id)\n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc12893-7fcd-4cfc-a467-e36cf3f13d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56563fd9-f2d4-40fb-b817-9f5e6dbdc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dfbcb-c2ad-4d7f-840f-31f53b61c124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c45ae57-6564-4116-b44e-0f23ac7fa46a",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450b1be-5902-4685-99ab-07bc1cfab394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Find all .ipynb_checkpoints directories\n",
    "for checkpoint_dir in jpg_data_path.rglob('.ipynb_checkpoints'):\n",
    "    if checkpoint_dir.is_dir():\n",
    "        print(f\"Removing: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "#image_files.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1c5ab-0461-4149-99f4-d8c04072ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "llm_i.convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375230d-8684-44ab-9732-9571a3cf9f43",
   "metadata": {},
   "source": [
    "## Yolo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "## Define the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80166cf-42cd-48d6-a5ea-074716419a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv5 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use yolov8n (nano) for faster inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3e0ce-6f84-4e7a-9001-14f6f4b49dfc",
   "metadata": {},
   "source": [
    "## Detect persons with pretrained yolo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473f807-cc07-4b78-a894-dd46ba196293",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_yolo'\n",
    "label_name = 'with_person'\n",
    "prediction_name = 'with_person_yolo_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a696001-b66f-4a55-be94-190f0b36acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ids, with_person = sif.sort_img_files(image_dir, model, output_dir_with_person, \n",
    "#                                           output_dir_without_person, threshold=0.25)\n",
    "\n",
    "\n",
    "timestamp_start_pers_yolo = pd.Timestamp.now()\n",
    "\n",
    "img_ids, with_person = dpy.detect_persons_yolo(image_dir, model, threshold=0.25,\n",
    "                                              file_format=\"jpg\")\n",
    "timestamp_end_pers_yolo = pd.Timestamp.now()\n",
    "\n",
    "\n",
    "duration = timestamp_end_pers_yolo - timestamp_start_pers_yolo\n",
    "\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "\n",
    "# Store information about duration: \n",
    "time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "               duration, timestamp_start_pers_yolo,\n",
    "              timestamp_end_pers_yolo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65320479-c1e5-4c5c-8532-b0482e2922c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f73d9-c659-4442-bc64-129bdfacf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(with_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c91ac-b072-4a77-85d5-e65728870b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_ids))\n",
    "print(len(with_person))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c752b-e8b7-4661-b8dd-6392c57b98e8",
   "metadata": {},
   "source": [
    "## Load person predictions into a dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9109a-8ee8-49fc-86b4-2b67f56d1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_person = pd.DataFrame({'image_id': img_ids, label_name: with_person})\n",
    "results_person.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700135be-b2cc-43e0-be66-03eb03a48178",
   "metadata": {},
   "source": [
    "## Add one-hot-coded person predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4984e3-c840-48d6-8067-cb2111ee34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_person['with_person_yolo_pred']= [1 if x else 0 for x in results_person.with_person]\n",
    "results_person_select = results_person.loc[:, ['image_id', prediction_name]]\n",
    "results_person_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f29025-cec0-4d5c-87cf-51bac765e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_without_person = pd.read_csv(data_path/'labels_mod.csv')\n",
    "with_without_person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875af8c-605e-4358-b3a4-d5f781f424b8",
   "metadata": {},
   "source": [
    "### Get relevant part of label data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1801e2-675c-42e9-9ee6-b26f94b3fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take copy of label_data and select relevant columns:\n",
    "with_without_person = label_data.copy()\n",
    "with_without_person = with_without_person.iloc[:, 0:3]\n",
    "with_without_person.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a17dc-4c15-4d1a-b808-1dd7be6703d3",
   "metadata": {},
   "source": [
    "## Merge label data with the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33349e62-6be4-408a-8efc-103e2655948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = with_without_person.merge(results_person_select, how='inner', on='image_id')\n",
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298971ac-6446-4930-af46-6bc156f630e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9df5a-88f0-4de3-ae3c-dde8d4185905",
   "metadata": {},
   "source": [
    "## Calculate sensitivity and specificity for person predictions and get the different data subsets based on label and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c51e4-fd75-4d56-a119-45a205538dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, \n",
    "                                                               'with_person_yolo_pred')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5a3f5-ea6e-431f-aff3-03d994b4d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives, negatives, true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics \n",
    "print(sensitivity)\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c95cb-6605-49d0-b3af-c3ff908641a7",
   "metadata": {},
   "source": [
    "## Inspect false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446b2d-4b55-4bef-8485-f2be100e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343ee97-be36-46cc-a187-222201fa544d",
   "metadata": {},
   "source": [
    "## Inspect false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f47b2-baed-4a59-8307-f8ca516b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4153d-ea07-4df8-b8e5-faa36475b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_positives = positives.shape[0]\n",
    "number_negatives = negatives.shape[0]\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cdda2-ff3b-4d89-aee2-fe4466c20314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1306dc9b-1941-4280-973e-6c5d28f6c3f6",
   "metadata": {},
   "source": [
    "### Add performance metrics to data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152978b-b781-4f13-b247-6df6c64adbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_to_stack = pd.DataFrame({})\n",
    "ml_metrics_to_stack['analysis_name'] = [analysis_name]\n",
    "ml_metrics_to_stack['time_stamp'] = [timestamp_start_pers_yolo]\n",
    "ml_metrics_to_stack['positives'] = [number_positives]\n",
    "ml_metrics_to_stack['negatives'] = [number_negatives]\n",
    "ml_metrics_to_stack['true_positives'] = [number_true_positives]\n",
    "ml_metrics_to_stack['false_positives'] = [number_false_positives]\n",
    "ml_metrics_to_stack['true_negatives'] = [number_true_negatives]\n",
    "ml_metrics_to_stack['false_negatives'] = [number_false_negatives]\n",
    "ml_metrics_to_stack['sensitivity'] = [sensitivity]\n",
    "ml_metrics_to_stack['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics_to_concat = [ml_metrics, ml_metrics_to_stack]\n",
    "ml_metrics = pd.concat(ml_metrics_to_concat)\n",
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d36b8-cfb0-4943-882d-f36cda072404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2be7aa5-9956-474c-a4d3-beba2fc93daa",
   "metadata": {},
   "source": [
    "### Plot confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c436586-c21f-4d77-96e7-b8b026779175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases = true_positives, false_positives, true_negatives, false_negatives, positives, negatives\n",
    "\n",
    "# llm_o.plot_conf_matrix(labels_results, 'with_person', 'with_person_yolo_pred', cases)\n",
    "fig = llm_o.save_conf_matrix(labels_results, label_name, 'with_person_yolo_pred', cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c278c3a-c922-499e-b90d-59326ac0417b",
   "metadata": {},
   "source": [
    "### Save confusion matrix as pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9488026-1069-44d6-800d-44b9d48302a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fig object was created when plotting the confusion matrix\n",
    "# so now we can use it to save the plot as pdf:\n",
    "file_name = 'conf_matrix_metrics_' + analysis_name + '.pdf'\n",
    "conf_matrix_path = data_path / file_name\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166179c5-cf02-4a0a-a478-7559e06f1bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673922cb-2284-4bce-81eb-bccb11756b57",
   "metadata": {},
   "source": [
    "## Recalculate Measures with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68789693-d8ae-4619-a3c3-0c31948f8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_recognisable_yolo'\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_yolo_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee07bf91-9329-4565-b4b7-64e5204c3716",
   "metadata": {},
   "source": [
    "## Calculate sensitivity and specificity for person predictions and get the different data subsets based on label and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18625f-ed0f-487d-b859-28bd80b82e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results, label_name, \n",
    "                                                               prediction_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf461d2-8213-4756-a6fd-824529caa6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(positives, negatives, true_positives, true_negatives, false_negatives, \n",
    " false_positives, sensitivity, specificity) = subsets_and_metrics\n",
    "print(sensitivity) \n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a339a8-aa32-46c1-a0c1-f4d519a759b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_positives = positives.shape[0]\n",
    "number_negatives = negatives.shape[0]\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b4f22-6c35-4b23-bee2-fd260a195906",
   "metadata": {},
   "source": [
    "### Add performance metrics to data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e65bf-dfbe-4d3d-851d-d95c308e6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_to_stack = pd.DataFrame({})\n",
    "ml_metrics_to_stack['analysis_name'] = [analysis_name]\n",
    "ml_metrics_to_stack['time_stamp'] = [timestamp_start_pers_yolo]\n",
    "ml_metrics_to_stack['positives'] = [number_positives]\n",
    "ml_metrics_to_stack['negatives'] = [number_negatives]\n",
    "ml_metrics_to_stack['true_positives'] = [number_true_positives]\n",
    "ml_metrics_to_stack['false_positives'] = [number_false_positives]\n",
    "ml_metrics_to_stack['true_negatives'] = [number_true_negatives]\n",
    "ml_metrics_to_stack['false_negatives'] = [number_false_negatives]\n",
    "ml_metrics_to_stack['sensitivity'] = [sensitivity]\n",
    "ml_metrics_to_stack['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics_to_concat = [ml_metrics, ml_metrics_to_stack]\n",
    "ml_metrics = pd.concat(ml_metrics_to_concat)\n",
    "ml_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cf22b-0b47-4712-88e9-a8b6d7957c8b",
   "metadata": {},
   "source": [
    "### Plot confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969fcdf-a360-4d70-a9ca-c26a09095569",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = true_positives, false_positives, true_negatives, false_negatives, positives, negatives\n",
    "\n",
    "#llm_o.plot_conf_matrix(labels_results, 'person_recognisable', 'with_person_yolo_pred', cases)\n",
    "fig = llm_o.save_conf_matrix(labels_results, label_name, prediction_name, cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f861c-44a3-471b-b938-5b21ab256acf",
   "metadata": {},
   "source": [
    "### Save confusion matrix as pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329c2d5-a3ca-4223-830e-6255c14bb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The fig object was created when plotting the confusion matrix\n",
    "# so now we can use it to save the plot as pdf:\n",
    "file_name = 'conf_matrix_metrics_' + analysis_name + '.pdf'\n",
    "conf_matrix_path = data_path / file_name\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a4298-9f83-4fea-9179-d9ad4ea7d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53ae21-05f1-4030-93c5-9f6abe6f6d0c",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77988db-6a83-42ac-bcc9-b23b5d7ff6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9ac00-0ae1-4ecb-a246-79533ef517b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_person():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'contains_persons': X,  # True if the image contains a person or multiple persons, False if the image does not contain any person.\n",
    "        'additional_comments': '' # Any additional observations or empty string if none.\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image contains one or multiple persons) or False (does not contain any person).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077f3f1-4497-4536-bc9d-d79433c13882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    print(image_files)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        print('\\n')\n",
    "        print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        #image_description = analyze_image_structured(image_path)\n",
    "        #image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt)\n",
    "        image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "        print(image_description)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        #print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b70eb-3694-4982-8c41-3e61c206b5e0",
   "metadata": {},
   "source": [
    "### Choose LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca73b51-c951-4403-9fb3-01d51ee5cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_function = llm_i.call_minicpm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c790d4-7556-4ad5-9120-a4cddb99961a",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary to store the different response dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5853ba-d1a2-43d5-8316-94c5ec33e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dictionaries = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05ed0e-f223-43ff-b312-1ecc737628f9",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for cases with unstructured answers for visual inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c089a-1b31-4b65-9595-5a5d4ab62973",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_closer_inspection = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d4212-bcc6-471c-980b-88a3f0789284",
   "metadata": {},
   "source": [
    "### Prepare empty dictionary for result dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b913ad-32fd-46ae-9b7c-7eaefb7df194",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2c346-6a77-45ae-a2db-06f967318f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "769388c8-1352-4b0b-a1a0-791651f53cb1",
   "metadata": {},
   "source": [
    "## Identify non-photo images with intuitive prompt:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f64de9-2205-4d31-b04f-ea9737a82219",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c63d8-1965-4493-9af9-d3fc519ba778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'pers_struct_minicpm'\n",
    "create_analysis_prompt = create_analysis_prompt_person\n",
    "keys_list_expected = ['contains_persons', 'additional_comments']\n",
    "response_variable = 'contains_persons'\n",
    "\n",
    "label_name = 'with_person'\n",
    "prediction_name = 'with_person_minicpm_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cd759-f8c9-4a30-bbae-602a50a8f5e1",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72ca94-cc5b-46c3-8ed8-02f19d8a8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "labels_results_repetitions = []\n",
    "response_dictionaries[analysis_name] = {}\n",
    "\n",
    "ml_metrics_analysis_name = []\n",
    "ml_metrics_time_stamp = []\n",
    "ml_metrics_positives = []\n",
    "ml_metrics_negatives = []\n",
    "ml_metrics_true_positives = []\n",
    "ml_metrics_false_positives = []\n",
    "ml_metrics_true_negatives = []\n",
    "ml_metrics_false_negatives = []\n",
    "ml_metrics_sensitivity = []\n",
    "ml_metrics_specificity = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d2d13-267f-492b-a946-787077b125c0",
   "metadata": {},
   "source": [
    "### Extract and store results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539dd53-cbe6-424c-8264-c52cadb99b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "itercount = 0\n",
    "\n",
    "while itercount < 1:\n",
    "\n",
    "    # Analysis with LLM: \n",
    "    timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function)\n",
    "\n",
    "    # Calculate duration of analysis: \n",
    "    duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "    total_seconds = duration.total_seconds()\n",
    "    print(total_seconds)\n",
    "\n",
    "    # Store information about duration: \n",
    "    time_analyses, time_analyses_for_df = store_duration(time_analyses, time_analyses_for_df, analysis_name, \n",
    "                   duration,timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis)\n",
    "    \n",
    "    # Store dictionary with LLM responses:\n",
    "    response_dictionaries[analysis_name][timestamp_start_is_photo_analysis] = image_descr\n",
    "    \n",
    "    # Extract LLM responses from dictionary:\n",
    "    img_ids, is_photo, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids, image_descr, keys_list_expected, response_variable)\n",
    "    \n",
    "    # Check if the response variable lists has the same length as id list:\n",
    "    # print('Length of img_ids:')\n",
    "    # print(len(img_ids))\n",
    "    # print('Length of is_photo:')\n",
    "    # print(len(is_photo))\n",
    "    \n",
    "    # Put response variables into data frame: \n",
    "    # timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    # predictions = pd.DataFrame({'image_id': img_ids, \n",
    "    #                            prediction_name: is_photo,\n",
    "    #                           'time_stamp': timestamp_ids})\n",
    "\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids)\n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                               prediction_name: is_photo})\n",
    "    \n",
    "    # Check for missing values:\n",
    "    # print(predictions.isnull().any().any())\n",
    "    # print(predictions.isna().any().any())\n",
    "    # print(has_missing_comprehensive(predictions))\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    labels_results_c = labels_results.copy()\n",
    "    labels_results_i = labels_results_c.merge(predictions, how='inner', on='image_id')\n",
    "    print(labels_results_i.shape)\n",
    "    labels_results_repetitions.append(labels_results_i)\n",
    "    \n",
    "    # Save labels and predictions in dictionary: \n",
    "    #results_tabular[analysis_name] = {}\n",
    "    #results_tabular[analysis_name][timestamp_start_is_photo_analysis] = labels_results\n",
    "    \n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [timestamp_start_is_photo_analysis] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_i, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "    # ml_metrics['analysis_name'] = analysis_name\n",
    "    # ml_metrics['time_stamp'] = timestamp_start_is_photo_analysis\n",
    "    # ml_metrics['positives'] = positives.shape[0]\n",
    "    # ml_metrics['negatives'] = negatives.shape[0]\n",
    "    # ml_metrics['true_positives'] = true_positives.shape[0]\n",
    "    # ml_metrics['false_positives'] = false_positives.shape[0]\n",
    "    # ml_metrics['true_negatives'] = true_negatives.shape[0]\n",
    "    # ml_metrics['false_negatives'] = false_negatives.shape[0]\n",
    "    # ml_metrics['sensitivity'] = sensitivity\n",
    "    # ml_metrics['specificity'] = specificity\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'True Positives: {true_positives.shape[0]}')\n",
    "    print(f'False Positives: {false_positives.shape[0]}')\n",
    "    print(f'True Negatives: {true_negatives.shape[0]}')\n",
    "    print(f'False Negatives: {false_negatives.shape[0]}')\n",
    "    \n",
    "    itercount += 1\n",
    "\n",
    "results_tabular[analysis_name] = pd.concat(labels_results_repetitions, ignore_index=True)\n",
    "\n",
    "\n",
    "ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5170d-42fd-413a-990b-7efaf053d97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af43db-9da3-4268-84ac-672787c635cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8af82e-38f9-4644-ba9f-6833415a0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d496db-a33f-45b7-9ef3-d6519bd7c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_struct_minicpm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c38ab6-b6df-47fb-b3c1-2ee446cf62f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae45e9c-1d90-41cc-9b52-d4297421f199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da36bb-da83-400b-b3ff-f45dde2c38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "previous_analysis_name = analysis_name\n",
    "labels_results_i = results_tabular[previous_analysis_name]\n",
    "\n",
    "# Set parameters: \n",
    "analysis_name = 'pers_recognisable_struct_minicpm'\n",
    "# create_analysis_prompt = create_analysis_prompt_person\n",
    "# keys_list_expected = ['contains_persons', 'additional_comments']\n",
    "# response_variable = 'contains_persons'\n",
    "\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_minicpm_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b41d4f-5a56-416b-bf1d-5dbc82185901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a09db-ae4c-48f5-9715-a1f7c251d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_i, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837d9fa-cc97-443e-a094-1d7e5ce7bcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d510a6-ba5e-4fec-afae-8d10822e3585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1cdc9-a196-4285-8907-58980d67fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = [analysis_name]\n",
    "ml_metrics_one_analysis['time_stamp'] = [timestamp_start_is_photo_analysis]\n",
    "ml_metrics_one_analysis['positives'] = [positives.shape[0]]\n",
    "ml_metrics_one_analysis['negatives'] = [negatives.shape[0]]\n",
    "ml_metrics_one_analysis['true_positives'] = [true_positives.shape[0]]\n",
    "ml_metrics_one_analysis['false_positives'] = [false_positives.shape[0]]\n",
    "ml_metrics_one_analysis['true_negatives'] = [true_negatives.shape[0]]\n",
    "ml_metrics_one_analysis['false_negatives'] = [false_negatives.shape[0]]\n",
    "ml_metrics_one_analysis['sensitivity'] = [sensitivity]\n",
    "ml_metrics_one_analysis['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics = pd.concat([ml_metrics, ml_metrics_one_analysis], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789b8fb-6f8f-4fdc-8707-3d6462a3b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220fbb5-a3d6-4676-ba28-a7da7ca48502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45199f2-519d-4477-a40c-1b6e292bc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results = results_tabular['pers_struct_minicpm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4e26-6112-4d78-818c-4507b2af1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cf3d7-5b5f-41c6-ad27-f78a8ebe5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_bools = labels_results.with_person_yolo_pred == 1\n",
    "minicpm_bools = labels_results.with_person_minicpm_pred == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614414-1b55-4c6d-af8b-132a61f0bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(yolo_bools))\n",
    "print(sum(minicpm_bools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cb932-3029-47e7-bc2f-b19ee64a1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_one_detection = labels_results[yolo_bools | minicpm_bools].copy()\n",
    "imgs_one_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c41b3-9655-43ca-a41e-c707fe88538a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f21999-0e11-4993-96c9-747f3c4bc435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e546487-c87e-4c58-ad0d-596da8102967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520dda2-1d01-490d-af78-e0ffad7119eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f451591-afbb-41d9-a3b2-d1be9914fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d305021-7cdd-46ef-8338-9af38927bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image ids that will remain string type even when saved to csv and reloaded:\n",
    "labels = list(labels_results.image_id)\n",
    "new_labels = img_idc.complete_image_ids(labels)\n",
    "labels_results['image_id_str'] = new_labels\n",
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268a577-6522-4e06-96a2-81f32875fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf11295-3caf-416e-bce0-87a071f379fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208739d7-1d0e-47a9-b9ee-f57d2649183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9ee53-47e7-4ba3-bbab-3f7dcd588bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_select = ['image_id', 'with_person', 'person_recognisable', 'with_person_yolo_pred', 'with_person_minicpm_pred', 'image_id_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8e612-4bc6-45c4-8306-df02cde9e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_to_store = labels_results[cols_to_select].copy()\n",
    "labels_results_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6671fb-d2e6-4b18-bf58-7ebb322d0691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b269970-622f-4dbe-8363-d28d84c76a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da750ea3-6641-4c24-a3e0-4df46725056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_name = 'people_detect_multi_approach_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ab9b-b8c3-4020-806d-c6ba76fc2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'labels_results.csv'\n",
    "labels_results_to_store.to_csv(data_path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b9b61-1df5-4ee6-999c-f2c2f302a7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39f470-ad16-496b-904e-21fbae7ba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'ml_metrics.csv'\n",
    "ml_metrics.to_csv(data_path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c26f4-cc59-491d-a3d2-dc45ef03cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a5430-02fe-42d1-ad28-241c5edf48dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89772f51-0852-42d8-b713-c81216a8e7e0",
   "metadata": {},
   "source": [
    "### Save time analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ea35c-0969-4df8-932c-9dbe13ec236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304483-e32e-472e-accb-87f03c2faca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_df_file_name = workflow_name + 'time_analysis_for_df' + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_df_output_path = os.path.join(data_path, time_analyses_df_file_name)\n",
    "with open(time_analyses_df_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_for_df, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_df_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_for_df = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_for_df))\n",
    "print(type(time_analyses_for_df))\n",
    "print(type(reloaded_time_analyses_for_df))\n",
    "print(len(reloaded_time_analyses_for_df))\n",
    "\n",
    "print(time_analyses_for_df.keys() == reloaded_time_analyses_for_df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe560e35-ece4-41df-bf2f-f1691b72664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_file_name = workflow_name + 'time_analysis' + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_output_path = os.path.join(data_path, time_analyses_file_name)\n",
    "with open(time_analyses_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses))\n",
    "print(type(time_analyses))\n",
    "print(type(reloaded_time_analyses))\n",
    "print(len(reloaded_time_analyses))\n",
    "\n",
    "print(time_analyses.keys() == reloaded_time_analyses.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da5573-2b9c-4712-8002-b921d82286b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebd24e-951e-438b-b4ce-a8aac91f442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad074bc-503e-43ae-855a-2684ffb76413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651d92e-fa41-464a-9d39-f8424ea87ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c54a3-e0ca-4fb1-90d6-9f8b72d3de17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test-qwen-env)",
   "language": "python",
   "name": "test_qwen-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
