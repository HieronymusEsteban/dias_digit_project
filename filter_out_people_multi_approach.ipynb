{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de50bf5-56eb-40d7-8016-22959f1f1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from source import image_id_converter as img_idc\n",
    "#from source import sort_img_files as sif\n",
    "from source import detect_persons_yolo as dpy\n",
    "from source import llm_input as llm_i\n",
    "from source import llm_output as llm_o\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f992c0-9920-4c20-963a-d4f3bafbef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd0d8e-bb05-411b-9684-8e0edd348996",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43342371-5d6a-4df4-b521-911399c2f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea648d46-1292-496c-9833-f5e103a67ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8afa7-89c3-45d1-b5d3-6c2b5e40b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_duration(time_analysis_dict, time_analysis_for_df_dict, analysis_name, duration,\n",
    "                  timestamp_start_is_photo_analysis,\n",
    "                  timestamp_end_is_photo_analysis):\n",
    "    time_analysis_dict[analysis_name] = {}\n",
    "    time_analysis_dict[analysis_name]['duration_str'] = f\"Analysis took: {duration}\"\n",
    "    time_analysis_dict[analysis_name]['duration_seconds'] = total_seconds\n",
    "    time_analysis_dict[analysis_name]['duration_seconds_str'] = f\"Analysis took: {total_seconds:.2f} seconds\"\n",
    "    time_analysis_dict[analysis_name]['duration_minutes'] = total_seconds/60\n",
    "    time_analysis_dict[analysis_name]['duration_minutes_str'] = f\"Analysis took: {total_seconds/60:.2f} minutes\"\n",
    "    time_analysis_dict[analysis_name]['time_stamp_start'] = timestamp_start_is_photo_analysis\n",
    "    time_analysis_dict[analysis_name]['time_stamp_end'] = timestamp_end_is_photo_analysis\n",
    "\n",
    "    time_analysis_for_df_dict['analysis_name'].append(analysis_name)\n",
    "    time_analysis_for_df_dict['time_stamp_start'].append(timestamp_start_is_photo_analysis)\n",
    "    time_analysis_for_df_dict['duration_str'].append(f\"Analysis took: {duration}\")\n",
    "    time_analysis_for_df_dict['duration_seconds'].append(total_seconds)\n",
    "    time_analysis_for_df_dict['duration_seconds_str'].append(f\"Analysis took: {total_seconds:.2f} seconds\")\n",
    "    time_analysis_for_df_dict['duration_minutes'].append(total_seconds/60)\n",
    "    time_analysis_for_df_dict['duration_minutes_str'].append(f\"Analysis took: {total_seconds/60:.2f} minutes\")\n",
    "\n",
    "    return time_analysis_dict, time_analysis_for_df_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3eac1-77c7-4d69-9224-cca38ee310df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf71fe-dffa-419f-a765-e72003a07043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7fa6a-5d37-4f37-a10e-de6155c103f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea703fc-910a-43ee-b187-bf961eaa582e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ad9cd2-eee5-44cf-a6dd-cee0115b112e",
   "metadata": {},
   "source": [
    "## Set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e14a3-c84e-44ab-90a3-287d078b8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = Path('/Users/stephanehess/Documents/CAS_AML/dias_digit_project/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece681-2ea0-4de7-b84b-ec3e1f8ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(os.getcwd())\n",
    "root_path = project_path / '..' / 'test_data_folders/test_filter_out_people_multi_approach'\n",
    "# root_path = project_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9ff36-8849-4814-9d1b-99e39f0e6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "# image_dir = root_path/\"../data\"  # Replace with your directory containing images\n",
    "# Adaptation to the different file structure on ubelix: \n",
    "data_path = root_path/\"data\"  # Replace with your directory containing images\n",
    "tif_data_path = root_path / 'data_1'\n",
    "jpg_data_path = root_path / 'data_jpg'\n",
    "image_dir = jpg_data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc36722-dc8f-4363-bd69-e0e1403ccdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8627427b-9eac-429a-884b-e10eee880a99",
   "metadata": {},
   "source": [
    "### Load label data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bba5d-201d-470c-95c1-578906246062",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv(data_path/'labels_mod.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6aa73-8348-4a71-9f83-b606e5107f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert image ids to integers (e.g. '234') as strings from the form they were saved in (e.g. 'id234' \n",
    "# to ensure string data type to deal with duck typing): \n",
    "img_ids = list(label_data.image_id)\n",
    "label_data['image_id'] = img_idc.reconvert_image_ids(img_ids)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc12893-7fcd-4cfc-a467-e36cf3f13d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56563fd9-f2d4-40fb-b817-9f5e6dbdc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dfbcb-c2ad-4d7f-840f-31f53b61c124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c45ae57-6564-4116-b44e-0f23ac7fa46a",
   "metadata": {},
   "source": [
    "### The following cell is only required for the test run on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450b1be-5902-4685-99ab-07bc1cfab394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only rows referring to images in the smaller data set (test run):\n",
    "\n",
    "# Make sure no .DS_Store file is included in jpg_data_path: \n",
    "import os\n",
    "ds_file_path = jpg_data_path / '.DS_Store'\n",
    "\n",
    "# Remove a specific .DS_Store file\n",
    "if os.path.exists(ds_file_path):\n",
    "    os.remove(ds_file_path)\n",
    "    print(\"Removed .DS_Store\")\n",
    "else:\n",
    "    print(\".DS_Store not found\")\n",
    "\n",
    "# Find all .ipynb_checkpoints directories\n",
    "for checkpoint_dir in jpg_data_path.rglob('.ipynb_checkpoints'):\n",
    "    if checkpoint_dir.is_dir():\n",
    "        print(f\"Removing: {checkpoint_dir}\")\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Get list of image files present:\n",
    "image_files = os.listdir(jpg_data_path)\n",
    "\n",
    "#image_files.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract image ids from image file names:\n",
    "img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "img_ids.sort()\n",
    "print(img_ids)\n",
    "\n",
    "# Select relevant rows from label_data data frame by id list: \n",
    "select_bools = [img_id in img_ids for img_id in label_data.image_id]\n",
    "\n",
    "label_data = label_data[select_bools].copy()\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41eeea-fed0-4a96-9e12-5bcfbe5e1c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902fa678-9992-4b4f-8946-6554e3f6e926",
   "metadata": {},
   "source": [
    "### Convert tif images to jpg images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1c5ab-0461-4149-99f4-d8c04072ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = tif_data_path\n",
    "destination_folder = jpg_data_path\n",
    "\n",
    "llm_i.convert_tif_to_jpg(source_folder, destination_folder, quality=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b7367-06d3-4a85-b243-35cb10475486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdb6cf-3c7a-4b3f-9c27-a4649415cde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8375230d-8684-44ab-9732-9571a3cf9f43",
   "metadata": {},
   "source": [
    "## Yolo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83c0f-fab5-4993-bfee-34f92a23da91",
   "metadata": {},
   "source": [
    "### Define the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80166cf-42cd-48d6-a5ea-074716419a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLO model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use yolov8n (nano) for faster inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84879e-4b5f-4eac-9781-3a0bb44fcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save information about model version being used: \n",
    "model_name = model.model_name\n",
    "model_name_file_path = data_path /'yolo_model_info.txt'\n",
    "model_name_file_path\n",
    "with open(model_name_file_path, 'w') as f:\n",
    "    f.write(f\"YOLO Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0775f7f-99d1-4c5f-84c4-432c68d7c07c",
   "metadata": {},
   "source": [
    "### Prepare data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad6a54-0860-43a4-a939-cf7b9c10dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare empty data frame to store performance metrics:\n",
    "ml_metrics_yolo = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6647da-8663-490a-aab5-fc286a9be963",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_yolo = {}\n",
    "time_analyses_yolo['analysis_name'] = []\n",
    "time_analyses_yolo['time_stamp_start'] = []\n",
    "time_analyses_yolo['duration_str'] = []\n",
    "time_analyses_yolo['duration_seconds'] = []\n",
    "time_analyses_yolo['duration_seconds_str'] = []\n",
    "time_analyses_yolo['duration_minutes'] = []\n",
    "time_analyses_yolo['duration_minutes_str'] = []\n",
    "\n",
    "timestamp_start_workflow = pd.Timestamp.now()\n",
    "timestamp_start_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93bc2f-dabe-402a-b3dd-e822d3097492",
   "metadata": {},
   "source": [
    "### Set parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7cec7-0e4d-4479-af53-6eda2ee0c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_yolo'\n",
    "label_name = 'with_person'\n",
    "prediction_name = 'with_person_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3e0ce-6f84-4e7a-9001-14f6f4b49dfc",
   "metadata": {},
   "source": [
    "## Detect persons with pretrained yolo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a696001-b66f-4a55-be94-190f0b36acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_ids, with_person = sif.sort_img_files(image_dir, model, output_dir_with_person, \n",
    "#                                           output_dir_without_person, threshold=0.25)\n",
    "\n",
    "\n",
    "timestamp_start_pers_yolo = pd.Timestamp.now()\n",
    "\n",
    "img_ids, with_person = dpy.detect_persons_yolo(image_dir, model, threshold=0.25,\n",
    "                                              file_format=\"jpg\")\n",
    "timestamp_end_pers_yolo = pd.Timestamp.now()\n",
    "\n",
    "\n",
    "duration = timestamp_end_pers_yolo - timestamp_start_pers_yolo\n",
    "\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "\n",
    "# Store information about duration: \n",
    "time_analyses, time_analyses_yolo = store_duration(time_analyses, time_analyses_yolo, analysis_name, \n",
    "               duration, timestamp_start_pers_yolo,\n",
    "              timestamp_end_pers_yolo)\n",
    "\n",
    "yolo_timestamp_id = timestamp_start_pers_yolo.strftime('%Y%m%d_%H%M%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65320479-c1e5-4c5c-8532-b0482e2922c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f73d9-c659-4442-bc64-129bdfacf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(with_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c91ac-b072-4a77-85d5-e65728870b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_ids))\n",
    "print(len(with_person))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c752b-e8b7-4661-b8dd-6392c57b98e8",
   "metadata": {},
   "source": [
    "## Load label data and merge with prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9109a-8ee8-49fc-86b4-2b67f56d1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load person predictions into a dataframe: \n",
    "results_person = pd.DataFrame({'image_id': img_ids, label_name: with_person})\n",
    "# Add one-hot-coded person predictions:\n",
    "results_person[prediction_name]= [1 if x else 0 for x in results_person.with_person]\n",
    "results_person_select = results_person.loc[:, ['image_id', prediction_name]]\n",
    "# Take copy of label_data and select relevant columns:\n",
    "with_without_person = label_data.copy()\n",
    "with_without_person = with_without_person.iloc[:, 0:3]\n",
    "# Merge label data with the predictions:\n",
    "labels_results_yolo = with_without_person.merge(results_person_select, how='inner', on='image_id')\n",
    "labels_results_yolo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9df5a-88f0-4de3-ae3c-dde8d4185905",
   "metadata": {},
   "source": [
    "### Calculate performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c51e4-fd75-4d56-a119-45a205538dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity and specificity for person predictions and get the different data subsets based on label and predictions:\n",
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_yolo, label_name, \n",
    "                                                               prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics \n",
    "print(sensitivity)\n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c95cb-6605-49d0-b3af-c3ff908641a7",
   "metadata": {},
   "source": [
    "### Inspect false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c446b2d-4b55-4bef-8485-f2be100e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343ee97-be36-46cc-a187-222201fa544d",
   "metadata": {},
   "source": [
    "### Inspect false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f47b2-baed-4a59-8307-f8ca516b4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cdda2-ff3b-4d89-aee2-fe4466c20314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1306dc9b-1941-4280-973e-6c5d28f6c3f6",
   "metadata": {},
   "source": [
    "### Add performance metrics to data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152978b-b781-4f13-b247-6df6c64adbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of positives, negatives, true and false: \n",
    "number_positives = positives.shape[0]\n",
    "number_negatives = negatives.shape[0]\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "# Put everything into a dataframe: \n",
    "ml_metrics_to_stack = pd.DataFrame({})\n",
    "ml_metrics_to_stack['analysis_name'] = [analysis_name]\n",
    "ml_metrics_to_stack['time_stamp'] = [timestamp_start_pers_yolo]\n",
    "ml_metrics_to_stack['positives'] = [number_positives]\n",
    "ml_metrics_to_stack['negatives'] = [number_negatives]\n",
    "ml_metrics_to_stack['true_positives'] = [number_true_positives]\n",
    "ml_metrics_to_stack['false_positives'] = [number_false_positives]\n",
    "ml_metrics_to_stack['true_negatives'] = [number_true_negatives]\n",
    "ml_metrics_to_stack['false_negatives'] = [number_false_negatives]\n",
    "ml_metrics_to_stack['sensitivity'] = [sensitivity]\n",
    "ml_metrics_to_stack['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics_to_concat = [ml_metrics_yolo, ml_metrics_to_stack]\n",
    "ml_metrics_yolo = pd.concat(ml_metrics_to_concat)\n",
    "ml_metrics_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d36b8-cfb0-4943-882d-f36cda072404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2be7aa5-9956-474c-a4d3-beba2fc93daa",
   "metadata": {},
   "source": [
    "### Plot confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c436586-c21f-4d77-96e7-b8b026779175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cases = true_positives, false_positives, true_negatives, false_negatives, positives, negatives\n",
    "\n",
    "# llm_o.plot_conf_matrix(labels_results, 'with_person', 'with_person_yolo_pred', cases)\n",
    "fig = llm_o.save_conf_matrix(labels_results_yolo, label_name, prediction_name, cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c278c3a-c922-499e-b90d-59326ac0417b",
   "metadata": {},
   "source": [
    "### Save confusion matrix as pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9488026-1069-44d6-800d-44b9d48302a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fig object was created when plotting the confusion matrix\n",
    "# so now we can use it to save the plot as pdf:\n",
    "file_name = 'conf_matrix_metrics_' + analysis_name + '.pdf'\n",
    "conf_matrix_path = data_path / file_name\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166179c5-cf02-4a0a-a478-7559e06f1bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673922cb-2284-4bce-81eb-bccb11756b57",
   "metadata": {},
   "source": [
    "### Recalculate performance metrics with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68789693-d8ae-4619-a3c3-0c31948f8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_recognisable_yolo'\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18625f-ed0f-487d-b859-28bd80b82e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'pers_recognisable_yolo'\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_pred'\n",
    "\n",
    "# Calculate sensitivity and specificity for person predictions and get the different data subsets based on label and predictions:\n",
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_yolo, label_name, \n",
    "                                                               prediction_name)\n",
    "\n",
    "(positives, negatives, true_positives, true_negatives, false_negatives, \n",
    " false_positives, sensitivity, specificity) = subsets_and_metrics\n",
    "print(sensitivity) \n",
    "print(specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b4f22-6c35-4b23-bee2-fd260a195906",
   "metadata": {},
   "source": [
    "### Add performance metrics to data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e65bf-dfbe-4d3d-851d-d95c308e6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of positives and negatives, true and false: \n",
    "number_positives = positives.shape[0]\n",
    "number_negatives = negatives.shape[0]\n",
    "number_true_positives = true_positives.shape[0]\n",
    "number_false_positives = false_positives.shape[0]\n",
    "number_true_negatives = true_negatives.shape[0]\n",
    "number_false_negatives = false_negatives.shape[0]\n",
    "\n",
    "# Put everything into a dataframe:\n",
    "ml_metrics_to_stack = pd.DataFrame({})\n",
    "ml_metrics_to_stack['analysis_name'] = [analysis_name]\n",
    "ml_metrics_to_stack['time_stamp'] = [timestamp_start_pers_yolo]\n",
    "ml_metrics_to_stack['positives'] = [number_positives]\n",
    "ml_metrics_to_stack['negatives'] = [number_negatives]\n",
    "ml_metrics_to_stack['true_positives'] = [number_true_positives]\n",
    "ml_metrics_to_stack['false_positives'] = [number_false_positives]\n",
    "ml_metrics_to_stack['true_negatives'] = [number_true_negatives]\n",
    "ml_metrics_to_stack['false_negatives'] = [number_false_negatives]\n",
    "ml_metrics_to_stack['sensitivity'] = [sensitivity]\n",
    "ml_metrics_to_stack['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics_to_concat = [ml_metrics_yolo, ml_metrics_to_stack]\n",
    "ml_metrics_yolo = pd.concat(ml_metrics_to_concat)\n",
    "ml_metrics_yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7cf22b-0b47-4712-88e9-a8b6d7957c8b",
   "metadata": {},
   "source": [
    "### Plot confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969fcdf-a360-4d70-a9ca-c26a09095569",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = true_positives, false_positives, true_negatives, false_negatives, positives, negatives\n",
    "\n",
    "#llm_o.plot_conf_matrix(labels_results, 'person_recognisable', 'with_person_yolo_pred', cases)\n",
    "fig = llm_o.save_conf_matrix(labels_results_yolo, label_name, prediction_name, cases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f861c-44a3-471b-b938-5b21ab256acf",
   "metadata": {},
   "source": [
    "### Save confusion matrix as pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329c2d5-a3ca-4223-830e-6255c14bb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The fig object was created when plotting the confusion matrix\n",
    "# so now we can use it to save the plot as pdf:\n",
    "file_name = 'conf_matrix_metrics_' + analysis_name + '.pdf'\n",
    "conf_matrix_path = data_path / file_name\n",
    "fig.savefig(conf_matrix_path)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a4298-9f83-4fea-9179-d9ad4ea7d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7f49d-1caa-4b64-9a72-0e67c5fb5030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8dabb-2177-4afb-a6e9-4770f30e5e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a96ebe9-1778-4913-988e-4bd4dd6ebcc5",
   "metadata": {},
   "source": [
    "## Save labels results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcb358-523d-4612-8c78-eafd9bd784ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_name = 'people_detect_multi_approach_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8353f-6ec7-4217-8a44-c21120a9db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'labels_results_yolo_' + yolo_timestamp_id + '.csv'\n",
    "labels_results_yolo.to_csv(data_path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7652db-1fb3-4e43-9a7b-73491d4eaa12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca46f9cd-be78-4e5b-9f2c-b49a155efc8f",
   "metadata": {},
   "source": [
    "### Save ml metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aae8fd-dbad-442d-830e-89336ee20b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'ml_metrics_yolo_' + yolo_timestamp_id + '.csv'\n",
    "ml_metrics_yolo.to_csv(data_path/filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b53c08-0931-4062-9db5-b54021c4c125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd364145-e6a6-493a-a808-3f5b7d23b935",
   "metadata": {},
   "source": [
    "### Save time analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cfe3a-17a8-4aed-b5a4-e808287a9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_yolo_file_name = 'times_' + workflow_name + 'yolo_' + yolo_timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_yolo_output_path = os.path.join(data_path, time_analyses_yolo_file_name)\n",
    "with open(time_analyses_yolo_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_yolo, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_yolo_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_yolo = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_yolo))\n",
    "print(type(time_analyses_yolo))\n",
    "print(type(reloaded_time_analyses_yolo))\n",
    "print(len(reloaded_time_analyses_yolo))\n",
    "\n",
    "print(time_analyses_yolo.keys() == reloaded_time_analyses_yolo.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542bd89-f7c7-4774-b3e4-908fa13b24aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb53ae21-05f1-4030-93c5-9f6abe6f6d0c",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77988db-6a83-42ac-bcc9-b23b5d7ff6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec9ac00-0ae1-4ecb-a246-79533ef517b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_prompt_person():\n",
    "    \"\"\"Create the structured prompt for image analysis.\"\"\"\n",
    "    return \"\"\"\n",
    "    Analyze this image and return ONLY a Python dictionary in exactly this format:\n",
    "    \n",
    "    {\n",
    "        'contains_persons': X,  # True if the image contains a person or multiple persons, False if the image does not contain any person.\n",
    "        'additional_comments': '' # Any additional observations or empty string if none.\n",
    "    }\n",
    "    \n",
    "    Replace X with True (image contains one or multiple persons) or False (does not contain any person).\n",
    "    Return ONLY the dictionary, no other text.\n",
    "    Your answer MUST have the exact structue of the dictionary described above (all keys MUST be present). \n",
    "    If you cannot answer the question in the way implied by this structure, enter 'None' as value and offer \n",
    "    your answer and explanations under 'additional_comments'.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077f3f1-4497-4536-bc9d-d79433c13882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_giub_img_dir_llm(jpg_data_path, create_analysis_prompt, model_function):\n",
    "    # Get time stamp:\n",
    "    timestamp_start_is_photo_analysis = pd.Timestamp.now()\n",
    "    \n",
    "    # Get list of image files to analyse: \n",
    "    image_files = os.listdir(jpg_data_path)\n",
    "    print(image_files)\n",
    "    img_ids = [image_file.split('Oberland')[1].split('.')[0] for image_file in image_files]\n",
    "    \n",
    "    # Make empty dictionary to store results:\n",
    "    image_descr = {}\n",
    "    \n",
    "    # Loop through images to get answers: \n",
    "    for image_file in image_files:\n",
    "        image_path = jpg_data_path / image_file\n",
    "        path_str = str(image_path)\n",
    "        print('\\n')\n",
    "        print(path_str)\n",
    "        parts = path_str.split('.jpg')\n",
    "        img_id = parts[-2][-3:]\n",
    "    \n",
    "        # Analyse image, get values for each of the categorical variables specified above:\n",
    "        #image_description = analyze_image_structured(image_path)\n",
    "        #image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt)\n",
    "        image_description = llm_o.analyze_image_structured(image_path, create_analysis_prompt, model_function)\n",
    "        print(image_description)\n",
    "        \n",
    "        dict_type_bool = type(image_description) == dict\n",
    "            \n",
    "        #print(image_description)\n",
    "        image_descr[img_id] = image_description\n",
    "    \n",
    "    timestamp_end_is_photo_analysis = pd.Timestamp.now()\n",
    "\n",
    "    return timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46a19f-866a-447b-a878-1f67cd90b1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b9454a-0b7c-4b4b-8201-d935494f7340",
   "metadata": {},
   "source": [
    "### Switch on working version of Ollama (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a586cb5-eeb3-4841-b3f4-b8254e58705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS FOR OLLAMA VERSION SWITCHING\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def stop_ollama():\n",
    "    \"\"\"Stop any running Ollama process\"\"\"\n",
    "    subprocess.run(['killall', 'ollama'], stderr=subprocess.DEVNULL)\n",
    "    subprocess.run(['killall', 'ollama-0.11.2'], stderr=subprocess.DEVNULL)\n",
    "    subprocess.run(['killall', 'ollama-0.11.10'], stderr=subprocess.DEVNULL)\n",
    "    time.sleep(2)\n",
    "    print(\"âœ“ Stopped all Ollama processes\")\n",
    "\n",
    "def start_ollama_version(version):\n",
    "    \"\"\"Start specific Ollama version (e.g., '0.11.2' or '0.11.10')\"\"\"\n",
    "    binary_name = f'ollama-{version}'\n",
    "    log_file = open(f'/tmp/ollama_{version}.log', 'w')\n",
    "    subprocess.Popen([binary_name, 'serve'], stdout=log_file, stderr=subprocess.STDOUT)\n",
    "    print(f\"Starting Ollama v{version}...\", end='', flush=True)\n",
    "    time.sleep(4)\n",
    "    print(\" âœ“ Running\")\n",
    "\n",
    "print(\"Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af58c06-9c7f-4f13-b0ef-a1771eb58c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: TESTING WITH v0.11.2 (WORKING VERSION - Aug 5, 2025)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"ðŸŸ¢ \"*35)\n",
    "print(\"PART 1: TESTING WITH v0.11.2 (WORKING VERSION)\")\n",
    "print(\"ðŸŸ¢ \"*35 + \"\\n\")\n",
    "\n",
    "stop_ollama()\n",
    "start_ollama_version('0.11.2')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644376b4-99e8-4281-a717-5dc8dd588ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f08cc3d-ef22-481d-92a7-87b3c9a8a398",
   "metadata": {},
   "source": [
    "### Define LLM model to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a266a-8113-420c-a319-af05a505da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_model(image_path, prompt_function):\n",
    "    prompt = prompt_function()\n",
    "    \"\"\"Make the API call to Ollama.\"\"\"\n",
    "    # Convert image if needed\n",
    "    processed_path = llm_i.convert_image_if_needed(image_path)\n",
    "    if processed_path is None:\n",
    "        raise ValueError(f\"Could not process image: {image_path}\")\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"minicpm-v\", \n",
    "        #model=\"llama3.2-vision:latest\",\n",
    "        #model=\"llama3.2-vision:90b\",\n",
    "        messages=[{\n",
    "            'role': 'user', \n",
    "            'content': prompt,\n",
    "            'images': [processed_path]\n",
    "        }],\n",
    "        options={\n",
    "        'temperature': 0.1,  # Lower = more deterministic (0.0 to 1.0)\n",
    "        #'seed': 42           # Fixed seed for reproducibility\n",
    "    }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca73b51-c951-4403-9fb3-01d51ee5cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_function = llm_i.call_minicpm_model\n",
    "#model_function = llm_i.call_ollama_model\n",
    "model_function = call_ollama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f988a15-d83e-4c73-933b-c501d40e2e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d6115ec-0434-4ca5-ba86-98bfae55bd74",
   "metadata": {},
   "source": [
    "### Get minicpm-v version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea643b06-62f6-4b9f-8a86-4a140f87b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MINICPM-V MODEL INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Read the manifest file directly\n",
    "manifest_path = '/Users/stephanehess/.ollama/models/manifests/registry.ollama.ai/library/minicpm-v/latest'\n",
    "\n",
    "with open(manifest_path, 'r') as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Get file modification time (when you pulled the model)\n",
    "file_stat = os.stat(manifest_path)\n",
    "pull_date = datetime.fromtimestamp(file_stat.st_mtime)\n",
    "\n",
    "full_digest = manifest['config']['digest']\n",
    "\n",
    "print(f\"\\nModel: minicpm-v:latest\")\n",
    "print(f\"Pulled on: {pull_date.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print('full digest:')\n",
    "print(full_digest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e139743-9228-428e-b8e6-5482af5ce548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save information about model version being used: \n",
    "model_version = full_digest\n",
    "model_name_file_path = data_path /'minicpm_v_model_info.txt'\n",
    "model_name_file_path\n",
    "with open(model_name_file_path, 'w') as f:\n",
    "    f.write(f\"minicpm-v Model: {model_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc6eee-3a92-4102-b229-e46812a548cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3654c42-eea1-4099-aec7-ab0babbfce55",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83082fb-f6c4-4ea6-9fea-1691c158c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses = {}\n",
    "time_analyses_llm = {}\n",
    "time_analyses_llm['analysis_name'] = []\n",
    "time_analyses_llm['time_stamp_start'] = []\n",
    "time_analyses_llm['duration_str'] = []\n",
    "time_analyses_llm['duration_seconds'] = []\n",
    "time_analyses_llm['duration_seconds_str'] = []\n",
    "time_analyses_llm['duration_minutes'] = []\n",
    "time_analyses_llm['duration_minutes_str'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5853ba-d1a2-43d5-8316-94c5ec33e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to store the different response dictionaries:\n",
    "response_dictionaries = {}\n",
    "# Empty dictionary for cases with unstructured answers for visual inspection:\n",
    "images_closer_inspection = {}\n",
    "# Empty dictionary for result dataframes:\n",
    "results_tabular = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2c346-6a77-45ae-a2db-06f967318f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74279c1f-1fca-4b99-bfbc-f945a96341a5",
   "metadata": {},
   "source": [
    "### Prepare data objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814e5e8-5b9e-4766-bf39-b7e9f4e6f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data objects: \n",
    "response_dictionaries = {}\n",
    "\n",
    "images_closer_inspection = {}\n",
    "\n",
    "results_tabular = {}\n",
    "\n",
    "ml_metrics_llm = pd.DataFrame({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f64de9-2205-4d31-b04f-ea9737a82219",
   "metadata": {},
   "source": [
    "### Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad187db-be68-41e7-b61c-b88a19c0372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters: \n",
    "analysis_name = 'pers_struct_minicpm'\n",
    "\n",
    "prompt_func = create_analysis_prompt_person\n",
    "prompt_template = prompt_func.__name__\n",
    "prompt_id = prompt_template + '_v1'\n",
    "prompt_text = prompt_func()\n",
    "\n",
    "keys_list_expected = ['contains_persons', 'additional_comments']\n",
    "response_variables = ['contains_persons']\n",
    "\n",
    "label_names = ['with_person']\n",
    "prediction_name = 'with_person_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d6841-875c-477c-bed4-d15454071348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0d2d13-267f-492b-a946-787077b125c0",
   "metadata": {},
   "source": [
    "### Carry out LLM analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db101a5e-5a9d-43f7-be32-5d5a9167df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_start_is_photo_analysis, timestamp_end_is_photo_analysis, image_descr = analyse_giub_img_dir_llm(jpg_data_path, prompt_func, model_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33e848-ac6a-47b8-a64e-ac8935f523b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "225576f3-bbb8-41ab-ab77-162edb16cf3c",
   "metadata": {},
   "source": [
    "### Extract and organize information from the dictionary containing the LLM responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8cb2b6-291a-4ec7-a0d4-358ba1c7c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timestamp_id as string from the time stamp:\n",
    "llm_timestamp_id = timestamp_start_is_photo_analysis.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Calculate duration of analysis: \n",
    "duration = timestamp_end_is_photo_analysis - timestamp_start_is_photo_analysis\n",
    "total_seconds = duration.total_seconds()\n",
    "print(total_seconds)\n",
    "\n",
    "# Store information about duration of LLM task: \n",
    "time_analyses, time_analyses_llm = store_duration(time_analyses, time_analyses_llm, prompt_id, \n",
    "                duration,timestamp_start_is_photo_analysis,\n",
    "                timestamp_end_is_photo_analysis)\n",
    "\n",
    "\n",
    "# Store dictionary with LLM responses as raw data:\n",
    "response_dictionaries[llm_timestamp_id] = {}\n",
    "response_dictionaries[llm_timestamp_id][prompt_id] = image_descr\n",
    "\n",
    "# convert img_ids pandas series into list:\n",
    "img_ids_l = list(img_ids)\n",
    "\n",
    "# Prepare dictionary for long term storing of results: \n",
    "results_tabular[llm_timestamp_id] = {}\n",
    "results_tabular[llm_timestamp_id]['prompt_id'] = prompt_id\n",
    "results_tabular[llm_timestamp_id]['prompt_template'] = prompt_template\n",
    "results_tabular[llm_timestamp_id]['prompt_text'] = prompt_text\n",
    "results_tabular[llm_timestamp_id]['predictions'] = {}\n",
    "\n",
    "# Get copy of label data to merge with prediction for short term presentation of results:\n",
    "labels_results_i = label_data.copy()\n",
    "labels_results_i = labels_results_i.iloc[:, 0:3]\n",
    "print('labels_results initial:')\n",
    "print(labels_results_i.shape)\n",
    "print(labels_results_i.columns)\n",
    "\n",
    "# Extract predictions for different response variables:\n",
    "for response_variable, label_name in zip(response_variables, label_names):\n",
    "    # set prediction name: \n",
    "    prediction_name = label_name + '_pred'\n",
    "    analysis_name = label_name + '_struct_minicpm'\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('response_variable name and prediction_name:')\n",
    "    print(response_variable)\n",
    "    print(prediction_name)\n",
    "    img_ids, response_values, img_ids_closer_inspection = \\\n",
    "    llm_o.extract_vals_from_response_dict(img_ids_l, image_descr, keys_list_expected, response_variable)\n",
    "\n",
    "    timestamp_ids = [llm_timestamp_id] * len(img_ids)\n",
    "    \n",
    "    predictions = pd.DataFrame({'image_id': img_ids, \n",
    "                                   prediction_name: response_values})\n",
    "    predictions[prediction_name] = predictions[prediction_name].astype('Int8')\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('predictions:')\n",
    "    # print(predictions.shape)\n",
    "    # print(predictions.columns)\n",
    "\n",
    "    results_tabular[llm_timestamp_id]['predictions'][response_variable] = predictions\n",
    "    \n",
    "    # Merge label data with the predictions:\n",
    "    labels_results_i = labels_results_i.merge(predictions, how='inner', on='image_id')\n",
    "    # print('\\n')\n",
    "    # print('merged labels_results:')\n",
    "    # print(labels_results_i.shape)\n",
    "    # print(labels_results_i.columns)\n",
    "\n",
    "    # Save image list for closer inspection:\n",
    "    timestamp_ids = [llm_timestamp_id] * len(img_ids_closer_inspection)\n",
    "    imgs_closer_inspection = pd.DataFrame({'image_id': img_ids_closer_inspection,\n",
    "    'time_stamp': timestamp_ids})\n",
    "    images_closer_inspection[analysis_name] = imgs_closer_inspection\n",
    "    \n",
    "    # Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "    subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_i, label_name, prediction_name)\n",
    "    positives, negatives, true_positives, true_negatives, \\\n",
    "    false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n",
    "\n",
    "\n",
    "    ml_metrics_analysis_name = []\n",
    "    ml_metrics_prompt_id = []\n",
    "    ml_metrics_label_name = []\n",
    "    ml_metrics_time_stamp = []\n",
    "    ml_metrics_positives = []\n",
    "    ml_metrics_negatives = []\n",
    "    ml_metrics_true_positives = []\n",
    "    ml_metrics_false_positives = []\n",
    "    ml_metrics_true_negatives = []\n",
    "    ml_metrics_false_negatives = []\n",
    "    ml_metrics_sensitivity = []\n",
    "    ml_metrics_specificity = []\n",
    "\n",
    "    ml_metrics_analysis_name.append(analysis_name)\n",
    "    ml_metrics_prompt_id.append(prompt_id)\n",
    "    ml_metrics_label_name.append(label_name)\n",
    "    ml_metrics_time_stamp.append(timestamp_start_is_photo_analysis)\n",
    "    ml_metrics_positives.append(positives.shape[0])\n",
    "    ml_metrics_negatives.append(negatives.shape[0])\n",
    "    ml_metrics_true_positives.append(true_positives.shape[0])\n",
    "    ml_metrics_false_positives.append(false_positives.shape[0])\n",
    "    ml_metrics_true_negatives.append(true_negatives.shape[0])\n",
    "    ml_metrics_false_negatives.append(false_negatives.shape[0])\n",
    "    ml_metrics_sensitivity.append(sensitivity)\n",
    "    ml_metrics_specificity.append(specificity)\n",
    "\n",
    "    ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "    ml_metrics_one_analysis['analysis_name'] = ml_metrics_analysis_name\n",
    "    ml_metrics_one_analysis['prompt_id'] = ml_metrics_prompt_id\n",
    "    ml_metrics_one_analysis['label_name'] = ml_metrics_label_name\n",
    "    ml_metrics_one_analysis['time_stamp'] = ml_metrics_time_stamp\n",
    "    ml_metrics_one_analysis['positives'] = ml_metrics_positives\n",
    "    ml_metrics_one_analysis['negatives'] = ml_metrics_negatives\n",
    "    ml_metrics_one_analysis['true_positives'] = ml_metrics_true_positives\n",
    "    ml_metrics_one_analysis['false_positives'] = ml_metrics_false_positives\n",
    "    ml_metrics_one_analysis['true_negatives'] = ml_metrics_true_negatives\n",
    "    ml_metrics_one_analysis['false_negatives'] = ml_metrics_false_negatives\n",
    "    ml_metrics_one_analysis['sensitivity'] = ml_metrics_sensitivity\n",
    "    ml_metrics_one_analysis['specificity'] = ml_metrics_specificity\n",
    "    \n",
    "    ml_metrics_llm = pd.concat([ml_metrics_llm, ml_metrics_one_analysis], ignore_index=True)\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('ml_metrics:')\n",
    "    # print(ml_metrics.shape)\n",
    "    # print(ml_metrics)\n",
    "labels_results_llm = labels_results_i.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f821c75-763a-439c-9974-d55c1a1b2a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da36bb-da83-400b-b3ff-f45dde2c38f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9f99b-f6c3-4bea-b0db-3ec9181104d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267c1a7c-50c3-426f-8769-ef4875abb849",
   "metadata": {},
   "source": [
    "## Recalculate Measures with recognisable_label as ground truth (instead of person_label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512b15a-05d3-4b58-aa08-f5bc3c6746dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#previous_analysis_name = analysis_name\n",
    "#labels_results_i = label_data.copy()\n",
    "#labels_results_i = labels_results_i.merge(predictions, how='inner', on='image_id')\n",
    "\n",
    "\n",
    "# Set parameters: \n",
    "analysis_name = 'pers_recognisable_struct_minicpm'\n",
    "# create_analysis_prompt = create_analysis_prompt_person\n",
    "# keys_list_expected = ['contains_persons', 'additional_comments']\n",
    "# response_variable = 'contains_persons'\n",
    "\n",
    "label_name = 'person_recognisable'\n",
    "prediction_name = 'with_person_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a09db-ae4c-48f5-9715-a1f7c251d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate sensitivity and specificity for photography predictions and get lists images with positive photography predictions:\n",
    "subsets_and_metrics = llm_o.get_classification_subsets_metrics(labels_results_llm, label_name, prediction_name)\n",
    "positives, negatives, true_positives, true_negatives, \\\n",
    "false_negatives, false_positives, sensitivity, specificity = subsets_and_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837d9fa-cc97-443e-a094-1d7e5ce7bcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d510a6-ba5e-4fec-afae-8d10822e3585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1cdc9-a196-4285-8907-58980d67fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_one_analysis = pd.DataFrame({})\n",
    "\n",
    "ml_metrics_one_analysis['analysis_name'] = [analysis_name]\n",
    "ml_metrics_one_analysis['prompt_id'] = [prompt_id]\n",
    "ml_metrics_one_analysis['label_name'] = [label_name]\n",
    "ml_metrics_one_analysis['time_stamp'] = [timestamp_start_is_photo_analysis]\n",
    "ml_metrics_one_analysis['positives'] = [positives.shape[0]]\n",
    "ml_metrics_one_analysis['negatives'] = [negatives.shape[0]]\n",
    "ml_metrics_one_analysis['true_positives'] = [true_positives.shape[0]]\n",
    "ml_metrics_one_analysis['false_positives'] = [false_positives.shape[0]]\n",
    "ml_metrics_one_analysis['true_negatives'] = [true_negatives.shape[0]]\n",
    "ml_metrics_one_analysis['false_negatives'] = [false_negatives.shape[0]]\n",
    "ml_metrics_one_analysis['sensitivity'] = [sensitivity]\n",
    "ml_metrics_one_analysis['specificity'] = [specificity]\n",
    "\n",
    "ml_metrics_llm = pd.concat([ml_metrics_llm, ml_metrics_one_analysis], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8d52a-5b41-499a-91f1-9d75e22d4484",
   "metadata": {},
   "source": [
    "### Inspect results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05595e67-9840-41c6-a788-f146b44cdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_yolo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f926d6-0a35-4811-8e0a-9583218930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_results_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5170d-42fd-413a-990b-7efaf053d97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af43db-9da3-4268-84ac-672787c635cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455f77d-97d6-418d-adb3-ddf5188d62bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61c871-a095-42af-8951-d11c289e026c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae45e9c-1d90-41cc-9b52-d4297421f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tabular[llm_timestamp_id]['predictions'][response_variables[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6466b-62e0-4c6e-b873-a60a181daa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f244846-e728-44d8-a9b6-160734777721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b59bba5-e0cb-43b1-9fcf-b9804dc60e82",
   "metadata": {},
   "source": [
    "### Get image ID's where at least one model has detected a person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cf3d7-5b5f-41c6-ad27-f78a8ebe5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_bools = labels_results_yolo.with_person_pred == 1\n",
    "minicpm_bools = labels_results_llm.with_person_pred == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1614414-1b55-4c6d-af8b-132a61f0bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(yolo_bools))\n",
    "print(sum(minicpm_bools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fbfb5-94f5-4415-a0db-fc2921324a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_yolo_detect = labels_results_yolo[yolo_bools].image_id\n",
    "img_ids_yolo_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b1d8-37e1-4004-8531-2f8d855e603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_llm_detect = labels_results_llm[minicpm_bools].image_id\n",
    "img_ids_llm_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392c67d-ef7a-4049-b08f-832c58cdd765",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids_detect = list(set.union(set(img_ids_yolo_detect), set(img_ids_llm_detect)))\n",
    "img_ids_detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74a5dd-4766-45d0-9941-03c78b4325fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_ids = list(label_data.image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133fd5f0-d29c-4939-a7f6-e8bca1644b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_detect_bools = [img_id in img_ids_detect for img_id in all_img_ids]\n",
    "person_detect_bools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c41b3-9655-43ca-a41e-c707fe88538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_detected_data = label_data[person_detect_bools]\n",
    "person_detected_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e546487-c87e-4c58-ad0d-596da8102967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520dda2-1d01-490d-af78-e0ffad7119eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1319be-905b-471f-b9fd-706b0408a780",
   "metadata": {},
   "source": [
    "## Save labels and results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098faba-99b2-4fbc-a481-240e03c93f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add image ids that will remain string type even when saved to csv and reloaded:\n",
    "labels = list(labels_results_llm.image_id)\n",
    "new_labels = img_idc.complete_image_ids(labels)\n",
    "labels_results_llm['image_id_str'] = new_labels\n",
    "labels_results_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52710d2-5058-4f0c-90e8-f3a84a2e03a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42b6ca9-dcb7-4c14-938c-d29655f59d58",
   "metadata": {},
   "source": [
    "## Save labels results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c4425-4d0f-4dc6-987e-488df4de8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_name = 'people_detect_multi_approach_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae56d911-5b35-4135-8343-94355251a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'labels_results_llm_' + llm_timestamp_id + '.csv'\n",
    "labels_results_llm.to_csv(data_path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2584d-8c79-46f8-aae6-031400479816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26790c1e-a468-48df-a969-f9bb07a95cbd",
   "metadata": {},
   "source": [
    "### Save ml metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b0d16-a562-49e6-bb2c-39168897b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = workflow_name + 'ml_metrics_llm_' + llm_timestamp_id + '.csv'\n",
    "ml_metrics_llm.to_csv(data_path/filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5599cc7-ab75-44ad-9516-e7f2076cb29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fef058ec-2c53-48cd-aea7-fab5384a2640",
   "metadata": {},
   "source": [
    "## Save results object from llm analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfa6df-d2db-417c-a390-d9a2fea8970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "results_file_name = 'results_llm_' + workflow_name + llm_timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "results_tabular_output_path = os.path.join(data_path, results_file_name)\n",
    "with open(results_tabular_output_path, 'wb') as f:\n",
    "   pickle.dump(results_tabular, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(results_tabular_output_path, 'rb') as f:\n",
    "   reloaded_results_tabular = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(results_tabular))\n",
    "print(type(results_tabular))\n",
    "print(type(reloaded_results_tabular))\n",
    "print(len(reloaded_results_tabular))\n",
    "\n",
    "print(results_tabular.keys() == reloaded_results_tabular.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704780fe-5e1c-4d3e-a3ac-a4e1080fe59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "568b6ee5-e2ed-445e-85fd-56b50b0a82fd",
   "metadata": {},
   "source": [
    "## Save response dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f159f-0f69-4a73-b8d5-b243c049e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "filename = 'responses_llm_' + workflow_name + llm_timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary with LLM responses:\n",
    "img_analysis_output_path = os.path.join(data_path, filename)\n",
    "with open(img_analysis_output_path, 'wb') as f:\n",
    "   pickle.dump(response_dictionaries, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(img_analysis_output_path, 'rb') as f:\n",
    "   reloaded_response_dictionaries = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(response_dictionaries))\n",
    "print(type(response_dictionaries))\n",
    "print(type(reloaded_response_dictionaries))\n",
    "print(len(reloaded_response_dictionaries))\n",
    "\n",
    "print(response_dictionaries.keys() == reloaded_response_dictionaries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d11e80-210f-487a-9df3-53fcd9921b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89713e6d-0d55-4894-8936-803f79401769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89772f51-0852-42d8-b713-c81216a8e7e0",
   "metadata": {},
   "source": [
    "### Save time analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bfff1-e41d-4991-a636-b1f85b15f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name: \n",
    "\n",
    "time_analyses_llm_file_name = 'times_' +workflow_name + 'llm_' + llm_timestamp_id + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_llm_output_path = os.path.join(data_path, time_analyses_llm_file_name)\n",
    "with open(time_analyses_llm_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses_llm, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_llm_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses_llm = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses_llm))\n",
    "print(type(time_analyses_llm))\n",
    "print(type(reloaded_time_analyses_llm))\n",
    "print(len(reloaded_time_analyses_llm))\n",
    "\n",
    "print(time_analyses_llm.keys() == reloaded_time_analyses_llm.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bff919-ac06-4968-b8a0-5699ad075c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f293c-7769-47b9-b6c8-e912170eef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69137ae-a94c-4186-8a83-d65f1b8eca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_analyses_llm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5144a8ee-640a-4da5-a521-d1454b59a206",
   "metadata": {},
   "source": [
    "\n",
    "# Define file name: \n",
    "\n",
    "time_analyses_file_name = workflow_name + '.pkl'\n",
    "\n",
    "# Save dictionary:\n",
    "time_analyses_output_path = os.path.join(data_path, time_analyses_file_name)\n",
    "with open(time_analyses_output_path, 'wb') as f:\n",
    "   pickle.dump(time_analyses, f)\n",
    "\n",
    "# Reload saved dictionary to check if saving worked:\n",
    "with open(time_analyses_output_path, 'rb') as f:\n",
    "   reloaded_time_analyses = pickle.load(f)\n",
    "\n",
    "# Check if original and reloaded dictionary are the same:\n",
    "print(len(time_analyses))\n",
    "print(type(time_analyses))\n",
    "print(type(reloaded_time_analyses))\n",
    "print(len(reloaded_time_analyses))\n",
    "\n",
    "print(time_analyses.keys() == reloaded_time_analyses.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da5573-2b9c-4712-8002-b921d82286b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ebd24e-951e-438b-b4ce-a8aac91f442c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad074bc-503e-43ae-855a-2684ffb76413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651d92e-fa41-464a-9d39-f8424ea87ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c54a3-e0ca-4fb1-90d6-9f8b72d3de17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
